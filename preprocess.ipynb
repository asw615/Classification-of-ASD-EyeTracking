{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob as glob\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import isodate\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Unique columns in each CSV file ## \n",
    "def read_csv_headers(file_path):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)  # Read the first line\n",
    "    return set(headers)\n",
    "\n",
    "# Directory containing your CSV files\n",
    "directory = '../data/Eye-tracking Output/raw_data'\n",
    "\n",
    "# Read headers from the first file (1.csv)\n",
    "base_headers = read_csv_headers(os.path.join(directory, '1.csv'))\n",
    "\n",
    "# Compare headers from all other files to the first file\n",
    "for i in range(2, 26):\n",
    "    file_path = os.path.join(directory, f'{i}.csv')\n",
    "    if os.path.exists(file_path):\n",
    "        current_headers = read_csv_headers(file_path)\n",
    "        if current_headers != base_headers:\n",
    "            print(f\"\\n{i}.csv differs from 1.csv:\")\n",
    "            print(\"Missing columns in 1.csv:\", current_headers - base_headers)\n",
    "            print(\"Additional columns in 1.csv:\", base_headers - current_headers)\n",
    "    else:\n",
    "        print(f\"{i}.csv does not exist in the directory.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking all files which contain the same column names ##\n",
    "\n",
    "# Define the directory containing the CSV files (using the provided path by the user)\n",
    "directory = '../data/Eye-tracking Output/raw_data'\n",
    "\n",
    "# Initialize an empty list to store the column names from each file\n",
    "all_columns = []\n",
    "\n",
    "# Iterate over the file numbers and collect their column names\n",
    "for i in range(1, 26):\n",
    "    file_path = os.path.join(directory, f'{i}.csv')\n",
    "    try:\n",
    "        # Read just the first row to get the column names\n",
    "        df = pd.read_csv(file_path, nrows=0)\n",
    "        # Append the column names to the list\n",
    "        all_columns.append(set(df.columns))\n",
    "    except FileNotFoundError:\n",
    "        print(f\"File {i}.csv not found.\")\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while processing {i}.csv: {e}\")\n",
    "\n",
    "# Use set intersection to find the common columns across all files\n",
    "common_columns = set.intersection(*all_columns) if all_columns else set()\n",
    "\n",
    "# Convert the common columns set to a sorted list\n",
    "common_columns_list = sorted(list(common_columns))\n",
    "common_columns_list\n",
    "\n",
    "## saving the column names into a file ## \n",
    "def read_csv_headers(file_path):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        headers = next(reader)  # Read the first line\n",
    "    return headers\n",
    "\n",
    "# Directory containing your CSV files\n",
    "directory = '../data/Eye-tracking Output/raw_data'\n",
    "\n",
    "# Set to store unique column names\n",
    "unique_columns = set()\n",
    "\n",
    "# Read headers from all files and update the set of unique columns\n",
    "for i in range(1, 26):\n",
    "    file_path = os.path.join(directory, f'{i}.csv')\n",
    "    if os.path.exists(file_path):\n",
    "        headers = read_csv_headers(file_path)\n",
    "        unique_columns.update(headers)\n",
    "    else:\n",
    "        print(f\"{i}.csv does not exist in the directory.\")\n",
    "\n",
    "# Path for the new CSV file to save unique columns\n",
    "output_file = os.path.join(directory, 'unique_columns.csv')\n",
    "\n",
    "# Write unique column names to the new CSV file\n",
    "with open(output_file, 'w', newline='') as csvfile:\n",
    "    writer = csv.writer(csvfile)\n",
    "    for column in sorted(unique_columns):\n",
    "        writer.writerow([column])\n",
    "\n",
    "print(f\"Unique columns have been saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Checking if all ET expirements had different videos ## \n",
    "def read_stimulus_values(file_path):\n",
    "    with open(file_path, 'r') as csvfile:\n",
    "        reader = csv.DictReader(csvfile)\n",
    "        return set(row['Stimulus'] for row in reader)\n",
    "\n",
    "# Directory containing your CSV files\n",
    "directory = '../data/Eye-tracking Output/raw_data'\n",
    "\n",
    "# Store the stimulus values for each file\n",
    "stimulus_dict = {}\n",
    "for i in range(1, 26):\n",
    "    file_path = os.path.join(directory, f'{i}.csv')\n",
    "    if os.path.exists(file_path):\n",
    "        stimulus_dict[f'{i}.csv'] = read_stimulus_values(file_path)\n",
    "    else:\n",
    "        print(f\"{i}.csv does not exist in the directory.\")\n",
    "\n",
    "# Compare the stimulus sets\n",
    "unique_sets = {}\n",
    "for filename, stimuli in stimulus_dict.items():\n",
    "    if stimuli not in unique_sets.values():\n",
    "        unique_sets[filename] = stimuli\n",
    "\n",
    "# Print results\n",
    "print(\"Unique Stimulus Sets:\")\n",
    "for filename in unique_sets:\n",
    "    print(f\"- {filename}\")\n",
    "\n",
    "print(\"\\nFiles with Same Stimulus Sets:\")\n",
    "for file1, stimuli1 in stimulus_dict.items():\n",
    "    same_sets = [file2 for file2, stimuli2 in stimulus_dict.items() if stimuli1 == stimuli2 and file1 != file2]\n",
    "    if same_sets:\n",
    "        print(f\"{file1} has the same stimulus set as: {', '.join(same_sets)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_86845/4294307232.py:15: DtypeWarning: Columns (15,16,17,18,19,20,21,22,23,24,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_, dtype=dtype_dict, index_col=None, header=0)\n"
     ]
    }
   ],
   "source": [
    "## Concatting data into single CSV file ##\n",
    "# Path to the directory containing CSV files\n",
    "path = \"../data/Eye-tracking Output/raw_data/*.csv\"\n",
    "\n",
    "# Using glob to find all csv files in the directory\n",
    "file_list = glob.glob(path)\n",
    "\n",
    "# Define data types for columns with mixed types\n",
    "dtype_dict = {str(i): str for i in range(15, 43)}\n",
    "dtype_dict['Participant'] = str  # Ensure Participant is also read as string\n",
    "\n",
    "# Reading all csv files and appending them to a list\n",
    "list_ = []\n",
    "for file_ in file_list:\n",
    "    df = pd.read_csv(file_, dtype=dtype_dict, index_col=None, header=0)\n",
    "    list_.append(df)\n",
    "\n",
    "# Concatenating all csv files into one dataframe\n",
    "df = pd.concat(list_, axis=0, ignore_index=True)\n",
    "\n",
    "# Saving the dataframe as a csv file\n",
    "df.to_csv(\"../data/Eye-tracking Output/combined.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of different participants across all CSV files: 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_86845/482206397.py:26: DtypeWarning: Columns (7,12,14,15,16,19,20,21,22,26,27,28,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('../data/Eye-tracking Output/combined.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset has 91 unique participants\n"
     ]
    }
   ],
   "source": [
    "## Checking how many participants in raw csv files compared to combined ##\n",
    "# Directory containing your CSV files\n",
    "directory = '../data/Eye-tracking Output/raw_data'\n",
    "\n",
    "def count_unique_participants(directory, participant_id_column):\n",
    "    participant_ids = set()\n",
    "    for i in range(1, 26):\n",
    "        file_path = os.path.join(directory, f'{i}.csv')\n",
    "        try:\n",
    "            with open(file_path, 'r') as csvfile:\n",
    "                reader = csv.DictReader(csvfile)\n",
    "                for row in reader:\n",
    "                    participant_ids.add(row[participant_id_column])\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file_path} not found.\")\n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred while processing {file_path}: {e}\")\n",
    "\n",
    "    return len(participant_ids)\n",
    "\n",
    "participant_id_column = 'Participant' \n",
    "num_participants = count_unique_participants(directory, participant_id_column)\n",
    "print(f\"Total number of different participants across all CSV files: {num_participants}\")\n",
    "\n",
    "# checking number of participants in the combined csv\n",
    "df = pd.read_csv('../data/Eye-tracking Output/combined.csv')\n",
    "n_participants = len(pd.unique(df['Participant']))\n",
    "print(\"dataset has\", n_participants, \"unique participants\")\n",
    "\n",
    "# NOTE ved fandeme ikke lige hvorfor den siger, der er 91 unique participants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_97442/2136264761.py:4: DtypeWarning: Columns (7,12,14,15,16,19,20,21,22,26,27,28,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_97442/2136264761.py:7: FutureWarning: In a future version of pandas all arguments of StringMethods.rsplit except for the argument 'pat' will be keyword-only.\n",
      "  df['Time of Day [h:m:s:ms]'] = df['Time of Day [h:m:s:ms]'].str.rsplit(':', 1).str.join('.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data cleaning completed and saved to ../data/Eye-tracking Output/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "## Cleaning the data ## \n",
    "# Load the main dataset\n",
    "file_path = '../data/Eye-tracking Output/combined.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Replace the last colon with a period to properly format the milliseconds\n",
    "df['Time of Day [h:m:s:ms]'] = df['Time of Day [h:m:s:ms]'].str.rsplit(':', 1).str.join('.')\n",
    "\n",
    "# Convert \"Time of Day [h:m:s:ms]\" to timedelta\n",
    "df['Time of Day [h:m:s:ms]'] = pd.to_timedelta(df['Time of Day [h:m:s:ms]'])\n",
    "\n",
    "# Sort by \"Participant\", \"Trial\", and \"Stimulus\"\n",
    "df.sort_values(by=['Participant', 'Trial', 'Stimulus'], inplace=True)\n",
    "\n",
    "# Subtract the first time for each group from all the times in that group\n",
    "df['Time.s'] = df.groupby(['Participant', 'Trial', 'Stimulus'])['Time of Day [h:m:s:ms]'].transform(lambda x: x - x.iloc[0])\n",
    "\n",
    "df['Time.s'] = df['Time.s'].apply(lambda x: x.total_seconds())\n",
    "\n",
    "\n",
    "# Keep only relevant columns\n",
    "relevant_columns = [\n",
    "    'Participant', 'Trial', 'Stimulus', 'Time.s', 'RecordingTime [ms]',\n",
    "    'Export Start Trial Time [ms]', 'Export End Trial Time [ms]',\n",
    "    'Point of Regard Left X [px]', 'Point of Regard Left Y [px]',\n",
    "    'Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "    'Pupil Diameter Left [mm]', 'Pupil Diameter Right [mm]',\n",
    "    'Tracking Ratio [%]', 'Category Left', 'Category Right'\n",
    "]\n",
    "df = df[relevant_columns]\n",
    "\n",
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Remove unidentified participants\n",
    "df = df[~df['Participant'].isin([\"Unidentified(Neg)\", \"Unidentified(Pos)\"])]\n",
    "\n",
    "# Convert 'Participant' to numeric if necessary\n",
    "df['Participant'] = pd.to_numeric(df['Participant'], errors='coerce')\n",
    "\n",
    "# Load the metadata\n",
    "df_metadata = pd.read_csv('../data/Metadata_Participants.csv')\n",
    "\n",
    "# Merge the metadata with the main dataframe\n",
    "df = pd.merge(df, df_metadata, left_on='Participant', right_on='ParticipantID', how='left')\n",
    "\n",
    "# Drop the 'ParticipantID' column\n",
    "df.drop('ParticipantID', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Save the cleaned data\n",
    "output_file = '../data/Eye-tracking Output/cleaned_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(\"Data cleaning completed and saved to\", output_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
