{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "from tensorflow.keras.layers import Embedding, Flatten, LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Load the data\u001b[39;00m\n\u001b[1;32m      2\u001b[0m data_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m../data/Eye-tracking Output/cleaned_data.csv\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(data_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Load the data\n",
    "data_path = \"../data/Eye-tracking Output/cleaned_data.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['Age'].fillna(0, inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant.fillna(method='bfill', inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n"
     ]
    }
   ],
   "source": [
    "## Normalizing data ##\n",
    "\n",
    "# Feature selection of relevant columns\n",
    "relevant_columns = ['Participant', 'Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "                    'Tracking Ratio [%]', 'Category Right',\n",
    "                    'Stimulus', 'Gender', 'Age', 'Class', 'Trial', 'Pupil Diameter Right [mm]', 'Time.s']\n",
    "\n",
    "df_relevant = df[relevant_columns]\n",
    "\n",
    "# Filling NaNs in 'CARS Score' with 0\n",
    "df_relevant['Age'].fillna(0, inplace=True)\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]', 'Pupil Diameter Right [mm]', 'Time.s'\n",
    "                     ] # Lidt i tvivl om vi skal have 'Age' med her. CARS og Age giver ogs√• 0. Pis lort\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
    "\n",
    "# Define a function to fill NaN with the mean of the previous and next row\n",
    "def fill_with_row_mean(df_relevant, col):\n",
    "    # First, forward fill the first NaN (if any)\n",
    "    df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
    "    \n",
    "    # Then, fill the rest with the mean of the previous and next row\n",
    "    df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
    "    \n",
    "    return df_relevant[col]\n",
    "\n",
    "# Apply this function to each numerical column\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
    "\n",
    "# Handle any remaining NaNs, especially at the end of the DataFrame\n",
    "df_relevant.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize data per combination of Trial, Participant, and Stimulus\n",
    "for (trial, participant, stimulus), group_data in df_relevant.groupby(['Trial', 'Participant', 'Stimulus']):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Apply the scaler to all numerical columns for this group\n",
    "    df_relevant.loc[group_data.index, numerical_columns] = scaler.fit_transform(group_data[numerical_columns])\n",
    "\n",
    "# For some reason Age and CARS Score are not scaled properly, so we do it manually\n",
    "scaler = MinMaxScaler()\n",
    "df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n",
    "\n",
    "# Save the normalized data\n",
    "df_relevant.to_csv(\"../data/Eye-tracking Output/normalized_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant = pd.read_csv(\"../data/Eye-tracking Output/normalized_data.csv\")\n",
    "# Label encoding for participant, subject, and trial. \n",
    "# Input dimensions are the number of unique values in each column and output is the square root of the input\n",
    "# embeddings = []\n",
    "# inputs = ['Stimulus', 'Trial']\n",
    "# input_dims = [114, 34]\n",
    "# output_dims = [11, 7]\n",
    "\n",
    "# for input_name, input_dim, output_dim in zip(inputs, input_dims, output_dims):\n",
    "#     le = LabelEncoder()\n",
    "#     df_relevant[input_name] = le.fit_transform(df_relevant[input_name])\n",
    "    \n",
    "#     input_layer = Input(shape=(1,))\n",
    "#     embedding_layer = Embedding(input_dim=input_dim, output_dim=output_dim)(input_layer)\n",
    "    \n",
    "#     embeddings.append(embedding_layer)\n",
    "\n",
    "# # Concatenate embeddings\n",
    "# concatenated = Concatenate()(embeddings)\n",
    "\n",
    "# # print(df_relevant['Stimulus'].unique())\n",
    "# print(concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  dtype:  float32\n",
      "Point of Regard Right X [px]  dtype:  float32\n",
      "Point of Regard Right Y [px]  dtype:  float32\n",
      "Tracking Ratio [%]  dtype:  float32\n",
      "Gender  dtype:  float32\n",
      "Age  dtype:  float32\n",
      "Class  dtype:  float32\n",
      "Trial  dtype:  object\n",
      "Pupil Diameter Right [mm]  dtype:  float32\n",
      "Time.s  dtype:  float32\n",
      "Category Right_-  dtype:  float32\n",
      "Category Right_Blink  dtype:  float32\n",
      "Category Right_Fixation  dtype:  float32\n",
      "Category Right_Saccade  dtype:  float32\n",
      "Category Right_Separator  dtype:  float32\n",
      "Stimulus_01 coucou g.jpg  dtype:  float32\n",
      "Stimulus_01 neutre3.avi  dtype:  float32\n",
      "Stimulus_01vnvg151201b1.avi  dtype:  float32\n",
      "Stimulus_02 coucou d.jpg  dtype:  float32\n",
      "Stimulus_02 devant.jpg  dtype:  float32\n",
      "Stimulus_02 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_03 devant.jpg  dtype:  float32\n",
      "Stimulus_03 regard chien g.jpg  dtype:  float32\n",
      "Stimulus_03 vole triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_04 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_04 regard chien d.jpg  dtype:  float32\n",
      "Stimulus_04 tete chien g.jpg  dtype:  float32\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi  dtype:  float32\n",
      "Stimulus_05 tete chien d.jpg  dtype:  float32\n",
      "Stimulus_05 tete point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_06 devant point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 tete point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant.jpg  dtype:  float32\n",
      "Stimulus_07 tombe joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_08 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_08 devant.jpg  dtype:  float32\n",
      "Stimulus_08 voc chien g.jpg  dtype:  float32\n",
      "Stimulus_09 cadeau dernier1.avi  dtype:  float32\n",
      "Stimulus_09 voc chien d.jpg  dtype:  float32\n",
      "Stimulus_09 voc devant g.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.png  dtype:  float32\n",
      "Stimulus_10 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_10 voc devant.jpg  dtype:  float32\n",
      "Stimulus_11 devant.jpg  dtype:  float32\n",
      "Stimulus_11 punition orale triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_11 yeux chat G.png  dtype:  float32\n",
      "Stimulus_11 yeux chat d.jpg  dtype:  float32\n",
      "Stimulus_11 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat G.png  dtype:  float32\n",
      "Stimulus_12 tete chat droite.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 bonbons triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_13 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat G.png  dtype:  float32\n",
      "Stimulus_13 tete pointage chat droite.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat G.png  dtype:  float32\n",
      "Stimulus_14 devant point chat droite.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_15 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant.jpg  dtype:  float32\n",
      "Stimulus_15 devant.png  dtype:  float32\n",
      "Stimulus_16 devant.jpg  dtype:  float32\n",
      "Stimulus_16 voc chat G.png  dtype:  float32\n",
      "Stimulus_16 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_16 voc droite chat.jpg  dtype:  float32\n",
      "Stimulus_17 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant G.png  dtype:  float32\n",
      "Stimulus_17 voc devant d.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.png  dtype:  float32\n",
      "Stimulus_18 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_18 voc devant.jpg  dtype:  float32\n",
      "Stimulus_19 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_2 devant.jpg  dtype:  float32\n",
      "Stimulus_2 devant.png  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_21 neutre4.avi  dtype:  float32\n",
      "Stimulus_21 neutre5.avi  dtype:  float32\n",
      "Stimulus_22 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_23 bonbons triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_23 vole triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_24 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_24 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_25 punition orale triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi  dtype:  float32\n",
      "Stimulus_26 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_26 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_27 cadeau dernier2.avi  dtype:  float32\n",
      "Stimulus_27 tombe joie vs triste5.avi  dtype:  float32\n",
      "Stimulus_28 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_29 tombe joie vs triste3.avi  dtype:  float32\n",
      "Stimulus_3 regard chien D.jpg  dtype:  float32\n",
      "Stimulus_3 regard chien D.png  dtype:  float32\n",
      "Stimulus_30 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_31 punition orale triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_32 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_33 vole triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_34 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.png  dtype:  float32\n",
      "Stimulus_5 tete point chien D.jpg  dtype:  float32\n",
      "Stimulus_5 tete point chien D.png  dtype:  float32\n",
      "Stimulus_6 devant point chien D.jpg  dtype:  float32\n",
      "Stimulus_6 devant point chien D.png  dtype:  float32\n",
      "Stimulus_7 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_7 devant.png  dtype:  float32\n",
      "Stimulus_8 voc chien D.jpg  dtype:  float32\n",
      "Stimulus_8 voc chien D.png  dtype:  float32\n",
      "Stimulus_9 voc devant D.png  dtype:  float32\n",
      "Stimulus_9 voc devant.jpg  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi  dtype:  float32\n",
      "Stimulus_NoImage  dtype:  float32\n",
      "Stimulus_VNVD151207.avi  dtype:  float32\n",
      "Stimulus_VNVG151201b.avi  dtype:  float32\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi  dtype:  float32\n"
     ]
    }
   ],
   "source": [
    "# checking the variables to convert into dummy variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for column in df_relevant.columns:\n",
    "#     print(column, \" dtype: \", df_relevant.dtypes[column])\n",
    "    # if df_relevant.dtypes[column] == \"object\":\n",
    "    #     print(column)\n",
    "\n",
    "# print(df_relevant[\"Gender\"].unique())\n",
    "# print(df_relevant[\"Category Left\"].unique())\n",
    "# print(df_relevant[\"Category Right\"].unique())\n",
    "# print(df_relevant[\"Trial\"].unique())\n",
    "# print(df_relevant[\"Stimulus\"].unique())\n",
    "\n",
    "\n",
    "#print(df_relevant[\"Gender\"].unique())\n",
    "le_gen = LabelEncoder()\n",
    "df_relevant['Gender'] = le_gen.fit_transform(df_relevant['Gender']) # M, F\n",
    "\n",
    "\n",
    "le_class = LabelEncoder()\n",
    "df_relevant['Class'] = le_class.fit_transform(df_relevant['Class']) # ASD, TD\n",
    "\n",
    "\n",
    "# Assuming 'Category' is your categorical variable in a DataFrame df\n",
    "df_encoded = pd.get_dummies(df_relevant, columns=['Category Right', 'Stimulus'], prefix=['Category Right', 'Stimulus']) # one hot encoding\n",
    "\n",
    "# print(df_encoded.iloc[:, 16:22].head(5)) # checking how it looks.\n",
    "\n",
    "for column in df_encoded.columns: #convert int64 into float64 so network it expects the same value\n",
    "    if df_encoded.dtypes[column] == \"int64\" or df_encoded.dtypes[column] == \"uint8\" or df_encoded.dtypes[column] == \"float64\":\n",
    "        df_encoded[column] = df_encoded[column].astype('float32')\n",
    "\n",
    "for column in df_encoded.columns:\n",
    "    print(column, \" dtype: \", df_encoded.dtypes[column])\n",
    "#print(df_relevant[\"Class\"].unique())\n",
    "#print(df_relevant['Participant'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tror ikke vi skal bruge den her\n",
    "\n",
    "# # Save only the normalized columns into a new DataFrame\n",
    "# normalized_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "#                       'Tracking Ratio [%]',\n",
    "#                       'CARS Score', 'Age']\n",
    "# df_normalized = df_relevant[normalized_columns]\n",
    "\n",
    "\n",
    "# # Combining all data into a single tensor\n",
    "# # reshaping the normalized data into 3d np array\n",
    "# normalized_np = np.stack([df_normalized[col].values for col in df_normalized.columns], 1)\n",
    "# # converting from np array to keras tensors\n",
    "# normalized_tensor = tf.convert_to_tensor(normalized_np, dtype=tf.float32)\n",
    "\n",
    "# # Add a dimension to normalized_tensor and df_encoded\n",
    "# # This transforms them from shape (905519, 7) and (905519, 19) to (905519, 1, 7) and (905519, 1, 19)\n",
    "# normalized_tensor_3d = tf.expand_dims(normalized_tensor, axis=1)\n",
    "# df_encoded_3d = tf.expand_dims(df_encoded, axis=1)\n",
    "\n",
    "# # Now you can concatenate along the last axis\n",
    "# df_all = tf.keras.layers.Concatenate(axis=-1)([normalized_tensor_3d, df_encoded_3d, concatenated])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split. inf√∏r ogs√• evt padding\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def train_test(df):\n",
    "    # Extract the unique participant IDs\n",
    "    participant_ids = df['Participant'].unique()\n",
    "\n",
    "    # Split participant IDs into train and test sets\n",
    "    train_participant_ids, test_participant_ids = train_test_split(participant_ids, test_size=0.34, random_state=1)\n",
    "\n",
    "    # Filter data based on participant IDs\n",
    "    train_data = df_encoded[np.isin(df_encoded['Participant'], train_participant_ids)]\n",
    "    test_data = df_encoded[np.isin(df_encoded['Participant'], test_participant_ids)]\n",
    "\n",
    "    test_data_participants = test_data['Participant']\n",
    "\n",
    "    # Extract 'Class' column index dynamically and \n",
    "    class_column_index = df_encoded.columns.get_loc('Class')\n",
    "    participant_column_index = df_encoded.columns.get_loc('Participant')\n",
    "\n",
    "\n",
    "    # Extract 'Class' values for train and test\n",
    "    train_labels = train_data.iloc[:, class_column_index].values\n",
    "    test_labels = test_data.iloc[:, class_column_index].values\n",
    "\n",
    "\n",
    "    train_labels = pd.get_dummies(train_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "    test_labels = pd.get_dummies(test_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "\n",
    "\n",
    "    # Drop the 'Class' and 'Participant' column from the data\n",
    "    train_data = train_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "    test_data = test_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "\n",
    "    return train_data, test_data, train_labels, test_labels, test_data_participants, participant_column_index\n",
    "\n",
    "\n",
    "train_data, test_data, train_labels, test_labels, test_data_participants, participant_column_index = train_test(df_encoded)\n",
    "\n",
    "# Convert data into tensors with 60 samples each\n",
    "def create_tensors(data, labels, samples_per_tensor=60):\n",
    "    num_tensors = len(data) // samples_per_tensor\n",
    "    data_tensors = np.array_split(data[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    labels_tensors = np.array_split(labels[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    return np.stack(data_tensors), np.stack(labels_tensors) #, np.expand_dims(np.stack(labels_tensors), axis=-1)\n",
    "\n",
    "train_data_tensors, train_label_tensors = create_tensors(train_data.values, train_labels)\n",
    "test_data_tensors, test_label_tensors = create_tensors(test_data.values, test_labels)\n",
    "\n",
    "test_data_participants_tensor, lol = create_tensors(test_data_participants.values, test_labels)\n",
    "\n",
    "# checking if everythin looks good\n",
    "# print(train_data_tensors.shape)\n",
    "# print(test_data_tensors.shape)\n",
    "# print(train_label_tensors.shape)\n",
    "# print(test_label_tensors.shape)\n",
    "\n",
    "# #checking up on my data before feeding it to network.\n",
    "# for i in train_data.columns:\n",
    "#     print(i, train_data.dtypes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 120, 126)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "indices = torch.randperm(len(train_data_tensors))[:200]\n",
    "\n",
    "lort = train_data_tensors[indices] # making a subset of 200\n",
    "\n",
    "lort.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 411/1019 [===========>..................] - ETA: 7s - loss: 0.4266 - accuracy: 0.8009"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[39mreturn\u001b[39;00m model\n\u001b[1;32m     26\u001b[0m model \u001b[39m=\u001b[39m classification_model()\n\u001b[0;32m---> 28\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_data_tensors, train_label_tensors, epochs \u001b[39m=\u001b[39;49m \u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m \u001b[39m10\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m (test_data_tensors, test_label_tensors))\n\u001b[1;32m     31\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m'\u001b[39m\u001b[39mmodelus1.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[39m# Saving the history of the model\u001b[39;00m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     66\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/keras/src/engine/training.py:1783\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1776\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1777\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1780\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1783\u001b[0m     tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1784\u001b[0m     \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1785\u001b[0m         context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:867\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    864\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    865\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    866\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 867\u001b[0m   \u001b[39mreturn\u001b[39;00m tracing_compilation\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    868\u001b[0m       args, kwds, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_no_variable_creation_config\n\u001b[1;32m    869\u001b[0m   )\n\u001b[1;32m    870\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_variable_creation_config \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    871\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    872\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mbind(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[39mreturn\u001b[39;00m function\u001b[39m.\u001b[39;49m_call_flat(  \u001b[39m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m     flat_inputs, captured_inputs\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mcaptured_inputs\n\u001b[1;32m    141\u001b[0m )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mflat_call(args)\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mflat_call\u001b[39m(\u001b[39mself\u001b[39m, args: Sequence[core\u001b[39m.\u001b[39mTensor]) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[39m  \u001b[39m\u001b[39m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m(\u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    218\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfunction_type\u001b[39m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[39mwith\u001b[39;00m record\u001b[39m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_bound_context\u001b[39m.\u001b[39;49mcall_function(\n\u001b[1;32m    253\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mname,\n\u001b[1;32m    254\u001b[0m         \u001b[39mlist\u001b[39;49m(args),\n\u001b[1;32m    255\u001b[0m         \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfunction_type\u001b[39m.\u001b[39;49mflat_outputs),\n\u001b[1;32m    256\u001b[0m     )\n\u001b[1;32m    257\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[39m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[39mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[39mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_bound_context\u001b[39m.\u001b[39mfunction_call_options\u001b[39m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[39m=\u001b[39m cancellation\u001b[39m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m cancellation_context \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m   1480\u001b[0m       name\u001b[39m.\u001b[39;49mdecode(\u001b[39m\"\u001b[39;49m\u001b[39mutf-8\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1481\u001b[0m       num_outputs\u001b[39m=\u001b[39;49mnum_outputs,\n\u001b[1;32m   1482\u001b[0m       inputs\u001b[39m=\u001b[39;49mtensor_inputs,\n\u001b[1;32m   1483\u001b[0m       attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m   1484\u001b[0m       ctx\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m,\n\u001b[1;32m   1485\u001b[0m   )\n\u001b[1;32m   1486\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf-8\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[39m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[39m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[39m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[39m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[39m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, core_types\u001b[39m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[39melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     61\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     62\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Define the LSTM model\n",
    "\n",
    "input_shape = (60, 126)\n",
    "dropout = 0.2\n",
    "learning_rate = 0.0004\n",
    "\n",
    "\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an LSTM layer with, for example, 50 units\n",
    "    model.add(LSTM(units=70, input_shape=input_shape, return_sequences=True))\n",
    "\n",
    "    # Add a Dense layer with the number of classes as the output dimension and activation function\n",
    "    model.add(Dense(units=50))\n",
    "\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Compile the model with an optimizer, loss function, and metrics\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = classification_model()\n",
    "\n",
    "history = model.fit(train_data_tensors, train_label_tensors, epochs = 5, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "\n",
    "model.save('modelus1.h5')\n",
    "\n",
    "# Saving the history of the model\n",
    "import pickle\n",
    "\n",
    "with open('modelus1_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "    \n",
    "\n",
    "# Display a summary of the model's architecture\n",
    "model.summary()\n",
    "\n",
    "preds = model.predict(test_data_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir1/helloworld1/tuner0.json\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "100               |70                |units\n",
      "50                |50                |additional_units\n",
      "0.35              |0.05              |dropout\n",
      "0.0036991         |0.00010296        |learning_rate\n",
      "\n",
      "Epoch 1/5\n",
      "194/928 [=====>........................] - ETA: 11s - loss: 0.4956 - accuracy: 0.7818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 36\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkerastuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomSearch\n\u001b[1;32m     28\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[1;32m     29\u001b[0m     MyHyperModel(),\n\u001b[1;32m     30\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dir1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelloworld1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m best_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_modelus1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hypertuning the model\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "\n",
    "num_classes = 2  # Define the number of classes\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.LSTM(\n",
    "            units=hp.Int('units', min_value=30, max_value=100, step=10),\n",
    "            input_shape=(60, 126), return_sequences=True))\n",
    "        model.add(keras.layers.Dense(\n",
    "            units=hp.Int('additional_units', min_value=20, max_value=50, step=10),\n",
    "            activation='relu'))  # Additional hidden layer\n",
    "        model.add(keras.layers.Dropout(\n",
    "            rate=hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.25, step=0.05)))\n",
    "        model.add(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir1',\n",
    "    project_name='helloworld1')\n",
    "\n",
    "tuner.search(train_data_tensors, train_label_tensors, epochs = 5, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.save('best_modelus1.h5')\n",
    "\n",
    "# Saving the history of the model\n",
    "history=best_model.history\n",
    "with open('best_modelus1_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m model \u001b[39m=\u001b[39m load_model(\u001b[39m'\u001b[39m\u001b[39mbest_modelus1.h5\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[39m# MODELLENS HISTORIK SKAL LOADS IND HER\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[39mprint\u001b[39m(history\u001b[39m.\u001b[39mhistory\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m      7\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m      8\u001b[0m plt\u001b[39m.\u001b[39mplot(history\u001b[39m.\u001b[39mhistory[\u001b[39m'\u001b[39m\u001b[39mval_accuracy\u001b[39m\u001b[39m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "# Plotting to see if the model is overfitting\n",
    "model = load_model('best_modelus1.h5')\n",
    "\n",
    "# MODELLENS HISTORIK SKAL LOADS IND HER\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n",
      "163/163 [==============================] - 1s 7ms/step\n",
      "(5191, 60, 2)\n",
      "(5191, 60, 2)\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_modelus1.h5')\n",
    "preds = model.predict(test_data_tensors)\n",
    "\n",
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "# Assuming preds is the output of model.predict\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming preds is the output of model.predict\n",
    "predicted_class_labels = preds.argmax(axis=-1)\n",
    "predicted_class_labels_df = pd.DataFrame({'Predicted_Class': predicted_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "# Print the first 50 rows\n",
    "#print(predicted_class_labels_df.head(50))\n",
    "\n",
    "true_class_labels = test_label_tensors.argmax(axis=-1)\n",
    "true_class_labels_df = pd.DataFrame({'Predicted_Class': true_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "#print(true_class_labels_df[0:10])\n",
    "\n",
    "\n",
    "# for i in predicted_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "# for i in true_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "# ### making a prediction function based on models guesses.\n",
    "# # print(preds.shape)\n",
    "# dol = pd.DataFrame(test_data_participants_tensor)\n",
    "# dol[\"Name\"] = dol[1]\n",
    "# dol = dol.astype(object)\n",
    "\n",
    "# unique_indices = dol.drop_duplicates(subset=\"Name\").index.tolist()\n",
    "\n",
    "# unique_indices.append(len(dol)) #appending last index\n",
    "\n",
    "# true_df_list = []\n",
    "# pred_df_list = []\n",
    "\n",
    "# for i in range(len(unique_indices)-1): #segment data\n",
    "#     if i == unique_indices[-1]:\n",
    "#         break\n",
    "#     start_index = unique_indices[i]\n",
    "#     end_index = unique_indices[i + 1]\n",
    "\n",
    "#     # print(start_index, end_index)\n",
    "\n",
    "#     true_list = true_class_labels_df[start_index: end_index]\n",
    "#     pred_list = predicted_class_labels_df[start_index: end_index]\n",
    "\n",
    "#     true_df_list.append(true_list)\n",
    "#     pred_df_list.append(pred_list)\n",
    "\n",
    "# pred_list = []\n",
    "# true_list = []\n",
    "\n",
    "# #now for the prediction:\n",
    "# for df in pred_df_list:\n",
    "#     avg = sum(df['Predicted_Class'])/len(df)\n",
    "#     if avg <= 0.5:\n",
    "#         pred = 1\n",
    "#     elif avg > 0.5:\n",
    "#         pred = 0\n",
    "#     pred_list.append(pred)\n",
    "\n",
    "# for df in true_df_list:\n",
    "#     avg = sum(df['Predicted_Class'])/len(df)\n",
    "#     if avg <= 0.5:\n",
    "#         pred1 = 1\n",
    "#     elif avg > 0.5:\n",
    "#         pred1 = 0\n",
    "#     true_list.append(pred1)\n",
    "\n",
    "\n",
    "# print(pred_list)\n",
    "# print(true_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    }
   ],
   "source": [
    "#making a prediction function based on sum of outputs\n",
    "\n",
    "from keras.models import load_model\n",
    "import pandas as pd\n",
    "model = load_model('best_modelus1.h5')\n",
    "\n",
    "def sum_prediction(model, test_data_tensors1, test_data_participants_tensor1, test_label_tensors1):\n",
    "    preds = model.predict(test_data_tensors1)\n",
    "\n",
    "    #finding the indexes of the each persons data\n",
    "    dol = pd.DataFrame(test_data_participants_tensor1)\n",
    "    dol[\"Name\"] = dol[1]\n",
    "    dol = dol.astype(object)\n",
    "\n",
    "    unique_indices = dol.drop_duplicates(subset=\"Name\").index.tolist()\n",
    "\n",
    "    unique_indices.append(len(dol)) #appending last index\n",
    "        \n",
    "    predictions = pd.DataFrame(preds[:, -1, :])\n",
    "    test_label = pd.DataFrame(test_label_tensors1[:, -1, :])\n",
    "\n",
    "    #defining df lists\n",
    "    true_df_list = []\n",
    "    predict_df_list = []\n",
    "\n",
    "\n",
    "    for i in range(len(unique_indices)-1): #segment data\n",
    "        if i == unique_indices[-1]:\n",
    "                break\n",
    "        start_index = unique_indices[i]\n",
    "        end_index = unique_indices[i + 1]\n",
    "\n",
    "        # print(start_index, end_index)\n",
    "\n",
    "        true_list = test_label[start_index: end_index]\n",
    "        pred_list = predictions[start_index: end_index]\n",
    "\n",
    "        true_df_list.append(true_list)\n",
    "        predict_df_list .append(pred_list)\n",
    "\n",
    "\n",
    "        # now for predictions\n",
    "\n",
    "\n",
    "    final_predictions = []\n",
    "    true_list = []\n",
    "\n",
    "    for i in predict_df_list:\n",
    "        sum_0 = sum(i[0])\n",
    "        sum_1 = sum(i[1])\n",
    "        if sum_0 > sum_1:\n",
    "            final_predictions.append(1)\n",
    "        else:\n",
    "            final_predictions.append(0)\n",
    "\n",
    "\n",
    "\n",
    "    for df in true_df_list:\n",
    "        sum_2 = sum(df[0])\n",
    "        sum_3 = sum(df[1])\n",
    "\n",
    "        if sum_2 > sum_3:\n",
    "            true_list.append(1)\n",
    "        else:\n",
    "            true_list.append(0)\n",
    "            \n",
    "    return true_list, final_predictions\n",
    "\n",
    "\n",
    "# sum_prediction(model, test_data_tensors, test_data_participants_tensor, test_label_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting a ROC curve\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming preds is the output of model.predict\n",
    "fpr, tpr, _ = roc_curve(true_list, final_predictions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2,\n",
    "        label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # random predictions curve\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate or (1 - Specifity)')\n",
    "plt.ylabel('True Positive Rate or (Sensitivity)')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'true_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Flipping results so that 1 is ASD and 0 is TD\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m true_list \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m true_list]\n\u001b[1;32m      6\u001b[0m final_predictions \u001b[39m=\u001b[39m [\u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m i \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m final_predictions]\n\u001b[1;32m      9\u001b[0m sns\u001b[39m.\u001b[39mheatmap(confusion_matrix(true_list, final_predictions), annot\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, cmap\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mBlues\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'true_list' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualizing the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "# Flipping results so that 1 is ASD and 0 is TD\n",
    "true_list = [1 if i == 0 else 0 for i in true_list]\n",
    "final_predictions = [1 if i == 0 else 0 for i in final_predictions]\n",
    "\n",
    "\n",
    "sns.heatmap(confusion_matrix(true_list, final_predictions), annot=True, cmap='Blues')\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(true_list, final_predictions))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1:\n",
      "\n",
      "Train Data Shape: (5572, 120, 126)\n",
      "Train Labels Shape: (5572, 120, 2)\n",
      "Test Data Shape: (1973, 120, 126)\n",
      "Test Labels Shape: (1973, 120, 2)\n",
      "Test Participants Data Shape: (1973, 120)\n",
      "Epoch 1/5\n",
      "558/558 [==============================] - 19s 32ms/step - loss: 0.7988 - accuracy: 0.7708 - val_loss: 0.5858 - val_accuracy: 0.6921\n",
      "Epoch 2/5\n",
      "558/558 [==============================] - 17s 31ms/step - loss: 0.7143 - accuracy: 0.8232 - val_loss: 0.5936 - val_accuracy: 0.7106\n",
      "Epoch 3/5\n",
      "558/558 [==============================] - 18s 31ms/step - loss: 0.6919 - accuracy: 0.8329 - val_loss: 0.6073 - val_accuracy: 0.7215\n",
      "Epoch 4/5\n",
      "558/558 [==============================] - 17s 31ms/step - loss: 0.6757 - accuracy: 0.8413 - val_loss: 0.6729 - val_accuracy: 0.7139\n",
      "62/62 [==============================] - 1s 17ms/step\n",
      "Accuracy: 0.9167, F1 Score: 0.8889, Sensitivity: 1.0000, Specificity: 0.8750\n",
      "\n",
      "Fold 2:\n",
      "\n",
      "Train Data Shape: (5959, 120, 126)\n",
      "Train Labels Shape: (5959, 120, 2)\n",
      "Test Data Shape: (1586, 120, 126)\n",
      "Test Labels Shape: (1586, 120, 2)\n",
      "Test Participants Data Shape: (1586, 120)\n",
      "Epoch 1/5\n",
      "596/596 [==============================] - 20s 31ms/step - loss: 0.8064 - accuracy: 0.7606 - val_loss: 0.6646 - val_accuracy: 0.6878\n",
      "Epoch 2/5\n",
      "596/596 [==============================] - 18s 31ms/step - loss: 0.7177 - accuracy: 0.8137 - val_loss: 0.7129 - val_accuracy: 0.6940\n",
      "Epoch 3/5\n",
      "596/596 [==============================] - 19s 31ms/step - loss: 0.6996 - accuracy: 0.8228 - val_loss: 0.7084 - val_accuracy: 0.7184\n",
      "Epoch 4/5\n",
      "596/596 [==============================] - 18s 31ms/step - loss: 0.6895 - accuracy: 0.8272 - val_loss: 0.6821 - val_accuracy: 0.6999\n",
      "50/50 [==============================] - 1s 17ms/step\n",
      "Accuracy: 0.7273, F1 Score: 0.7273, Sensitivity: 0.6667, Specificity: 0.8000\n",
      "\n",
      "Fold 3:\n",
      "\n",
      "Train Data Shape: (6224, 120, 126)\n",
      "Train Labels Shape: (6224, 120, 2)\n",
      "Test Data Shape: (1321, 120, 126)\n",
      "Test Labels Shape: (1321, 120, 2)\n",
      "Test Participants Data Shape: (1321, 120)\n",
      "Epoch 1/5\n",
      "623/623 [==============================] - 20s 31ms/step - loss: 0.8713 - accuracy: 0.7253 - val_loss: 0.3304 - val_accuracy: 0.8405\n",
      "Epoch 2/5\n",
      "623/623 [==============================] - 19s 30ms/step - loss: 0.7994 - accuracy: 0.7907 - val_loss: 0.3457 - val_accuracy: 0.8388\n",
      "Epoch 3/5\n",
      "623/623 [==============================] - 19s 30ms/step - loss: 0.7681 - accuracy: 0.8026 - val_loss: 0.3604 - val_accuracy: 0.8275\n",
      "Epoch 4/5\n",
      "623/623 [==============================] - 19s 30ms/step - loss: 0.7556 - accuracy: 0.8076 - val_loss: 0.3594 - val_accuracy: 0.8238\n",
      "42/42 [==============================] - 1s 17ms/step\n",
      "Accuracy: 0.8182, F1 Score: 0.8750, Sensitivity: 1.0000, Specificity: 0.5000\n",
      "\n",
      "Fold 4:\n",
      "\n",
      "Train Data Shape: (6298, 120, 126)\n",
      "Train Labels Shape: (6298, 120, 2)\n",
      "Test Data Shape: (1247, 120, 126)\n",
      "Test Labels Shape: (1247, 120, 2)\n",
      "Test Participants Data Shape: (1247, 120)\n",
      "Epoch 1/5\n",
      "630/630 [==============================] - 20s 31ms/step - loss: 0.8447 - accuracy: 0.7438 - val_loss: 0.3689 - val_accuracy: 0.8459\n",
      "Epoch 2/5\n",
      "630/630 [==============================] - 19s 30ms/step - loss: 0.7679 - accuracy: 0.7961 - val_loss: 0.3463 - val_accuracy: 0.8582\n",
      "Epoch 3/5\n",
      "630/630 [==============================] - 19s 29ms/step - loss: 0.7579 - accuracy: 0.8005 - val_loss: 0.3501 - val_accuracy: 0.8566\n",
      "Epoch 4/5\n",
      "630/630 [==============================] - 19s 30ms/step - loss: 0.7497 - accuracy: 0.7995 - val_loss: 0.3482 - val_accuracy: 0.8530\n",
      "Epoch 5/5\n",
      "630/630 [==============================] - 19s 30ms/step - loss: 0.7359 - accuracy: 0.8039 - val_loss: 0.3453 - val_accuracy: 0.8581\n",
      "39/39 [==============================] - 1s 17ms/step\n",
      "Accuracy: 0.8182, F1 Score: 0.8333, Sensitivity: 0.8333, Specificity: 0.8000\n",
      "\n",
      "Fold 5:\n",
      "\n",
      "Train Data Shape: (6129, 120, 126)\n",
      "Train Labels Shape: (6129, 120, 2)\n",
      "Test Data Shape: (1416, 120, 126)\n",
      "Test Labels Shape: (1416, 120, 2)\n",
      "Test Participants Data Shape: (1416, 120)\n",
      "Epoch 1/5\n",
      "613/613 [==============================] - 20s 30ms/step - loss: 0.8372 - accuracy: 0.7441 - val_loss: 0.4067 - val_accuracy: 0.8489\n",
      "Epoch 2/5\n",
      "613/613 [==============================] - 18s 30ms/step - loss: 0.7692 - accuracy: 0.7899 - val_loss: 0.3629 - val_accuracy: 0.9121\n",
      "Epoch 3/5\n",
      "613/613 [==============================] - 18s 30ms/step - loss: 0.7368 - accuracy: 0.8036 - val_loss: 0.4744 - val_accuracy: 0.8239\n",
      "Epoch 4/5\n",
      "613/613 [==============================] - 18s 30ms/step - loss: 0.7377 - accuracy: 0.8003 - val_loss: 0.5237 - val_accuracy: 0.7938\n",
      "Epoch 5/5\n",
      "613/613 [==============================] - 19s 30ms/step - loss: 0.7106 - accuracy: 0.8140 - val_loss: 0.6004 - val_accuracy: 0.7944\n",
      "45/45 [==============================] - 1s 17ms/step\n",
      "Accuracy: 0.9091, F1 Score: 0.9231, Sensitivity: 1.0000, Specificity: 0.8000\n",
      "\n",
      "Aggregated Results:\n",
      "Mean Accuracy: 0.8379\n",
      "Mean F1 Score: 0.8495\n",
      "Mean Sensitivity: 0.9000\n",
      "Mean Specificity: 0.7550\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "# Your create_tensors function\n",
    "def create_tensors(data, labels, samples_per_tensor=120):\n",
    "    num_tensors = len(data) // samples_per_tensor\n",
    "    data_tensors = np.array_split(data[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    labels_tensors = np.array_split(labels[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    return np.stack(data_tensors), np.stack(labels_tensors)\n",
    "\n",
    "# Your classification model\n",
    "\n",
    "def classification_model(input_shape=(120, 126)):\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(units=90, input_shape=input_shape, return_sequences=True))\n",
    "    model.add(Dense(units=50))\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "    model.add(tf.keras.layers.Dropout(rate=0.05))\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "# Your k_fold_cross_validation function\n",
    "def k_fold_cross_validation(df, k=5, samples_per_tensor=120, random_state=None):\n",
    "    participant_ids = df['Participant'].unique()\n",
    "    kf = KFold(n_splits=k, shuffle=True, random_state=random_state)\n",
    "\n",
    "    for train_index, test_index in kf.split(participant_ids):\n",
    "        train_participant_ids = participant_ids[train_index]\n",
    "        test_participant_ids = participant_ids[test_index]\n",
    "\n",
    "        train_data = df[np.isin(df['Participant'], train_participant_ids)]\n",
    "        test_data = df[np.isin(df['Participant'], test_participant_ids)]\n",
    "\n",
    "        test_data_participants = test_data['Participant']\n",
    "\n",
    "        class_column_index = df.columns.get_loc('Class')\n",
    "\n",
    "        train_labels = train_data.iloc[:, class_column_index].values\n",
    "        test_labels = test_data.iloc[:, class_column_index].values\n",
    "\n",
    "        train_labels = pd.get_dummies(train_labels, columns=['Class'], prefix=['Class'])\n",
    "        test_labels = pd.get_dummies(test_labels, columns=['Class'], prefix=['Class'])\n",
    "\n",
    "        train_data = train_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "        test_data = test_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "\n",
    "        train_data_tensors, train_label_tensors = create_tensors(train_data.values, train_labels, samples_per_tensor)\n",
    "        test_data_tensors, test_label_tensors = create_tensors(test_data.values, test_labels, samples_per_tensor)\n",
    "\n",
    "        test_data_participants_tensor, _ = create_tensors(test_data_participants.values, test_labels, samples_per_tensor)\n",
    "\n",
    "        yield train_data_tensors, train_label_tensors, test_data_tensors, test_label_tensors, test_data_participants_tensor\n",
    "\n",
    "\n",
    "\n",
    "# Initialize lists to store results for each fold\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "sensitivity_scores = []\n",
    "specificity_scores = []\n",
    "roc_auc_scores = []\n",
    "\n",
    "\n",
    "# Your training and evaluation code\n",
    "# Your training and evaluation code\n",
    "for i, (train_data_tensors, train_label_tensors, test_data_tensors, test_label_tensors, test_data_participants_tensor) in enumerate(k_fold_cross_validation(df_encoded, k=5, samples_per_tensor=120, random_state=42)):\n",
    "    print(f\"\\nFold {i + 1}:\\n\")\n",
    "    print(\"Train Data Shape:\", train_data_tensors.shape)\n",
    "    print(\"Train Labels Shape:\", train_label_tensors.shape)\n",
    "    print(\"Test Data Shape:\", test_data_tensors.shape)\n",
    "    print(\"Test Labels Shape:\", test_label_tensors.shape)\n",
    "    print(\"Test Participants Data Shape:\", test_data_participants_tensor.shape)\n",
    "\n",
    "    model = classification_model()\n",
    "\n",
    "    # Add EarlyStopping to prevent overfitting\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    model.fit(train_data_tensors, train_label_tensors, epochs=5, batch_size=10, validation_data=(test_data_tensors, test_label_tensors), callbacks=[early_stopping])\n",
    "\n",
    "    true_list, final_predictions = sum_prediction(model, test_data_tensors, test_data_participants_tensor, test_label_tensors)\n",
    "\n",
    "\n",
    "    #flip results\n",
    "    true_list = [1 if i == 0 else 0 for i in true_list]\n",
    "    final_predictions = [1 if i == 0 else 0 for i in final_predictions]\n",
    "\n",
    "    # Convert lists to NumPy arrays\n",
    "    true_array = np.array(true_list)\n",
    "    final_predictions_array = np.array(final_predictions)\n",
    "\n",
    "    # Reshape final_predictions_array if necessary\n",
    "    # For example, if final_predictions should be a 2D array with one column\n",
    "    final_predictions_array = final_predictions_array.reshape(-1, 1)\n",
    "\n",
    "    # Calculate and store evaluation metrics\n",
    "    accuracy = accuracy_score(true_list, final_predictions)\n",
    "    f1 = f1_score(true_list, final_predictions)\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    conf_matrix = confusion_matrix(true_list, final_predictions)\n",
    "    TP = conf_matrix[1, 1]\n",
    "    TN = conf_matrix[0, 0]\n",
    "    FP = conf_matrix[0, 1]\n",
    "    FN = conf_matrix[1, 0]\n",
    "\n",
    "    # Calculate sensitivity and specificity with checks for division by zero\n",
    "    sensitivity = TP / (TP + FN) if (TP + FN) != 0 else 0\n",
    "    specificity = TN / (TN + FP) if (TN + FP) != 0 else 0\n",
    "\n",
    "    # Append scores to their respective lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "    sensitivity_scores.append(sensitivity)\n",
    "    specificity_scores.append(specificity)\n",
    "    \n",
    "\n",
    "    # Print results for each fold\n",
    "    print(f\"Accuracy: {accuracy:.4f}, F1 Score: {f1:.4f}, Sensitivity: {sensitivity:.4f}, Specificity: {specificity:.4f}\")\n",
    "\n",
    "# Print aggregated results\n",
    "print(\"\\nAggregated Results:\")\n",
    "print(f\"Mean Accuracy: {np.mean(accuracy_scores):.4f}\")\n",
    "print(f\"Mean F1 Score: {np.mean(f1_scores):.4f}\")\n",
    "print(f\"Mean Sensitivity: {np.mean(sensitivity_scores):.4f}\")\n",
    "print(f\"Mean Specificity: {np.mean(specificity_scores):.4f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
