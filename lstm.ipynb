{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tensorflow.keras.layers import Embedding, Flatten, LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = \"../data/Eye-tracking Output/cleaned_data.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['Age'].fillna(0, inplace=True)\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant.fillna(method='bfill', inplace=True)\n",
      "/var/folders/5z/ksmd9z810hv7hd63k2mmtgzr0000gn/T/ipykernel_72758/1142433817.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n"
     ]
    }
   ],
   "source": [
    "## Normalizing data ##\n",
    "\n",
    "# Feature selection of relevant columns\n",
    "relevant_columns = ['Participant', 'Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "                    'Tracking Ratio [%]', 'Category Right',\n",
    "                    'Stimulus', 'Gender', 'Age', 'Class', 'Trial', 'Pupil Diameter Right [mm]', 'Time.s']\n",
    "\n",
    "df_relevant = df[relevant_columns]\n",
    "\n",
    "# Filling NaNs in 'CARS Score' with 0\n",
    "df_relevant['Age'].fillna(0, inplace=True)\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]', 'Pupil Diameter Right [mm]', 'Time.s'\n",
    "                     ] # Lidt i tvivl om vi skal have 'Age' med her. CARS og Age giver ogs√• 0. Pis lort\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
    "\n",
    "# Define a function to fill NaN with the mean of the previous and next row\n",
    "def fill_with_row_mean(df_relevant, col):\n",
    "    # First, forward fill the first NaN (if any)\n",
    "    df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
    "    \n",
    "    # Then, fill the rest with the mean of the previous and next row\n",
    "    df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
    "    \n",
    "    return df_relevant[col]\n",
    "\n",
    "# Apply this function to each numerical column\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
    "\n",
    "# Handle any remaining NaNs, especially at the end of the DataFrame\n",
    "df_relevant.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize data per combination of Trial, Participant, and Stimulus\n",
    "for (trial, participant, stimulus), group_data in df_relevant.groupby(['Trial', 'Participant', 'Stimulus']):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Apply the scaler to all numerical columns for this group\n",
    "    df_relevant.loc[group_data.index, numerical_columns] = scaler.fit_transform(group_data[numerical_columns])\n",
    "\n",
    "# For some reason Age and CARS Score are not scaled properly, so we do it manually\n",
    "scaler = MinMaxScaler()\n",
    "df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n",
    "\n",
    "# Save the normalized data\n",
    "df_relevant.to_csv(\"../data/Eye-tracking Output/normalized_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant = pd.read_csv(\"../data/Eye-tracking Output/normalized_data.csv\")\n",
    "# Label encoding for participant, subject, and trial. \n",
    "# Input dimensions are the number of unique values in each column and output is the square root of the input\n",
    "# embeddings = []\n",
    "# inputs = ['Stimulus', 'Trial']\n",
    "# input_dims = [114, 34]\n",
    "# output_dims = [11, 7]\n",
    "\n",
    "# for input_name, input_dim, output_dim in zip(inputs, input_dims, output_dims):\n",
    "#     le = LabelEncoder()\n",
    "#     df_relevant[input_name] = le.fit_transform(df_relevant[input_name])\n",
    "    \n",
    "#     input_layer = Input(shape=(1,))\n",
    "#     embedding_layer = Embedding(input_dim=input_dim, output_dim=output_dim)(input_layer)\n",
    "    \n",
    "#     embeddings.append(embedding_layer)\n",
    "\n",
    "# # Concatenate embeddings\n",
    "# concatenated = Concatenate()(embeddings)\n",
    "\n",
    "# # print(df_relevant['Stimulus'].unique())\n",
    "# print(concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  dtype:  float64\n",
      "Point of Regard Right X [px]  dtype:  float64\n",
      "Point of Regard Right Y [px]  dtype:  float64\n",
      "Tracking Ratio [%]  dtype:  float64\n",
      "Gender  dtype:  float64\n",
      "Age  dtype:  float64\n",
      "Class  dtype:  float64\n",
      "Trial  dtype:  object\n",
      "Pupil Diameter Right [mm]  dtype:  float64\n",
      "Time.s  dtype:  float64\n",
      "Category Right_-  dtype:  float64\n",
      "Category Right_Blink  dtype:  float64\n",
      "Category Right_Fixation  dtype:  float64\n",
      "Category Right_Saccade  dtype:  float64\n",
      "Category Right_Separator  dtype:  float64\n",
      "Stimulus_01 coucou g.jpg  dtype:  float64\n",
      "Stimulus_01 neutre3.avi  dtype:  float64\n",
      "Stimulus_01vnvg151201b1.avi  dtype:  float64\n",
      "Stimulus_02 coucou d.jpg  dtype:  float64\n",
      "Stimulus_02 devant.jpg  dtype:  float64\n",
      "Stimulus_02 neutre visage gris.jpg  dtype:  float64\n",
      "Stimulus_03 devant.jpg  dtype:  float64\n",
      "Stimulus_03 regard chien g.jpg  dtype:  float64\n",
      "Stimulus_03 vole triste vs joie1.avi  dtype:  float64\n",
      "Stimulus_04 b joie triste - copie.jpg  dtype:  float64\n",
      "Stimulus_04 regard chien d.jpg  dtype:  float64\n",
      "Stimulus_04 tete chien g.jpg  dtype:  float64\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi  dtype:  float64\n",
      "Stimulus_05 tete chien d.jpg  dtype:  float64\n",
      "Stimulus_05 tete point chien g.jpg  dtype:  float64\n",
      "Stimulus_06 a triste joie.jpg  dtype:  float64\n",
      "Stimulus_06 devant point chien g.jpg  dtype:  float64\n",
      "Stimulus_06 tete point chien d.jpg  dtype:  float64\n",
      "Stimulus_07 devant point chien d.jpg  dtype:  float64\n",
      "Stimulus_07 devant.jpg  dtype:  float64\n",
      "Stimulus_07 tombe joie vs triste2.avi  dtype:  float64\n",
      "Stimulus_08 b triste joie.jpg  dtype:  float64\n",
      "Stimulus_08 devant.jpg  dtype:  float64\n",
      "Stimulus_08 voc chien g.jpg  dtype:  float64\n",
      "Stimulus_09 cadeau dernier1.avi  dtype:  float64\n",
      "Stimulus_09 voc chien d.jpg  dtype:  float64\n",
      "Stimulus_09 voc devant g.jpg  dtype:  float64\n",
      "Stimulus_1 coucou D.jpg  dtype:  float64\n",
      "Stimulus_1 coucou D.png  dtype:  float64\n",
      "Stimulus_10 a joie triste.jpg  dtype:  float64\n",
      "Stimulus_10 voc devant.jpg  dtype:  float64\n",
      "Stimulus_11 devant.jpg  dtype:  float64\n",
      "Stimulus_11 punition orale triste vs joie1.avi  dtype:  float64\n",
      "Stimulus_11 yeux chat G.png  dtype:  float64\n",
      "Stimulus_11 yeux chat d.jpg  dtype:  float64\n",
      "Stimulus_11 yeux chat gauche.jpg  dtype:  float64\n",
      "Stimulus_12 a triste joie - copie.jpg  dtype:  float64\n",
      "Stimulus_12 tete chat G.png  dtype:  float64\n",
      "Stimulus_12 tete chat droite.jpg  dtype:  float64\n",
      "Stimulus_12 tete chat gauche.jpg  dtype:  float64\n",
      "Stimulus_12 yeux chat gauche.jpg  dtype:  float64\n",
      "Stimulus_13 bonbons triste vs joie1.avi  dtype:  float64\n",
      "Stimulus_13 tete chat gauche.jpg  dtype:  float64\n",
      "Stimulus_13 tete pointage chat G.png  dtype:  float64\n",
      "Stimulus_13 tete pointage chat droite.jpg  dtype:  float64\n",
      "Stimulus_13 tete pointage chat gauche.jpg  dtype:  float64\n",
      "Stimulus_14 b joie triste.jpg  dtype:  float64\n",
      "Stimulus_14 devant point chat G.png  dtype:  float64\n",
      "Stimulus_14 devant point chat droite.jpg  dtype:  float64\n",
      "Stimulus_14 devant point chat gauche.jpg  dtype:  float64\n",
      "Stimulus_14 tete pointage chat gauche.jpg  dtype:  float64\n",
      "Stimulus_15 devant - Copie.jpg  dtype:  float64\n",
      "Stimulus_15 devant point chat gauche.jpg  dtype:  float64\n",
      "Stimulus_15 devant.jpg  dtype:  float64\n",
      "Stimulus_15 devant.png  dtype:  float64\n",
      "Stimulus_16 devant.jpg  dtype:  float64\n",
      "Stimulus_16 voc chat G.png  dtype:  float64\n",
      "Stimulus_16 voc chat gauche.jpg  dtype:  float64\n",
      "Stimulus_16 voc droite chat.jpg  dtype:  float64\n",
      "Stimulus_17 voc chat gauche.jpg  dtype:  float64\n",
      "Stimulus_17 voc devant G.png  dtype:  float64\n",
      "Stimulus_17 voc devant d.jpg  dtype:  float64\n",
      "Stimulus_17 voc devant.jpg  dtype:  float64\n",
      "Stimulus_18 au revoir.jpg  dtype:  float64\n",
      "Stimulus_18 au revoir.png  dtype:  float64\n",
      "Stimulus_18 aurevoir.jpg  dtype:  float64\n",
      "Stimulus_18 voc devant.jpg  dtype:  float64\n",
      "Stimulus_19 aurevoir.jpg  dtype:  float64\n",
      "Stimulus_2 devant.jpg  dtype:  float64\n",
      "Stimulus_2 devant.png  dtype:  float64\n",
      "Stimulus_20 eye tracking (ballon droite).avi  dtype:  float64\n",
      "Stimulus_20 eye tracking (ballon gauche).avi  dtype:  float64\n",
      "Stimulus_21 neutre4.avi  dtype:  float64\n",
      "Stimulus_21 neutre5.avi  dtype:  float64\n",
      "Stimulus_22 neutre visage gris.jpg  dtype:  float64\n",
      "Stimulus_23 bonbons triste vs joie2.avi  dtype:  float64\n",
      "Stimulus_23 vole triste vs joie4.avi  dtype:  float64\n",
      "Stimulus_24 a triste joie.jpg  dtype:  float64\n",
      "Stimulus_24 b joie triste.jpg  dtype:  float64\n",
      "Stimulus_25 punition orale triste vs joie2.avi  dtype:  float64\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi  dtype:  float64\n",
      "Stimulus_26 a triste joie.jpg  dtype:  float64\n",
      "Stimulus_26 b joie triste.jpg  dtype:  float64\n",
      "Stimulus_27 cadeau dernier2.avi  dtype:  float64\n",
      "Stimulus_27 tombe joie vs triste5.avi  dtype:  float64\n",
      "Stimulus_28 b triste joie.jpg  dtype:  float64\n",
      "Stimulus_29 tombe joie vs triste3.avi  dtype:  float64\n",
      "Stimulus_3 regard chien D.jpg  dtype:  float64\n",
      "Stimulus_3 regard chien D.png  dtype:  float64\n",
      "Stimulus_30 a joie triste.jpg  dtype:  float64\n",
      "Stimulus_31 punition orale triste vs joie4.avi  dtype:  float64\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi  dtype:  float64\n",
      "Stimulus_32 b joie triste - copie.jpg  dtype:  float64\n",
      "Stimulus_33 vole triste vs joie2.avi  dtype:  float64\n",
      "Stimulus_34 a triste joie - copie.jpg  dtype:  float64\n",
      "Stimulus_4 tete chien D.jpg  dtype:  float64\n",
      "Stimulus_4 tete chien D.png  dtype:  float64\n",
      "Stimulus_5 tete point chien D.jpg  dtype:  float64\n",
      "Stimulus_5 tete point chien D.png  dtype:  float64\n",
      "Stimulus_6 devant point chien D.jpg  dtype:  float64\n",
      "Stimulus_6 devant point chien D.png  dtype:  float64\n",
      "Stimulus_7 devant - Copie.jpg  dtype:  float64\n",
      "Stimulus_7 devant.png  dtype:  float64\n",
      "Stimulus_8 voc chien D.jpg  dtype:  float64\n",
      "Stimulus_8 voc chien D.png  dtype:  float64\n",
      "Stimulus_9 voc devant D.png  dtype:  float64\n",
      "Stimulus_9 voc devant.jpg  dtype:  float64\n",
      "Stimulus_Eye Tracking (ballon droite).avi  dtype:  float64\n",
      "Stimulus_Eye Tracking (ballon gauche).avi  dtype:  float64\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi  dtype:  float64\n",
      "Stimulus_NoImage  dtype:  float64\n",
      "Stimulus_VNVD151207.avi  dtype:  float64\n",
      "Stimulus_VNVG151201b.avi  dtype:  float64\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi  dtype:  float64\n"
     ]
    }
   ],
   "source": [
    "# checking the variables to convert into dummy variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for column in df_relevant.columns:\n",
    "#     print(column, \" dtype: \", df_relevant.dtypes[column])\n",
    "    # if df_relevant.dtypes[column] == \"object\":\n",
    "    #     print(column)\n",
    "\n",
    "# print(df_relevant[\"Gender\"].unique())\n",
    "# print(df_relevant[\"Category Left\"].unique())\n",
    "# print(df_relevant[\"Category Right\"].unique())\n",
    "# print(df_relevant[\"Trial\"].unique())\n",
    "# print(df_relevant[\"Stimulus\"].unique())\n",
    "\n",
    "\n",
    "#print(df_relevant[\"Gender\"].unique())\n",
    "le_gen = LabelEncoder()\n",
    "df_relevant['Gender'] = le_gen.fit_transform(df_relevant['Gender']) # M, F\n",
    "\n",
    "\n",
    "le_class = LabelEncoder()\n",
    "df_relevant['Class'] = le_class.fit_transform(df_relevant['Class']) # ASD, TD\n",
    "\n",
    "\n",
    "# Assuming 'Category' is your categorical variable in a DataFrame df\n",
    "df_encoded = pd.get_dummies(df_relevant, columns=['Category Right', 'Stimulus'], prefix=['Category Right', 'Stimulus']) # one hot encoding\n",
    "\n",
    "# print(df_encoded.iloc[:, 16:22].head(5)) # checking how it looks.\n",
    "\n",
    "for column in df_encoded.columns: #convert int64 into float64 so network it expects the same value\n",
    "    if df_encoded.dtypes[column] == \"int64\" or df_encoded.dtypes[column] == \"uint8\":\n",
    "        df_encoded[column] = df_encoded[column].astype('float64')\n",
    "\n",
    "for column in df_encoded.columns:\n",
    "    print(column, \" dtype: \", df_encoded.dtypes[column])\n",
    "#print(df_relevant[\"Class\"].unique())\n",
    "#print(df_relevant['Participant'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tror ikke vi skal bruge den her\n",
    "\n",
    "# # Save only the normalized columns into a new DataFrame\n",
    "# normalized_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "#                       'Tracking Ratio [%]',\n",
    "#                       'CARS Score', 'Age']\n",
    "# df_normalized = df_relevant[normalized_columns]\n",
    "\n",
    "\n",
    "# # Combining all data into a single tensor\n",
    "# # reshaping the normalized data into 3d np array\n",
    "# normalized_np = np.stack([df_normalized[col].values for col in df_normalized.columns], 1)\n",
    "# # converting from np array to keras tensors\n",
    "# normalized_tensor = tf.convert_to_tensor(normalized_np, dtype=tf.float32)\n",
    "\n",
    "# # Add a dimension to normalized_tensor and df_encoded\n",
    "# # This transforms them from shape (905519, 7) and (905519, 19) to (905519, 1, 7) and (905519, 1, 19)\n",
    "# normalized_tensor_3d = tf.expand_dims(normalized_tensor, axis=1)\n",
    "# df_encoded_3d = tf.expand_dims(df_encoded, axis=1)\n",
    "\n",
    "# # Now you can concatenate along the last axis\n",
    "# df_all = tf.keras.layers.Concatenate(axis=-1)([normalized_tensor_3d, df_encoded_3d, concatenated])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ['Class']_0.0  ['Class']_1.0\n",
      "0              1              0\n",
      "1              1              0\n",
      "2              1              0\n",
      "3              1              0\n",
      "4              1              0 (236795, 2)\n",
      "(11145, 60, 126)\n",
      "(3946, 60, 126)\n",
      "(11145, 60, 2)\n",
      "(3946, 60, 2)\n",
      "Point of Regard Right X [px] float64\n",
      "Point of Regard Right Y [px] float64\n",
      "Tracking Ratio [%] float64\n",
      "Gender float64\n",
      "Age float64\n",
      "Pupil Diameter Right [mm] float64\n",
      "Time.s float64\n",
      "Category Right_- float64\n",
      "Category Right_Blink float64\n",
      "Category Right_Fixation float64\n",
      "Category Right_Saccade float64\n",
      "Category Right_Separator float64\n",
      "Stimulus_01 coucou g.jpg float64\n",
      "Stimulus_01 neutre3.avi float64\n",
      "Stimulus_01vnvg151201b1.avi float64\n",
      "Stimulus_02 coucou d.jpg float64\n",
      "Stimulus_02 devant.jpg float64\n",
      "Stimulus_02 neutre visage gris.jpg float64\n",
      "Stimulus_03 devant.jpg float64\n",
      "Stimulus_03 regard chien g.jpg float64\n",
      "Stimulus_03 vole triste vs joie1.avi float64\n",
      "Stimulus_04 b joie triste - copie.jpg float64\n",
      "Stimulus_04 regard chien d.jpg float64\n",
      "Stimulus_04 tete chien g.jpg float64\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi float64\n",
      "Stimulus_05 tete chien d.jpg float64\n",
      "Stimulus_05 tete point chien g.jpg float64\n",
      "Stimulus_06 a triste joie.jpg float64\n",
      "Stimulus_06 devant point chien g.jpg float64\n",
      "Stimulus_06 tete point chien d.jpg float64\n",
      "Stimulus_07 devant point chien d.jpg float64\n",
      "Stimulus_07 devant.jpg float64\n",
      "Stimulus_07 tombe joie vs triste2.avi float64\n",
      "Stimulus_08 b triste joie.jpg float64\n",
      "Stimulus_08 devant.jpg float64\n",
      "Stimulus_08 voc chien g.jpg float64\n",
      "Stimulus_09 cadeau dernier1.avi float64\n",
      "Stimulus_09 voc chien d.jpg float64\n",
      "Stimulus_09 voc devant g.jpg float64\n",
      "Stimulus_1 coucou D.jpg float64\n",
      "Stimulus_1 coucou D.png float64\n",
      "Stimulus_10 a joie triste.jpg float64\n",
      "Stimulus_10 voc devant.jpg float64\n",
      "Stimulus_11 devant.jpg float64\n",
      "Stimulus_11 punition orale triste vs joie1.avi float64\n",
      "Stimulus_11 yeux chat G.png float64\n",
      "Stimulus_11 yeux chat d.jpg float64\n",
      "Stimulus_11 yeux chat gauche.jpg float64\n",
      "Stimulus_12 a triste joie - copie.jpg float64\n",
      "Stimulus_12 tete chat G.png float64\n",
      "Stimulus_12 tete chat droite.jpg float64\n",
      "Stimulus_12 tete chat gauche.jpg float64\n",
      "Stimulus_12 yeux chat gauche.jpg float64\n",
      "Stimulus_13 bonbons triste vs joie1.avi float64\n",
      "Stimulus_13 tete chat gauche.jpg float64\n",
      "Stimulus_13 tete pointage chat G.png float64\n",
      "Stimulus_13 tete pointage chat droite.jpg float64\n",
      "Stimulus_13 tete pointage chat gauche.jpg float64\n",
      "Stimulus_14 b joie triste.jpg float64\n",
      "Stimulus_14 devant point chat G.png float64\n",
      "Stimulus_14 devant point chat droite.jpg float64\n",
      "Stimulus_14 devant point chat gauche.jpg float64\n",
      "Stimulus_14 tete pointage chat gauche.jpg float64\n",
      "Stimulus_15 devant - Copie.jpg float64\n",
      "Stimulus_15 devant point chat gauche.jpg float64\n",
      "Stimulus_15 devant.jpg float64\n",
      "Stimulus_15 devant.png float64\n",
      "Stimulus_16 devant.jpg float64\n",
      "Stimulus_16 voc chat G.png float64\n",
      "Stimulus_16 voc chat gauche.jpg float64\n",
      "Stimulus_16 voc droite chat.jpg float64\n",
      "Stimulus_17 voc chat gauche.jpg float64\n",
      "Stimulus_17 voc devant G.png float64\n",
      "Stimulus_17 voc devant d.jpg float64\n",
      "Stimulus_17 voc devant.jpg float64\n",
      "Stimulus_18 au revoir.jpg float64\n",
      "Stimulus_18 au revoir.png float64\n",
      "Stimulus_18 aurevoir.jpg float64\n",
      "Stimulus_18 voc devant.jpg float64\n",
      "Stimulus_19 aurevoir.jpg float64\n",
      "Stimulus_2 devant.jpg float64\n",
      "Stimulus_2 devant.png float64\n",
      "Stimulus_20 eye tracking (ballon droite).avi float64\n",
      "Stimulus_20 eye tracking (ballon gauche).avi float64\n",
      "Stimulus_21 neutre4.avi float64\n",
      "Stimulus_21 neutre5.avi float64\n",
      "Stimulus_22 neutre visage gris.jpg float64\n",
      "Stimulus_23 bonbons triste vs joie2.avi float64\n",
      "Stimulus_23 vole triste vs joie4.avi float64\n",
      "Stimulus_24 a triste joie.jpg float64\n",
      "Stimulus_24 b joie triste.jpg float64\n",
      "Stimulus_25 punition orale triste vs joie2.avi float64\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi float64\n",
      "Stimulus_26 a triste joie.jpg float64\n",
      "Stimulus_26 b joie triste.jpg float64\n",
      "Stimulus_27 cadeau dernier2.avi float64\n",
      "Stimulus_27 tombe joie vs triste5.avi float64\n",
      "Stimulus_28 b triste joie.jpg float64\n",
      "Stimulus_29 tombe joie vs triste3.avi float64\n",
      "Stimulus_3 regard chien D.jpg float64\n",
      "Stimulus_3 regard chien D.png float64\n",
      "Stimulus_30 a joie triste.jpg float64\n",
      "Stimulus_31 punition orale triste vs joie4.avi float64\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi float64\n",
      "Stimulus_32 b joie triste - copie.jpg float64\n",
      "Stimulus_33 vole triste vs joie2.avi float64\n",
      "Stimulus_34 a triste joie - copie.jpg float64\n",
      "Stimulus_4 tete chien D.jpg float64\n",
      "Stimulus_4 tete chien D.png float64\n",
      "Stimulus_5 tete point chien D.jpg float64\n",
      "Stimulus_5 tete point chien D.png float64\n",
      "Stimulus_6 devant point chien D.jpg float64\n",
      "Stimulus_6 devant point chien D.png float64\n",
      "Stimulus_7 devant - Copie.jpg float64\n",
      "Stimulus_7 devant.png float64\n",
      "Stimulus_8 voc chien D.jpg float64\n",
      "Stimulus_8 voc chien D.png float64\n",
      "Stimulus_9 voc devant D.png float64\n",
      "Stimulus_9 voc devant.jpg float64\n",
      "Stimulus_Eye Tracking (ballon droite).avi float64\n",
      "Stimulus_Eye Tracking (ballon gauche).avi float64\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi float64\n",
      "Stimulus_NoImage float64\n",
      "Stimulus_VNVD151207.avi float64\n",
      "Stimulus_VNVG151201b.avi float64\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi float64\n"
     ]
    }
   ],
   "source": [
    "# train test split. inf√∏r ogs√• evt padding\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is loaded into a variable called 'df_encoded'\n",
    "# Modify the following line based on the actual column name of 'Class'\n",
    "\n",
    "# Extract the unique participant IDs\n",
    "participant_ids = df_encoded['Participant'].unique()\n",
    "\n",
    "# Split participant IDs into train and test sets\n",
    "train_participant_ids, test_participant_ids = train_test_split(participant_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "# Filter data based on participant IDs\n",
    "train_data = df_encoded[np.isin(df_encoded['Participant'], train_participant_ids)]\n",
    "test_data = df_encoded[np.isin(df_encoded['Participant'], test_participant_ids)]\n",
    "\n",
    "# Extract 'Class' column index dynamically and \n",
    "class_column_index = df_encoded.columns.get_loc('Class')\n",
    "participant_column_index = df_encoded.columns.get_loc('Participant')\n",
    "\n",
    "\n",
    "# Extract 'Class' values for train and test\n",
    "train_labels = train_data.iloc[:, class_column_index].values\n",
    "test_labels = test_data.iloc[:, class_column_index].values\n",
    "\n",
    "\n",
    "train_labels = pd.get_dummies(train_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "test_labels = pd.get_dummies(test_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "\n",
    "\n",
    "# Drop the 'Class' and 'Participant' column from the data\n",
    "train_data = train_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "test_data = test_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "\n",
    "\n",
    "\n",
    "# Convert data into tensors with 60 samples each\n",
    "def create_tensors(data, labels, samples_per_tensor=60):\n",
    "    num_tensors = len(data) // samples_per_tensor\n",
    "    data_tensors = np.array_split(data[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    labels_tensors = np.array_split(labels[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    return np.stack(data_tensors), np.stack(labels_tensors) #, np.expand_dims(np.stack(labels_tensors), axis=-1)\n",
    "\n",
    "train_data_tensors, train_label_tensors = create_tensors(train_data.values, train_labels)\n",
    "test_data_tensors, test_label_tensors = create_tensors(test_data.values, test_labels)\n",
    "\n",
    "# checking if everythin looks good\n",
    "print(train_data_tensors.shape)\n",
    "print(test_data_tensors.shape)\n",
    "print(train_label_tensors.shape)\n",
    "print(test_label_tensors.shape)\n",
    "\n",
    "#checking up on my data before feeding it to network.\n",
    "for i in train_data.columns:\n",
    "    print(i, train_data.dtypes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60, 124)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "indices = torch.randperm(len(train_data_tensors))[:200]\n",
    "\n",
    "lort = train_data_tensors[indices] # making a subset of 200\n",
    "\n",
    "lort.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11145/11145 [==============================] - 98s 9ms/step - loss: 0.3350 - accuracy: 0.8471 - val_loss: 0.9107 - val_accuracy: 0.6884\n",
      "Epoch 2/5\n",
      "11145/11145 [==============================] - 97s 9ms/step - loss: 0.2566 - accuracy: 0.8870 - val_loss: 0.8284 - val_accuracy: 0.6723\n",
      "Epoch 3/5\n",
      "11145/11145 [==============================] - 97s 9ms/step - loss: 0.2146 - accuracy: 0.9024 - val_loss: 1.4309 - val_accuracy: 0.6809\n",
      "Epoch 4/5\n",
      "11145/11145 [==============================] - 96s 9ms/step - loss: 0.1815 - accuracy: 0.9173 - val_loss: 1.2846 - val_accuracy: 0.6812\n",
      "Epoch 5/5\n",
      "11145/11145 [==============================] - 96s 9ms/step - loss: 0.1632 - accuracy: 0.9290 - val_loss: 1.9681 - val_accuracy: 0.6976\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_10 (LSTM)              (None, 60, 50)            35400     \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 60, 50)            2550      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 60, 2)             102       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38052 (148.64 KB)\n",
      "Trainable params: 38052 (148.64 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "124/124 [==============================] - 1s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Define the LSTM model\n",
    "\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an LSTM layer with, for example, 50 units\n",
    "    model.add(LSTM(units=50, input_shape=(60, 126), return_sequences=True))\n",
    "\n",
    "    # Add a Dense layer with the number of classes as the output dimension and activation function\n",
    "    model.add(Dense(units=50))\n",
    "\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Compile the model with an optimizer, loss function, and metrics\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = classification_model()\n",
    "\n",
    "model.fit(train_data_tensors, train_label_tensors, epochs = 5, batch_size= 1, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "\n",
    "model.save('modelus.h5')\n",
    "\n",
    "# Display a summary of the model's architecture\n",
    "model.summary()\n",
    "\n",
    "preds = model.predict(test_data_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3946, 60, 2)\n",
      "(3946, 60, 2)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "# Assuming preds is the output of model.predict\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming preds is the output of model.predict\n",
    "predicted_class_labels = preds.argmax(axis=-1)\n",
    "predicted_class_labels_df = pd.DataFrame({'Predicted_Class': predicted_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "# Print the first 50 rows\n",
    "#print(predicted_class_labels_df.head(50))\n",
    "\n",
    "true_class_labels = test_label_tensors.argmax(axis=-1)\n",
    "true_class_labels_df = pd.DataFrame({'Predicted_Class': true_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "\n",
    "# for i in predicted_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "# for i in true_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
