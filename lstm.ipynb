{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import torch\n",
    "from tensorflow.keras.layers import Embedding, Flatten, LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "from keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = \"../data/Eye-tracking Output/cleaned_data.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['Age'].fillna(0, inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant.fillna(method='bfill', inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n"
     ]
    }
   ],
   "source": [
    "## Normalizing data ##\n",
    "\n",
    "# Feature selection of relevant columns\n",
    "relevant_columns = ['Participant', 'Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "                    'Tracking Ratio [%]', 'Category Right',\n",
    "                    'Stimulus', 'Gender', 'Age', 'Class', 'Trial', 'Pupil Diameter Right [mm]', 'Time.s']\n",
    "\n",
    "df_relevant = df[relevant_columns]\n",
    "\n",
    "# Filling NaNs in 'CARS Score' with 0\n",
    "df_relevant['Age'].fillna(0, inplace=True)\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]', 'Pupil Diameter Right [mm]', 'Time.s'\n",
    "                     ] # Lidt i tvivl om vi skal have 'Age' med her. CARS og Age giver også 0. Pis lort\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
    "\n",
    "# Define a function to fill NaN with the mean of the previous and next row\n",
    "def fill_with_row_mean(df_relevant, col):\n",
    "    # First, forward fill the first NaN (if any)\n",
    "    df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
    "    \n",
    "    # Then, fill the rest with the mean of the previous and next row\n",
    "    df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
    "    \n",
    "    return df_relevant[col]\n",
    "\n",
    "# Apply this function to each numerical column\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
    "\n",
    "# Handle any remaining NaNs, especially at the end of the DataFrame\n",
    "df_relevant.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize data per combination of Trial, Participant, and Stimulus\n",
    "for (trial, participant, stimulus), group_data in df_relevant.groupby(['Trial', 'Participant', 'Stimulus']):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Apply the scaler to all numerical columns for this group\n",
    "    df_relevant.loc[group_data.index, numerical_columns] = scaler.fit_transform(group_data[numerical_columns])\n",
    "\n",
    "# For some reason Age and CARS Score are not scaled properly, so we do it manually\n",
    "scaler = MinMaxScaler()\n",
    "df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n",
    "\n",
    "# Save the normalized data\n",
    "df_relevant.to_csv(\"../data/Eye-tracking Output/normalized_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant = pd.read_csv(\"../data/Eye-tracking Output/normalized_data.csv\")\n",
    "# Label encoding for participant, subject, and trial. \n",
    "# Input dimensions are the number of unique values in each column and output is the square root of the input\n",
    "# embeddings = []\n",
    "# inputs = ['Stimulus', 'Trial']\n",
    "# input_dims = [114, 34]\n",
    "# output_dims = [11, 7]\n",
    "\n",
    "# for input_name, input_dim, output_dim in zip(inputs, input_dims, output_dims):\n",
    "#     le = LabelEncoder()\n",
    "#     df_relevant[input_name] = le.fit_transform(df_relevant[input_name])\n",
    "    \n",
    "#     input_layer = Input(shape=(1,))\n",
    "#     embedding_layer = Embedding(input_dim=input_dim, output_dim=output_dim)(input_layer)\n",
    "    \n",
    "#     embeddings.append(embedding_layer)\n",
    "\n",
    "# # Concatenate embeddings\n",
    "# concatenated = Concatenate()(embeddings)\n",
    "\n",
    "# # print(df_relevant['Stimulus'].unique())\n",
    "# print(concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  dtype:  float32\n",
      "Point of Regard Right X [px]  dtype:  float32\n",
      "Point of Regard Right Y [px]  dtype:  float32\n",
      "Tracking Ratio [%]  dtype:  float32\n",
      "Gender  dtype:  float32\n",
      "Age  dtype:  float32\n",
      "Class  dtype:  float32\n",
      "Trial  dtype:  object\n",
      "Pupil Diameter Right [mm]  dtype:  float32\n",
      "Time.s  dtype:  float32\n",
      "Category Right_-  dtype:  float32\n",
      "Category Right_Blink  dtype:  float32\n",
      "Category Right_Fixation  dtype:  float32\n",
      "Category Right_Saccade  dtype:  float32\n",
      "Category Right_Separator  dtype:  float32\n",
      "Stimulus_01 coucou g.jpg  dtype:  float32\n",
      "Stimulus_01 neutre3.avi  dtype:  float32\n",
      "Stimulus_01vnvg151201b1.avi  dtype:  float32\n",
      "Stimulus_02 coucou d.jpg  dtype:  float32\n",
      "Stimulus_02 devant.jpg  dtype:  float32\n",
      "Stimulus_02 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_03 devant.jpg  dtype:  float32\n",
      "Stimulus_03 regard chien g.jpg  dtype:  float32\n",
      "Stimulus_03 vole triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_04 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_04 regard chien d.jpg  dtype:  float32\n",
      "Stimulus_04 tete chien g.jpg  dtype:  float32\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi  dtype:  float32\n",
      "Stimulus_05 tete chien d.jpg  dtype:  float32\n",
      "Stimulus_05 tete point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_06 devant point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 tete point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant.jpg  dtype:  float32\n",
      "Stimulus_07 tombe joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_08 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_08 devant.jpg  dtype:  float32\n",
      "Stimulus_08 voc chien g.jpg  dtype:  float32\n",
      "Stimulus_09 cadeau dernier1.avi  dtype:  float32\n",
      "Stimulus_09 voc chien d.jpg  dtype:  float32\n",
      "Stimulus_09 voc devant g.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.png  dtype:  float32\n",
      "Stimulus_10 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_10 voc devant.jpg  dtype:  float32\n",
      "Stimulus_11 devant.jpg  dtype:  float32\n",
      "Stimulus_11 punition orale triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_11 yeux chat G.png  dtype:  float32\n",
      "Stimulus_11 yeux chat d.jpg  dtype:  float32\n",
      "Stimulus_11 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat G.png  dtype:  float32\n",
      "Stimulus_12 tete chat droite.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 bonbons triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_13 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat G.png  dtype:  float32\n",
      "Stimulus_13 tete pointage chat droite.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat G.png  dtype:  float32\n",
      "Stimulus_14 devant point chat droite.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_15 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant.jpg  dtype:  float32\n",
      "Stimulus_15 devant.png  dtype:  float32\n",
      "Stimulus_16 devant.jpg  dtype:  float32\n",
      "Stimulus_16 voc chat G.png  dtype:  float32\n",
      "Stimulus_16 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_16 voc droite chat.jpg  dtype:  float32\n",
      "Stimulus_17 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant G.png  dtype:  float32\n",
      "Stimulus_17 voc devant d.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.png  dtype:  float32\n",
      "Stimulus_18 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_18 voc devant.jpg  dtype:  float32\n",
      "Stimulus_19 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_2 devant.jpg  dtype:  float32\n",
      "Stimulus_2 devant.png  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_21 neutre4.avi  dtype:  float32\n",
      "Stimulus_21 neutre5.avi  dtype:  float32\n",
      "Stimulus_22 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_23 bonbons triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_23 vole triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_24 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_24 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_25 punition orale triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi  dtype:  float32\n",
      "Stimulus_26 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_26 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_27 cadeau dernier2.avi  dtype:  float32\n",
      "Stimulus_27 tombe joie vs triste5.avi  dtype:  float32\n",
      "Stimulus_28 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_29 tombe joie vs triste3.avi  dtype:  float32\n",
      "Stimulus_3 regard chien D.jpg  dtype:  float32\n",
      "Stimulus_3 regard chien D.png  dtype:  float32\n",
      "Stimulus_30 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_31 punition orale triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_32 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_33 vole triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_34 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.png  dtype:  float32\n",
      "Stimulus_5 tete point chien D.jpg  dtype:  float32\n",
      "Stimulus_5 tete point chien D.png  dtype:  float32\n",
      "Stimulus_6 devant point chien D.jpg  dtype:  float32\n",
      "Stimulus_6 devant point chien D.png  dtype:  float32\n",
      "Stimulus_7 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_7 devant.png  dtype:  float32\n",
      "Stimulus_8 voc chien D.jpg  dtype:  float32\n",
      "Stimulus_8 voc chien D.png  dtype:  float32\n",
      "Stimulus_9 voc devant D.png  dtype:  float32\n",
      "Stimulus_9 voc devant.jpg  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi  dtype:  float32\n",
      "Stimulus_NoImage  dtype:  float32\n",
      "Stimulus_VNVD151207.avi  dtype:  float32\n",
      "Stimulus_VNVG151201b.avi  dtype:  float32\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi  dtype:  float32\n"
     ]
    }
   ],
   "source": [
    "# checking the variables to convert into dummy variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for column in df_relevant.columns:\n",
    "#     print(column, \" dtype: \", df_relevant.dtypes[column])\n",
    "    # if df_relevant.dtypes[column] == \"object\":\n",
    "    #     print(column)\n",
    "\n",
    "# print(df_relevant[\"Gender\"].unique())\n",
    "# print(df_relevant[\"Category Left\"].unique())\n",
    "# print(df_relevant[\"Category Right\"].unique())\n",
    "# print(df_relevant[\"Trial\"].unique())\n",
    "# print(df_relevant[\"Stimulus\"].unique())\n",
    "\n",
    "\n",
    "#print(df_relevant[\"Gender\"].unique())\n",
    "le_gen = LabelEncoder()\n",
    "df_relevant['Gender'] = le_gen.fit_transform(df_relevant['Gender']) # M, F\n",
    "\n",
    "\n",
    "le_class = LabelEncoder()\n",
    "df_relevant['Class'] = le_class.fit_transform(df_relevant['Class']) # ASD, TD\n",
    "\n",
    "\n",
    "# Assuming 'Category' is your categorical variable in a DataFrame df\n",
    "df_encoded = pd.get_dummies(df_relevant, columns=['Category Right', 'Stimulus'], prefix=['Category Right', 'Stimulus']) # one hot encoding\n",
    "\n",
    "# print(df_encoded.iloc[:, 16:22].head(5)) # checking how it looks.\n",
    "\n",
    "for column in df_encoded.columns: #convert int64 into float64 so network it expects the same value\n",
    "    if df_encoded.dtypes[column] == \"int64\" or df_encoded.dtypes[column] == \"uint8\" or df_encoded.dtypes[column] == \"float64\":\n",
    "        df_encoded[column] = df_encoded[column].astype('float32')\n",
    "\n",
    "for column in df_encoded.columns:\n",
    "    print(column, \" dtype: \", df_encoded.dtypes[column])\n",
    "#print(df_relevant[\"Class\"].unique())\n",
    "#print(df_relevant['Participant'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tror ikke vi skal bruge den her\n",
    "\n",
    "# # Save only the normalized columns into a new DataFrame\n",
    "# normalized_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "#                       'Tracking Ratio [%]',\n",
    "#                       'CARS Score', 'Age']\n",
    "# df_normalized = df_relevant[normalized_columns]\n",
    "\n",
    "\n",
    "# # Combining all data into a single tensor\n",
    "# # reshaping the normalized data into 3d np array\n",
    "# normalized_np = np.stack([df_normalized[col].values for col in df_normalized.columns], 1)\n",
    "# # converting from np array to keras tensors\n",
    "# normalized_tensor = tf.convert_to_tensor(normalized_np, dtype=tf.float32)\n",
    "\n",
    "# # Add a dimension to normalized_tensor and df_encoded\n",
    "# # This transforms them from shape (905519, 7) and (905519, 19) to (905519, 1, 7) and (905519, 1, 19)\n",
    "# normalized_tensor_3d = tf.expand_dims(normalized_tensor, axis=1)\n",
    "# df_encoded_3d = tf.expand_dims(df_encoded, axis=1)\n",
    "\n",
    "# # Now you can concatenate along the last axis\n",
    "# df_all = tf.keras.layers.Concatenate(axis=-1)([normalized_tensor_3d, df_encoded_3d, concatenated])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split. infør også evt padding\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is loaded into a variable called 'df_encoded'\n",
    "# Modify the following line based on the actual column name of 'Class'\n",
    "\n",
    "# Extract the unique participant IDs\n",
    "participant_ids = df_encoded['Participant'].unique()\n",
    "\n",
    "# Split participant IDs into train and test sets\n",
    "train_participant_ids, test_participant_ids = train_test_split(participant_ids, test_size=0.34, random_state=3)\n",
    "\n",
    "# Filter data based on participant IDs\n",
    "train_data = df_encoded[np.isin(df_encoded['Participant'], train_participant_ids)]\n",
    "test_data = df_encoded[np.isin(df_encoded['Participant'], test_participant_ids)]\n",
    "\n",
    "test_data_participants = test_data['Participant']\n",
    "\n",
    "# Extract 'Class' column index dynamically and \n",
    "class_column_index = df_encoded.columns.get_loc('Class')\n",
    "participant_column_index = df_encoded.columns.get_loc('Participant')\n",
    "\n",
    "\n",
    "# Extract 'Class' values for train and test\n",
    "train_labels = train_data.iloc[:, class_column_index].values\n",
    "test_labels = test_data.iloc[:, class_column_index].values\n",
    "\n",
    "\n",
    "train_labels = pd.get_dummies(train_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "test_labels = pd.get_dummies(test_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "\n",
    "\n",
    "# Drop the 'Class' and 'Participant' column from the data\n",
    "train_data = train_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "test_data = test_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert data into tensors with 60 samples each\n",
    "def create_tensors(data, labels, samples_per_tensor=60):\n",
    "    num_tensors = len(data) // samples_per_tensor\n",
    "    data_tensors = np.array_split(data[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    labels_tensors = np.array_split(labels[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    return np.stack(data_tensors), np.stack(labels_tensors) #, np.expand_dims(np.stack(labels_tensors), axis=-1)\n",
    "\n",
    "train_data_tensors, train_label_tensors = create_tensors(train_data.values, train_labels)\n",
    "test_data_tensors, test_label_tensors = create_tensors(test_data.values, test_labels)\n",
    "\n",
    "test_data_participants_tensor, lol = create_tensors(test_data_participants.values, test_labels)\n",
    "\n",
    "# checking if everythin looks good\n",
    "# print(train_data_tensors.shape)\n",
    "# print(test_data_tensors.shape)\n",
    "# print(train_label_tensors.shape)\n",
    "# print(test_label_tensors.shape)\n",
    "\n",
    "# #checking up on my data before feeding it to network.\n",
    "# for i in train_data.columns:\n",
    "#     print(i, train_data.dtypes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60, 126)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "indices = torch.randperm(len(train_data_tensors))[:200]\n",
    "\n",
    "lort = train_data_tensors[indices] # making a subset of 200\n",
    "\n",
    "lort.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "919/928 [============================>.] - ETA: 0s - loss: 0.4347 - accuracy: 0.7975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[49], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m classification_model()\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelus1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Saving the history of the model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Define the LSTM model\n",
    "\n",
    "input_shape = (60, 126)\n",
    "dropout = 0.2\n",
    "learning_rate = 0.0004\n",
    "\n",
    "\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an LSTM layer with, for example, 50 units\n",
    "    model.add(LSTM(units=60, input_shape=input_shape, return_sequences=True))\n",
    "\n",
    "    # Add a Dense layer with the number of classes as the output dimension and activation function\n",
    "    model.add(Dense(units=50))\n",
    "\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Compile the model with an optimizer, loss function, and metrics\n",
    "    model.compile(optimizer=tf.keras.optimizers.legacy.Adam(learning_rate=learning_rate), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = classification_model()\n",
    "\n",
    "history = model.fit(train_data_tensors, train_label_tensors, epochs = 5, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "\n",
    "model.save('modelus1.h5')\n",
    "\n",
    "# Saving the history of the model\n",
    "import pickle\n",
    "\n",
    "with open('modelus1_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "    \n",
    "\n",
    "# Display a summary of the model's architecture\n",
    "model.summary()\n",
    "\n",
    "preds = model.predict(test_data_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir1/helloworld1/tuner0.json\n",
      "\n",
      "Search: Running Trial #8\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "100               |70                |units\n",
      "50                |50                |additional_units\n",
      "0.35              |0.05              |dropout\n",
      "0.0036991         |0.00010296        |learning_rate\n",
      "\n",
      "Epoch 1/5\n",
      "194/928 [=====>........................] - ETA: 11s - loss: 0.4956 - accuracy: 0.7818"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[73], line 36\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkerastuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomSearch\n\u001b[1;32m     28\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[1;32m     29\u001b[0m     MyHyperModel(),\n\u001b[1;32m     30\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     33\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dir1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     34\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelloworld1\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 36\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     40\u001b[0m best_model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_modelus1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hypertuning the model\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "\n",
    "num_classes = 2  # Define the number of classes\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.LSTM(\n",
    "            units=hp.Int('units', min_value=30, max_value=100, step=10),\n",
    "            input_shape=(60, 126), return_sequences=True))\n",
    "        model.add(keras.layers.Dense(\n",
    "            units=hp.Int('additional_units', min_value=20, max_value=50, step=10),\n",
    "            activation='relu'))  # Additional hidden layer\n",
    "        model.add(keras.layers.Dropout(\n",
    "            rate=hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.25, step=0.05)))\n",
    "        model.add(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.legacy.Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=2,\n",
    "    directory='my_dir1',\n",
    "    project_name='helloworld1')\n",
    "\n",
    "tuner.search(train_data_tensors, train_label_tensors, epochs = 5, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "best_model.save('best_modelus1.h5')\n",
    "\n",
    "# Saving the history of the model\n",
    "history=best_model.history\n",
    "with open('best_modelus1_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "import pickle\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[72], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m history\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mhistory\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbest_modelus1_history\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m file_pi:\n\u001b[0;32m----> 5\u001b[0m     pickle\u001b[38;5;241m.\u001b[39mdump(\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhistory\u001b[49m, file_pi)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(history\u001b[38;5;241m.\u001b[39mhistory\u001b[38;5;241m.\u001b[39mkeys())\n\u001b[1;32m      8\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(history\u001b[38;5;241m.\u001b[39mhistory[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "# Plotting to see if the model is overfitting\n",
    "model = load_model('best_modelus1.h5')\n",
    "\n",
    "# MODELLENS HISTORIK SKAL LOADS IND HER\n",
    "\n",
    "print(history.history.keys())\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Error in loading the saved optimizer state. As a result, your model is starting with a freshly initialized optimizer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 2s 8ms/step\n",
      "(5819, 60, 2)\n",
      "(5819, 60, 2)\n"
     ]
    }
   ],
   "source": [
    "#predictions\n",
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('best_modelus1.h5')\n",
    "preds = model.predict(test_data_tensors)\n",
    "\n",
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "# Assuming preds is the output of model.predict\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming preds is the output of model.predict\n",
    "predicted_class_labels = preds.argmax(axis=-1)\n",
    "predicted_class_labels_df = pd.DataFrame({'Predicted_Class': predicted_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "# Print the first 50 rows\n",
    "#print(predicted_class_labels_df.head(50))\n",
    "\n",
    "true_class_labels = test_label_tensors.argmax(axis=-1)\n",
    "true_class_labels_df = pd.DataFrame({'Predicted_Class': true_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "#print(true_class_labels_df[0:10])\n",
    "\n",
    "\n",
    "# for i in predicted_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "# for i in true_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "### making a prediction function based on models guesses.\n",
    "# print(preds.shape)\n",
    "dol = pd.DataFrame(test_data_participants_tensor)\n",
    "dol[\"Name\"] = dol[1]\n",
    "dol = dol.astype(object)\n",
    "\n",
    "unique_indices = dol.drop_duplicates(subset=\"Name\").index.tolist()\n",
    "\n",
    "unique_indices.append(len(dol)) #appending last index\n",
    "\n",
    "true_df_list = []\n",
    "pred_df_list = []\n",
    "\n",
    "for i in range(len(unique_indices)-1): #segment data\n",
    "    if i == unique_indices[-1]:\n",
    "        break\n",
    "    start_index = unique_indices[i]\n",
    "    end_index = unique_indices[i + 1]\n",
    "\n",
    "    # print(start_index, end_index)\n",
    "\n",
    "    true_list = true_class_labels_df[start_index: end_index]\n",
    "    pred_list = predicted_class_labels_df[start_index: end_index]\n",
    "\n",
    "    true_df_list.append(true_list)\n",
    "    pred_df_list.append(pred_list)\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "\n",
    "#now for the prediction:\n",
    "for df in pred_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred = 1\n",
    "    elif avg > 0.5:\n",
    "        pred = 0\n",
    "    pred_list.append(pred)\n",
    "\n",
    "for df in true_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred1 = 1\n",
    "    elif avg > 0.5:\n",
    "        pred1 = 0\n",
    "    true_list.append(pred1)\n",
    "\n",
    "\n",
    "print(pred_list)\n",
    "print(true_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5819, 60, 2)\n",
      "(5819, 60, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  1  0\n",
      "2  1  0\n",
      "3  1  0\n",
      "4  1  0\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#making a prediction function based on sum of outputs\n",
    "\n",
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "\n",
    "predictions = pd.DataFrame(preds[:, -1, :])\n",
    "test_label = pd.DataFrame(test_label_tensors[:, -1, :])\n",
    "\n",
    "\n",
    "print(test_label.head(5))\n",
    "\n",
    "\n",
    "True_df_list = []\n",
    "predict_df_list = []\n",
    "\n",
    "\n",
    "for i in range(len(unique_indices)-1): #segment data\n",
    "    if i == unique_indices[-1]:\n",
    "        break\n",
    "    start_index = unique_indices[i]\n",
    "    end_index = unique_indices[i + 1]\n",
    "\n",
    "    # print(start_index, end_index)\n",
    "\n",
    "    true_list = predictions[start_index: end_index]\n",
    "    pred_list = test_label[start_index: end_index]\n",
    "\n",
    "    True_df_list.append(true_list)\n",
    "    predict_df_list .append(pred_list)\n",
    "\n",
    "\n",
    "# now for predictions\n",
    "\n",
    "\n",
    "final_predictions = []\n",
    "true_list = []\n",
    "\n",
    "for i in True_df_list:\n",
    "    sum_0 = sum(i[0])\n",
    "    sum_1 = sum(i[1])\n",
    "    if sum_0 > sum_1:\n",
    "        final_predictions.append(1)\n",
    "    else:\n",
    "        final_predictions.append(0)\n",
    "\n",
    "\n",
    "for df in true_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred1 = 1\n",
    "    elif avg > 0.5:\n",
    "        pred1 = 0\n",
    "    true_list.append(pred1)\n",
    "    \n",
    "print(true_list)\n",
    "print(final_predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.90      0.95        10\n",
      "           1       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.95        20\n",
      "   macro avg       0.95      0.95      0.95        20\n",
      "weighted avg       0.95      0.95      0.95        20\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualizing the confusion matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(confusion_matrix(true_list, final_predictions), annot=True, cmap='Blues')\n",
    "\n",
    "# Printing classification report\n",
    "print(classification_report(true_list, final_predictions))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
