{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from tensorflow.keras.layers import Embedding, Flatten, LSTM, Dense, Input, Concatenate\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras import Input\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "data_path = \"../data/Eye-tracking Output/cleaned_data.csv\"\n",
    "df = pd.read_csv(data_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant['Age'].fillna(0, inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:33: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant.fillna(method='bfill', inplace=True)\n",
      "/var/folders/94/903y39c95x3g49g0_7l22jn00000gn/T/ipykernel_38004/1142433817.py:46: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n"
     ]
    }
   ],
   "source": [
    "## Normalizing data ##\n",
    "\n",
    "# Feature selection of relevant columns\n",
    "relevant_columns = ['Participant', 'Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "                    'Tracking Ratio [%]', 'Category Right',\n",
    "                    'Stimulus', 'Gender', 'Age', 'Class', 'Trial', 'Pupil Diameter Right [mm]', 'Time.s']\n",
    "\n",
    "df_relevant = df[relevant_columns]\n",
    "\n",
    "# Filling NaNs in 'CARS Score' with 0\n",
    "df_relevant['Age'].fillna(0, inplace=True)\n",
    "\n",
    "# List of numerical columns to scale\n",
    "numerical_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]', 'Pupil Diameter Right [mm]', 'Time.s'\n",
    "                     ] # Lidt i tvivl om vi skal have 'Age' med her. CARS og Age giver ogs√• 0. Pis lort\n",
    "\n",
    "# Convert columns to numeric, coercing errors to NaN\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = pd.to_numeric(df_relevant[col], errors='coerce')\n",
    "\n",
    "# Define a function to fill NaN with the mean of the previous and next row\n",
    "def fill_with_row_mean(df_relevant, col):\n",
    "    # First, forward fill the first NaN (if any)\n",
    "    df_relevant[col] = df_relevant[col].fillna(method='ffill')\n",
    "    \n",
    "    # Then, fill the rest with the mean of the previous and next row\n",
    "    df_relevant[col] = df_relevant[col].fillna((df_relevant[col].shift(1) + df_relevant[col].shift(-1)) / 2)\n",
    "    \n",
    "    return df_relevant[col]\n",
    "\n",
    "# Apply this function to each numerical column\n",
    "for col in numerical_columns:\n",
    "    df_relevant[col] = fill_with_row_mean(df_relevant, col)\n",
    "\n",
    "# Handle any remaining NaNs, especially at the end of the DataFrame\n",
    "df_relevant.fillna(method='bfill', inplace=True)\n",
    "\n",
    "# Normalize data per combination of Trial, Participant, and Stimulus\n",
    "for (trial, participant, stimulus), group_data in df_relevant.groupby(['Trial', 'Participant', 'Stimulus']):\n",
    "    scaler = MinMaxScaler()\n",
    "    # Apply the scaler to all numerical columns for this group\n",
    "    df_relevant.loc[group_data.index, numerical_columns] = scaler.fit_transform(group_data[numerical_columns])\n",
    "\n",
    "# For some reason Age and CARS Score are not scaled properly, so we do it manually\n",
    "scaler = MinMaxScaler()\n",
    "df_relevant[['Age', 'Tracking Ratio [%]']] = scaler.fit_transform(df_relevant[['Age', 'Tracking Ratio [%]']])\n",
    "\n",
    "# Save the normalized data\n",
    "df_relevant.to_csv(\"../data/Eye-tracking Output/normalized_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_relevant = pd.read_csv(\"../data/Eye-tracking Output/normalized_data.csv\")\n",
    "# Label encoding for participant, subject, and trial. \n",
    "# Input dimensions are the number of unique values in each column and output is the square root of the input\n",
    "# embeddings = []\n",
    "# inputs = ['Stimulus', 'Trial']\n",
    "# input_dims = [114, 34]\n",
    "# output_dims = [11, 7]\n",
    "\n",
    "# for input_name, input_dim, output_dim in zip(inputs, input_dims, output_dims):\n",
    "#     le = LabelEncoder()\n",
    "#     df_relevant[input_name] = le.fit_transform(df_relevant[input_name])\n",
    "    \n",
    "#     input_layer = Input(shape=(1,))\n",
    "#     embedding_layer = Embedding(input_dim=input_dim, output_dim=output_dim)(input_layer)\n",
    "    \n",
    "#     embeddings.append(embedding_layer)\n",
    "\n",
    "# # Concatenate embeddings\n",
    "# concatenated = Concatenate()(embeddings)\n",
    "\n",
    "# # print(df_relevant['Stimulus'].unique())\n",
    "# print(concatenated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Participant  dtype:  float32\n",
      "Point of Regard Right X [px]  dtype:  float32\n",
      "Point of Regard Right Y [px]  dtype:  float32\n",
      "Tracking Ratio [%]  dtype:  float32\n",
      "Gender  dtype:  float32\n",
      "Age  dtype:  float32\n",
      "Class  dtype:  float32\n",
      "Trial  dtype:  object\n",
      "Pupil Diameter Right [mm]  dtype:  float32\n",
      "Time.s  dtype:  float32\n",
      "Category Right_-  dtype:  float32\n",
      "Category Right_Blink  dtype:  float32\n",
      "Category Right_Fixation  dtype:  float32\n",
      "Category Right_Saccade  dtype:  float32\n",
      "Category Right_Separator  dtype:  float32\n",
      "Stimulus_01 coucou g.jpg  dtype:  float32\n",
      "Stimulus_01 neutre3.avi  dtype:  float32\n",
      "Stimulus_01vnvg151201b1.avi  dtype:  float32\n",
      "Stimulus_02 coucou d.jpg  dtype:  float32\n",
      "Stimulus_02 devant.jpg  dtype:  float32\n",
      "Stimulus_02 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_03 devant.jpg  dtype:  float32\n",
      "Stimulus_03 regard chien g.jpg  dtype:  float32\n",
      "Stimulus_03 vole triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_04 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_04 regard chien d.jpg  dtype:  float32\n",
      "Stimulus_04 tete chien g.jpg  dtype:  float32\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi  dtype:  float32\n",
      "Stimulus_05 tete chien d.jpg  dtype:  float32\n",
      "Stimulus_05 tete point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_06 devant point chien g.jpg  dtype:  float32\n",
      "Stimulus_06 tete point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant point chien d.jpg  dtype:  float32\n",
      "Stimulus_07 devant.jpg  dtype:  float32\n",
      "Stimulus_07 tombe joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_08 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_08 devant.jpg  dtype:  float32\n",
      "Stimulus_08 voc chien g.jpg  dtype:  float32\n",
      "Stimulus_09 cadeau dernier1.avi  dtype:  float32\n",
      "Stimulus_09 voc chien d.jpg  dtype:  float32\n",
      "Stimulus_09 voc devant g.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.jpg  dtype:  float32\n",
      "Stimulus_1 coucou D.png  dtype:  float32\n",
      "Stimulus_10 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_10 voc devant.jpg  dtype:  float32\n",
      "Stimulus_11 devant.jpg  dtype:  float32\n",
      "Stimulus_11 punition orale triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_11 yeux chat G.png  dtype:  float32\n",
      "Stimulus_11 yeux chat d.jpg  dtype:  float32\n",
      "Stimulus_11 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat G.png  dtype:  float32\n",
      "Stimulus_12 tete chat droite.jpg  dtype:  float32\n",
      "Stimulus_12 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_12 yeux chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 bonbons triste vs joie1.avi  dtype:  float32\n",
      "Stimulus_13 tete chat gauche.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat G.png  dtype:  float32\n",
      "Stimulus_13 tete pointage chat droite.jpg  dtype:  float32\n",
      "Stimulus_13 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat G.png  dtype:  float32\n",
      "Stimulus_14 devant point chat droite.jpg  dtype:  float32\n",
      "Stimulus_14 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_14 tete pointage chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_15 devant point chat gauche.jpg  dtype:  float32\n",
      "Stimulus_15 devant.jpg  dtype:  float32\n",
      "Stimulus_15 devant.png  dtype:  float32\n",
      "Stimulus_16 devant.jpg  dtype:  float32\n",
      "Stimulus_16 voc chat G.png  dtype:  float32\n",
      "Stimulus_16 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_16 voc droite chat.jpg  dtype:  float32\n",
      "Stimulus_17 voc chat gauche.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant G.png  dtype:  float32\n",
      "Stimulus_17 voc devant d.jpg  dtype:  float32\n",
      "Stimulus_17 voc devant.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.jpg  dtype:  float32\n",
      "Stimulus_18 au revoir.png  dtype:  float32\n",
      "Stimulus_18 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_18 voc devant.jpg  dtype:  float32\n",
      "Stimulus_19 aurevoir.jpg  dtype:  float32\n",
      "Stimulus_2 devant.jpg  dtype:  float32\n",
      "Stimulus_2 devant.png  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_20 eye tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_21 neutre4.avi  dtype:  float32\n",
      "Stimulus_21 neutre5.avi  dtype:  float32\n",
      "Stimulus_22 neutre visage gris.jpg  dtype:  float32\n",
      "Stimulus_23 bonbons triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_23 vole triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_24 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_24 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_25 punition orale triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi  dtype:  float32\n",
      "Stimulus_26 a triste joie.jpg  dtype:  float32\n",
      "Stimulus_26 b joie triste.jpg  dtype:  float32\n",
      "Stimulus_27 cadeau dernier2.avi  dtype:  float32\n",
      "Stimulus_27 tombe joie vs triste5.avi  dtype:  float32\n",
      "Stimulus_28 b triste joie.jpg  dtype:  float32\n",
      "Stimulus_29 tombe joie vs triste3.avi  dtype:  float32\n",
      "Stimulus_3 regard chien D.jpg  dtype:  float32\n",
      "Stimulus_3 regard chien D.png  dtype:  float32\n",
      "Stimulus_30 a joie triste.jpg  dtype:  float32\n",
      "Stimulus_31 punition orale triste vs joie4.avi  dtype:  float32\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi  dtype:  float32\n",
      "Stimulus_32 b joie triste - copie.jpg  dtype:  float32\n",
      "Stimulus_33 vole triste vs joie2.avi  dtype:  float32\n",
      "Stimulus_34 a triste joie - copie.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.jpg  dtype:  float32\n",
      "Stimulus_4 tete chien D.png  dtype:  float32\n",
      "Stimulus_5 tete point chien D.jpg  dtype:  float32\n",
      "Stimulus_5 tete point chien D.png  dtype:  float32\n",
      "Stimulus_6 devant point chien D.jpg  dtype:  float32\n",
      "Stimulus_6 devant point chien D.png  dtype:  float32\n",
      "Stimulus_7 devant - Copie.jpg  dtype:  float32\n",
      "Stimulus_7 devant.png  dtype:  float32\n",
      "Stimulus_8 voc chien D.jpg  dtype:  float32\n",
      "Stimulus_8 voc chien D.png  dtype:  float32\n",
      "Stimulus_9 voc devant D.png  dtype:  float32\n",
      "Stimulus_9 voc devant.jpg  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon droite).avi  dtype:  float32\n",
      "Stimulus_Eye Tracking (ballon gauche).avi  dtype:  float32\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi  dtype:  float32\n",
      "Stimulus_NoImage  dtype:  float32\n",
      "Stimulus_VNVD151207.avi  dtype:  float32\n",
      "Stimulus_VNVG151201b.avi  dtype:  float32\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi  dtype:  float32\n"
     ]
    }
   ],
   "source": [
    "# checking the variables to convert into dummy variables.\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# for column in df_relevant.columns:\n",
    "#     print(column, \" dtype: \", df_relevant.dtypes[column])\n",
    "    # if df_relevant.dtypes[column] == \"object\":\n",
    "    #     print(column)\n",
    "\n",
    "# print(df_relevant[\"Gender\"].unique())\n",
    "# print(df_relevant[\"Category Left\"].unique())\n",
    "# print(df_relevant[\"Category Right\"].unique())\n",
    "# print(df_relevant[\"Trial\"].unique())\n",
    "# print(df_relevant[\"Stimulus\"].unique())\n",
    "\n",
    "\n",
    "#print(df_relevant[\"Gender\"].unique())\n",
    "le_gen = LabelEncoder()\n",
    "df_relevant['Gender'] = le_gen.fit_transform(df_relevant['Gender']) # M, F\n",
    "\n",
    "\n",
    "le_class = LabelEncoder()\n",
    "df_relevant['Class'] = le_class.fit_transform(df_relevant['Class']) # ASD, TD\n",
    "\n",
    "\n",
    "# Assuming 'Category' is your categorical variable in a DataFrame df\n",
    "df_encoded = pd.get_dummies(df_relevant, columns=['Category Right', 'Stimulus'], prefix=['Category Right', 'Stimulus']) # one hot encoding\n",
    "\n",
    "# print(df_encoded.iloc[:, 16:22].head(5)) # checking how it looks.\n",
    "\n",
    "for column in df_encoded.columns: #convert int64 into float64 so network it expects the same value\n",
    "    if df_encoded.dtypes[column] == \"int64\" or df_encoded.dtypes[column] == \"uint8\" or df_encoded.dtypes[column] == \"float64\":\n",
    "        df_encoded[column] = df_encoded[column].astype('float32')\n",
    "\n",
    "for column in df_encoded.columns:\n",
    "    print(column, \" dtype: \", df_encoded.dtypes[column])\n",
    "#print(df_relevant[\"Class\"].unique())\n",
    "#print(df_relevant['Participant'].unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tror ikke vi skal bruge den her\n",
    "\n",
    "# # Save only the normalized columns into a new DataFrame\n",
    "# normalized_columns = ['Point of Regard Right X [px]', 'Point of Regard Right Y [px]',\n",
    "#                       'Tracking Ratio [%]',\n",
    "#                       'CARS Score', 'Age']\n",
    "# df_normalized = df_relevant[normalized_columns]\n",
    "\n",
    "\n",
    "# # Combining all data into a single tensor\n",
    "# # reshaping the normalized data into 3d np array\n",
    "# normalized_np = np.stack([df_normalized[col].values for col in df_normalized.columns], 1)\n",
    "# # converting from np array to keras tensors\n",
    "# normalized_tensor = tf.convert_to_tensor(normalized_np, dtype=tf.float32)\n",
    "\n",
    "# # Add a dimension to normalized_tensor and df_encoded\n",
    "# # This transforms them from shape (905519, 7) and (905519, 19) to (905519, 1, 7) and (905519, 1, 19)\n",
    "# normalized_tensor_3d = tf.expand_dims(normalized_tensor, axis=1)\n",
    "# df_encoded_3d = tf.expand_dims(df_encoded, axis=1)\n",
    "\n",
    "# # Now you can concatenate along the last axis\n",
    "# df_all = tf.keras.layers.Concatenate(axis=-1)([normalized_tensor_3d, df_encoded_3d, concatenated])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9272, 60, 126)\n",
      "(5819, 60, 126)\n",
      "(9272, 60, 2)\n",
      "(5819, 60, 2)\n",
      "Point of Regard Right X [px] float32\n",
      "Point of Regard Right Y [px] float32\n",
      "Tracking Ratio [%] float32\n",
      "Gender float32\n",
      "Age float32\n",
      "Pupil Diameter Right [mm] float32\n",
      "Time.s float32\n",
      "Category Right_- float32\n",
      "Category Right_Blink float32\n",
      "Category Right_Fixation float32\n",
      "Category Right_Saccade float32\n",
      "Category Right_Separator float32\n",
      "Stimulus_01 coucou g.jpg float32\n",
      "Stimulus_01 neutre3.avi float32\n",
      "Stimulus_01vnvg151201b1.avi float32\n",
      "Stimulus_02 coucou d.jpg float32\n",
      "Stimulus_02 devant.jpg float32\n",
      "Stimulus_02 neutre visage gris.jpg float32\n",
      "Stimulus_03 devant.jpg float32\n",
      "Stimulus_03 regard chien g.jpg float32\n",
      "Stimulus_03 vole triste vs joie1.avi float32\n",
      "Stimulus_04 b joie triste - copie.jpg float32\n",
      "Stimulus_04 regard chien d.jpg float32\n",
      "Stimulus_04 tete chien g.jpg float32\n",
      "Stimulus_05 sophie sous l'eau joie vs triste1.avi float32\n",
      "Stimulus_05 tete chien d.jpg float32\n",
      "Stimulus_05 tete point chien g.jpg float32\n",
      "Stimulus_06 a triste joie.jpg float32\n",
      "Stimulus_06 devant point chien g.jpg float32\n",
      "Stimulus_06 tete point chien d.jpg float32\n",
      "Stimulus_07 devant point chien d.jpg float32\n",
      "Stimulus_07 devant.jpg float32\n",
      "Stimulus_07 tombe joie vs triste2.avi float32\n",
      "Stimulus_08 b triste joie.jpg float32\n",
      "Stimulus_08 devant.jpg float32\n",
      "Stimulus_08 voc chien g.jpg float32\n",
      "Stimulus_09 cadeau dernier1.avi float32\n",
      "Stimulus_09 voc chien d.jpg float32\n",
      "Stimulus_09 voc devant g.jpg float32\n",
      "Stimulus_1 coucou D.jpg float32\n",
      "Stimulus_1 coucou D.png float32\n",
      "Stimulus_10 a joie triste.jpg float32\n",
      "Stimulus_10 voc devant.jpg float32\n",
      "Stimulus_11 devant.jpg float32\n",
      "Stimulus_11 punition orale triste vs joie1.avi float32\n",
      "Stimulus_11 yeux chat G.png float32\n",
      "Stimulus_11 yeux chat d.jpg float32\n",
      "Stimulus_11 yeux chat gauche.jpg float32\n",
      "Stimulus_12 a triste joie - copie.jpg float32\n",
      "Stimulus_12 tete chat G.png float32\n",
      "Stimulus_12 tete chat droite.jpg float32\n",
      "Stimulus_12 tete chat gauche.jpg float32\n",
      "Stimulus_12 yeux chat gauche.jpg float32\n",
      "Stimulus_13 bonbons triste vs joie1.avi float32\n",
      "Stimulus_13 tete chat gauche.jpg float32\n",
      "Stimulus_13 tete pointage chat G.png float32\n",
      "Stimulus_13 tete pointage chat droite.jpg float32\n",
      "Stimulus_13 tete pointage chat gauche.jpg float32\n",
      "Stimulus_14 b joie triste.jpg float32\n",
      "Stimulus_14 devant point chat G.png float32\n",
      "Stimulus_14 devant point chat droite.jpg float32\n",
      "Stimulus_14 devant point chat gauche.jpg float32\n",
      "Stimulus_14 tete pointage chat gauche.jpg float32\n",
      "Stimulus_15 devant - Copie.jpg float32\n",
      "Stimulus_15 devant point chat gauche.jpg float32\n",
      "Stimulus_15 devant.jpg float32\n",
      "Stimulus_15 devant.png float32\n",
      "Stimulus_16 devant.jpg float32\n",
      "Stimulus_16 voc chat G.png float32\n",
      "Stimulus_16 voc chat gauche.jpg float32\n",
      "Stimulus_16 voc droite chat.jpg float32\n",
      "Stimulus_17 voc chat gauche.jpg float32\n",
      "Stimulus_17 voc devant G.png float32\n",
      "Stimulus_17 voc devant d.jpg float32\n",
      "Stimulus_17 voc devant.jpg float32\n",
      "Stimulus_18 au revoir.jpg float32\n",
      "Stimulus_18 au revoir.png float32\n",
      "Stimulus_18 aurevoir.jpg float32\n",
      "Stimulus_18 voc devant.jpg float32\n",
      "Stimulus_19 aurevoir.jpg float32\n",
      "Stimulus_2 devant.jpg float32\n",
      "Stimulus_2 devant.png float32\n",
      "Stimulus_20 eye tracking (ballon droite).avi float32\n",
      "Stimulus_20 eye tracking (ballon gauche).avi float32\n",
      "Stimulus_21 neutre4.avi float32\n",
      "Stimulus_21 neutre5.avi float32\n",
      "Stimulus_22 neutre visage gris.jpg float32\n",
      "Stimulus_23 bonbons triste vs joie2.avi float32\n",
      "Stimulus_23 vole triste vs joie4.avi float32\n",
      "Stimulus_24 a triste joie.jpg float32\n",
      "Stimulus_24 b joie triste.jpg float32\n",
      "Stimulus_25 punition orale triste vs joie2.avi float32\n",
      "Stimulus_25 sophie sous l'eau joie vs triste4.avi float32\n",
      "Stimulus_26 a triste joie.jpg float32\n",
      "Stimulus_26 b joie triste.jpg float32\n",
      "Stimulus_27 cadeau dernier2.avi float32\n",
      "Stimulus_27 tombe joie vs triste5.avi float32\n",
      "Stimulus_28 b triste joie.jpg float32\n",
      "Stimulus_29 tombe joie vs triste3.avi float32\n",
      "Stimulus_3 regard chien D.jpg float32\n",
      "Stimulus_3 regard chien D.png float32\n",
      "Stimulus_30 a joie triste.jpg float32\n",
      "Stimulus_31 punition orale triste vs joie4.avi float32\n",
      "Stimulus_31 sophie sous l'eau joie vs triste2.avi float32\n",
      "Stimulus_32 b joie triste - copie.jpg float32\n",
      "Stimulus_33 vole triste vs joie2.avi float32\n",
      "Stimulus_34 a triste joie - copie.jpg float32\n",
      "Stimulus_4 tete chien D.jpg float32\n",
      "Stimulus_4 tete chien D.png float32\n",
      "Stimulus_5 tete point chien D.jpg float32\n",
      "Stimulus_5 tete point chien D.png float32\n",
      "Stimulus_6 devant point chien D.jpg float32\n",
      "Stimulus_6 devant point chien D.png float32\n",
      "Stimulus_7 devant - Copie.jpg float32\n",
      "Stimulus_7 devant.png float32\n",
      "Stimulus_8 voc chien D.jpg float32\n",
      "Stimulus_8 voc chien D.png float32\n",
      "Stimulus_9 voc devant D.png float32\n",
      "Stimulus_9 voc devant.jpg float32\n",
      "Stimulus_Eye Tracking (ballon droite).avi float32\n",
      "Stimulus_Eye Tracking (ballon gauche).avi float32\n",
      "Stimulus_Federica Final_WMV_3000Kbps_720p.avi float32\n",
      "Stimulus_NoImage float32\n",
      "Stimulus_VNVD151207.avi float32\n",
      "Stimulus_VNVG151201b.avi float32\n",
      "Stimulus_fede invisible d avi mpeg4-pcm.avi float32\n"
     ]
    }
   ],
   "source": [
    "# train test split. inf√∏r ogs√• evt padding\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming your data is loaded into a variable called 'df_encoded'\n",
    "# Modify the following line based on the actual column name of 'Class'\n",
    "\n",
    "# Extract the unique participant IDs\n",
    "participant_ids = df_encoded['Participant'].unique()\n",
    "\n",
    "# Split participant IDs into train and test sets\n",
    "train_participant_ids, test_participant_ids = train_test_split(participant_ids, test_size=0.34, random_state=3)\n",
    "\n",
    "# Filter data based on participant IDs\n",
    "train_data = df_encoded[np.isin(df_encoded['Participant'], train_participant_ids)]\n",
    "test_data = df_encoded[np.isin(df_encoded['Participant'], test_participant_ids)]\n",
    "\n",
    "test_data_participants = test_data['Participant']\n",
    "\n",
    "# Extract 'Class' column index dynamically and \n",
    "class_column_index = df_encoded.columns.get_loc('Class')\n",
    "participant_column_index = df_encoded.columns.get_loc('Participant')\n",
    "\n",
    "\n",
    "# Extract 'Class' values for train and test\n",
    "train_labels = train_data.iloc[:, class_column_index].values\n",
    "test_labels = test_data.iloc[:, class_column_index].values\n",
    "\n",
    "\n",
    "train_labels = pd.get_dummies(train_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "test_labels = pd.get_dummies(test_labels, columns=['Class'], prefix=['Class']) # one hot encoding\n",
    "\n",
    "\n",
    "# Drop the 'Class' and 'Participant' column from the data\n",
    "train_data = train_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "test_data = test_data.drop(columns=['Class', 'Participant', 'Trial'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Convert data into tensors with 60 samples each\n",
    "def create_tensors(data, labels, samples_per_tensor=60):\n",
    "    num_tensors = len(data) // samples_per_tensor\n",
    "    data_tensors = np.array_split(data[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    labels_tensors = np.array_split(labels[:num_tensors * samples_per_tensor], num_tensors)\n",
    "    return np.stack(data_tensors), np.stack(labels_tensors) #, np.expand_dims(np.stack(labels_tensors), axis=-1)\n",
    "\n",
    "train_data_tensors, train_label_tensors = create_tensors(train_data.values, train_labels)\n",
    "test_data_tensors, test_label_tensors = create_tensors(test_data.values, test_labels)\n",
    "\n",
    "test_data_participants_tensor, lol = create_tensors(test_data_participants.values, test_labels)\n",
    "\n",
    "# checking if everythin looks good\n",
    "print(train_data_tensors.shape)\n",
    "print(test_data_tensors.shape)\n",
    "print(train_label_tensors.shape)\n",
    "print(test_label_tensors.shape)\n",
    "\n",
    "#checking up on my data before feeding it to network.\n",
    "for i in train_data.columns:\n",
    "    print(i, train_data.dtypes[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 60, 126)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print(X.shape)\n",
    "\n",
    "indices = torch.randperm(len(train_data_tensors))[:200]\n",
    "\n",
    "lort = train_data_tensors[indices] # making a subset of 200\n",
    "\n",
    "lort.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "382/928 [===========>..................] - ETA: 4s - loss: 0.4360 - accuracy: 0.8011"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 28\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model\n\u001b[1;32m     26\u001b[0m model \u001b[38;5;241m=\u001b[39m classification_model()\n\u001b[0;32m---> 28\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodelus1.h5\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Saving the history of the model\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "# Define the LSTM model\n",
    "\n",
    "input_shape = (60, 126)\n",
    "dropout = 0.2\n",
    "learning_rate = 0.001\n",
    "\n",
    "\n",
    "def classification_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add an LSTM layer with, for example, 50 units\n",
    "    model.add(LSTM(units=60, input_shape=input_shape, return_sequences=True))\n",
    "\n",
    "    # Add a Dense layer with the number of classes as the output dimension and activation function\n",
    "    model.add(Dense(units=50))\n",
    "\n",
    "    model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "    # Compile the model with an optimizer, loss function, and metrics\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = classification_model()\n",
    "\n",
    "history = model.fit(train_data_tensors, train_label_tensors, epochs = 15, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "\n",
    "model.save('modelus1.h5')\n",
    "\n",
    "# Saving the history of the model\n",
    "import pickle\n",
    "\n",
    "with open('modelus1_history', 'wb') as file_pi:\n",
    "    pickle.dump(history.history, file_pi)\n",
    "    \n",
    "\n",
    "# Display a summary of the model's architecture\n",
    "model.summary()\n",
    "\n",
    "preds = model.predict(test_data_tensors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reloading Tuner from my_dir/helloworld/tuner0.json\n",
      "\n",
      "Search: Running Trial #3\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "384               |352               |units\n",
      "0.45              |0                 |dropout\n",
      "0.00305           |0.00049571        |learning_rate\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "498/928 [===============>..............] - ETA: 34s - loss: 0.4768 - accuracy: 0.7800"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 33\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mkerastuner\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtuners\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomSearch\n\u001b[1;32m     25\u001b[0m tuner \u001b[38;5;241m=\u001b[39m RandomSearch(\n\u001b[1;32m     26\u001b[0m     MyHyperModel(),\n\u001b[1;32m     27\u001b[0m     objective\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     30\u001b[0m     directory\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmy_dir\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     31\u001b[0m     project_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhelloworld\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[43mtuner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_label_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m15\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_data_tensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_label_tensors\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     35\u001b[0m best_model \u001b[38;5;241m=\u001b[39m tuner\u001b[38;5;241m.\u001b[39mget_best_models(num_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;66;03m# Modify the output layer to have the same shape as the labels\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:233\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 233\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_try_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_trial_end(trial)\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_search_end()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:273\u001b[0m, in \u001b[0;36mBaseTuner._try_run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_try_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_and_update_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m         trial\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m trial_module\u001b[38;5;241m.\u001b[39mTrialStatus\u001b[38;5;241m.\u001b[39mCOMPLETED\n\u001b[1;32m    275\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/base_tuner.py:238\u001b[0m, in \u001b[0;36mBaseTuner._run_and_update_trial\u001b[0;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_and_update_trial\u001b[39m(\u001b[38;5;28mself\u001b[39m, trial, \u001b[38;5;241m*\u001b[39mfit_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_kwargs):\n\u001b[0;32m--> 238\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mget_trial(trial\u001b[38;5;241m.\u001b[39mtrial_id)\u001b[38;5;241m.\u001b[39mmetrics\u001b[38;5;241m.\u001b[39mexists(\n\u001b[1;32m    240\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moracle\u001b[38;5;241m.\u001b[39mobjective\u001b[38;5;241m.\u001b[39mname\n\u001b[1;32m    241\u001b[0m     ):\n\u001b[1;32m    242\u001b[0m         \u001b[38;5;66;03m# The oracle is updated by calling `self.oracle.update_trial()` in\u001b[39;00m\n\u001b[1;32m    243\u001b[0m         \u001b[38;5;66;03m# `Tuner.run_trial()`. For backward compatibility, we support this\u001b[39;00m\n\u001b[1;32m    244\u001b[0m         \u001b[38;5;66;03m# use case. No further action needed in this case.\u001b[39;00m\n\u001b[1;32m    245\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    246\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe use case of calling \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    247\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`self.oracle.update_trial(trial_id, metrics)` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    253\u001b[0m             stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[1;32m    254\u001b[0m         )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:314\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    312\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    313\u001b[0m     copied_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcallbacks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m callbacks\n\u001b[0;32m--> 314\u001b[0m     obj_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_build_and_fit_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcopied_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    316\u001b[0m     histories\u001b[38;5;241m.\u001b[39mappend(obj_value)\n\u001b[1;32m    317\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m histories\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/tuner.py:233\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    231\u001b[0m hp \u001b[38;5;241m=\u001b[39m trial\u001b[38;5;241m.\u001b[39mhyperparameters\n\u001b[1;32m    232\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 233\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhypermodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;66;03m# Save the build config for model loading later.\u001b[39;00m\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mmulti_backend():\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras_tuner/src/engine/hypermodel.py:149\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, hp, model, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    126\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    127\u001b[0m \n\u001b[1;32m    128\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;124;03m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Hypertuning the model\n",
    "from kerastuner import HyperModel\n",
    "from tensorflow import keras\n",
    "\n",
    "num_classes = 2  # Define the number of classes\n",
    "\n",
    "class MyHyperModel(HyperModel):\n",
    "    def build(self, hp):\n",
    "        model = keras.Sequential()\n",
    "        model.add(keras.layers.LSTM(\n",
    "            units=hp.Int('units', min_value=32, max_value=512, step=32),\n",
    "            input_shape=(60, 126, ), return_sequences=True))\n",
    "        model.add(keras.layers.Dropout(\n",
    "            rate=hp.Float('dropout', min_value=0.0, max_value=0.5, default=0.25, step=0.05)))\n",
    "        model.add(keras.layers.Dense(num_classes, activation='sigmoid'))\n",
    "        model.compile(\n",
    "            optimizer=keras.optimizers.Adam(\n",
    "                hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
    "            loss='binary_crossentropy',\n",
    "            metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "from kerastuner.tuners import RandomSearch\n",
    "\n",
    "tuner = RandomSearch(\n",
    "    MyHyperModel(),\n",
    "    objective='val_accuracy',\n",
    "    max_trials=10,\n",
    "    executions_per_trial=3,\n",
    "    directory='my_dir',\n",
    "    project_name='helloworld')\n",
    "\n",
    "tuner.search(train_data_tensors, train_label_tensors, epochs = 15, batch_size= 10, validation_data= (test_data_tensors, test_label_tensors))\n",
    "\n",
    "best_model = tuner.get_best_models(num_models=1)[0]\n",
    "\n",
    "# Modify the output layer to have the same shape as the labels\n",
    "best_model.add(Dense(num_classes, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB3lElEQVR4nO3dd3gU5d7G8e+mF5JASIdAAJHepESKFZQmioJSVIoIFooSjwpKs4EVscLRV9CjIIgCFgSFWBClGaQJRHpPQihJSEjdef8YWExCSSDJpNyf69oru7Ozs79ZQ/b2mafYDMMwEBEREREHJ6sLEBERESltFJBERERE8lBAEhEREclDAUlEREQkDwUkERERkTwUkERERETyUEASERERyUMBSURERCQPBSQRERGRPBSQRKRUsdlsTJo0qdCv27t3LzabjY8//rjIaxKRikcBSUTy+fjjj7HZbNhsNlauXJnvecMwCA8Px2azcdttt1lQYdH4/vvvsdlshIWFYbfbrS5HREoRBSQRuSAPDw/mzJmTb/uvv/7KwYMHcXd3t6CqojN79mwiIiI4cuQIP/30k9XliEgpooAkIhfUrVs35s+fT3Z2dq7tc+bMoWXLloSEhFhU2ZVLTU3l66+/JioqihYtWjB79myrS7qg1NRUq0sQqXAUkETkgvr168exY8dYtmyZY1tmZiZffvkl/fv3P+9rUlNTeeKJJwgPD8fd3Z169erx+uuvYxhGrv0yMjIYPXo0gYGB+Pj4cPvtt3Pw4MHzHvPQoUM88MADBAcH4+7uTqNGjZg5c+YVndvChQs5ffo0d999N3379mXBggWkp6fn2y89PZ1JkyZx9dVX4+HhQWhoKHfddRe7du1y7GO323nrrbdo0qQJHh4eBAYG0qVLF/7880/g4v2j8va5mjRpEjabja1bt9K/f3+qVKlChw4dANi0aRODBg2idu3aeHh4EBISwgMPPMCxY8fO+5kNGTKEsLAw3N3dqVWrFo888giZmZns3r0bm83Gm2++me91f/zxBzabjc8//7ywH6lIueJidQEiUnpFRETQtm1bPv/8c7p27QrAkiVLSEpKom/fvrz99tu59jcMg9tvv52ff/6ZIUOG0Lx5c3744QeefPJJDh06lOsL+cEHH+Szzz6jf//+tGvXjp9++onu3bvnqyE+Pp5rr70Wm83GiBEjCAwMZMmSJQwZMoTk5GQef/zxyzq32bNnc9NNNxESEkLfvn0ZM2YM3377LXfffbdjn5ycHG677Taio6Pp27cvjz32GCkpKSxbtowtW7ZQp04dAIYMGcLHH39M165defDBB8nOzua3335j9erVtGrV6rLqu/vuu6lbty6TJ092hMtly5axe/duBg8eTEhICH///TcffPABf//9N6tXr8ZmswFw+PBh2rRpw8mTJxk2bBj169fn0KFDfPnll6SlpVG7dm3at2/P7NmzGT16dL7PxcfHhzvuuOOy6hYpNwwRkTxmzZplAMa6deuMd9991/Dx8THS0tIMwzCMu+++27jpppsMwzCMmjVrGt27d3e8btGiRQZgvPjii7mO17t3b8Nmsxk7d+40DMMwNmzYYADGo48+mmu//v37G4AxceJEx7YhQ4YYoaGhRmJiYq59+/bta/j5+Tnq2rNnjwEYs2bNuuT5xcfHGy4uLsaHH37o2NauXTvjjjvuyLXfzJkzDcCYOnVqvmPY7XbDMAzjp59+MgBj1KhRF9znYrXlPd+JEycagNGvX798+54913/7/PPPDcBYsWKFY9uAAQMMJycnY926dRes6b///a8BGNu2bXM8l5mZaQQEBBgDBw7M9zqRikaX2ETkou655x5Onz7Nd999R0pKCt99990FL699//33ODs7M2rUqFzbn3jiCQzDYMmSJY79gHz75W0NMgyDr776ih49emAYBomJiY5b586dSUpKYv369YU+p7lz5+Lk5ESvXr0c2/r168eSJUs4ceKEY9tXX31FQEAAI0eOzHeMs601X331FTabjYkTJ15wn8vx8MMP59vm6enpuJ+enk5iYiLXXnstgONzsNvtLFq0iB49epy39epsTffccw8eHh65+l798MMPJCYmct9991123SLlhQKSiFxUYGAgnTp1Ys6cOSxYsICcnBx69+593n337dtHWFgYPj4+ubY3aNDA8fzZn05OTo5LVGfVq1cv1+OjR49y8uRJPvjgAwIDA3PdBg8eDEBCQkKhz+mzzz6jTZs2HDt2jJ07d7Jz505atGhBZmYm8+fPd+y3a9cu6tWrh4vLhXsj7Nq1i7CwMPz9/Qtdx8XUqlUr37bjx4/z2GOPERwcjKenJ4GBgY79kpKSAPMzS05OpnHjxhc9fuXKlenRo0euUYqzZ8+mWrVq3HzzzUV4JiJlk/ogicgl9e/fn6FDhxIXF0fXrl2pXLlyibzv2bmJ7rvvPgYOHHjefZo2bVqoY+7YsYN169YBULdu3XzPz549m2HDhhWy0ou7UEtSTk7OBV/z79ais+655x7++OMPnnzySZo3b06lSpWw2+106dLlsuZxGjBgAPPnz+ePP/6gSZMmfPPNNzz66KM4Oen/nUUUkETkku68804eeughVq9ezbx58y64X82aNVm+fDkpKSm5WpG2b9/ueP7sT7vd7mihOSs2NjbX8c6OcMvJyaFTp05Fci6zZ8/G1dWVTz/9FGdn51zPrVy5krfffpv9+/dTo0YN6tSpw5o1a8jKysLV1fW8x6tTpw4//PADx48fv2ArUpUqVQA4efJkru1nW9QK4sSJE0RHR/Pcc88xYcIEx/YdO3bk2i8wMBBfX1+2bNlyyWN26dKFwMBAZs+eTWRkJGlpadx///0FrkmkPNP/JojIJVWqVInp06czadIkevToccH9unXrRk5ODu+++26u7W+++SY2m80xEu7sz7yj4KZNm5brsbOzM7169eKrr7467xf+0aNHC30us2fP5rrrrqNPnz707t071+3JJ58EcAxx79WrF4mJifnOB3CMLOvVqxeGYfDcc89dcB9fX18CAgJYsWJFrufff//9Atd9NswZeaZLyPuZOTk50bNnT7799lvHNAPnqwnAxcWFfv368cUXX/Dxxx/TpEmTQrfIiZRXakESkQK50CWuf+vRowc33XQTzz77LHv37qVZs2b8+OOPfP311zz++OOOPkfNmzenX79+vP/++yQlJdGuXTuio6PZuXNnvmO+/PLL/Pzzz0RGRjJ06FAaNmzI8ePHWb9+PcuXL+f48eMFPoc1a9awc+dORowYcd7nq1WrxjXXXMPs2bN5+umnGTBgAP/73/+Iiopi7dq1XHfddaSmprJ8+XIeffRR7rjjDm666Sbuv/9+3n77bXbs2OG43PXbb79x0003Od7rwQcf5OWXX+bBBx+kVatWrFixgn/++afAtfv6+nL99dfz6quvkpWVRbVq1fjxxx/Zs2dPvn0nT57Mjz/+yA033MCwYcNo0KABR44cYf78+axcuTLXJdIBAwbw9ttv8/PPP/PKK68UuB6Rcs+6AXQiUlr9e5j/xeQd5m8YhpGSkmKMHj3aCAsLM1xdXY26desar732mmN4+VmnT582Ro0aZVStWtXw9vY2evToYRw4cCDfsHfDMIflDx8+3AgPDzdcXV2NkJAQo2PHjsYHH3zg2Kcgw/xHjhxpAMauXbsuuM+kSZMMwNi4caNhGObQ+meffdaoVauW47179+6d6xjZ2dnGa6+9ZtSvX99wc3MzAgMDja5duxoxMTGOfdLS0owhQ4YYfn5+ho+Pj3HPPfcYCQkJFxzmf/To0Xy1HTx40LjzzjuNypUrG35+fsbdd99tHD58+Lyf2b59+4wBAwYYgYGBhru7u1G7dm1j+PDhRkZGRr7jNmrUyHBycjIOHjx4wc9FpKKxGUae9loREalQWrRogb+/P9HR0VaXIlJqqA+SiEgF9ueff7JhwwYGDBhgdSkipYpakEREKqAtW7YQExPDG2+8QWJiIrt378bDw8PqskRKDbUgiYhUQF9++SWDBw8mKyuLzz//XOFIJA+1IImIiIjkoRYkERERkTwUkERERETy0ESRl8lut3P48GF8fHyuaMVuERERKTmGYZCSkkJYWNhF1x1UQLpMhw8fJjw83OoyRERE5DIcOHCA6tWrX/B5BaTLdHYhzgMHDuDr62txNSIiIlIQycnJhIeH51pQ+3wUkC7T2ctqvr6+CkgiIiJlzKW6x6iTtoiIiEgeCkgiIiIieSggiYiIiOShPkjFLCcnh6ysLKvLKJNcXV1xdna2ugwREamAFJCKiWEYxMXFcfLkSatLKdMqV65MSEiI5poSEZESpYBUTM6Go6CgILy8vPQFX0iGYZCWlkZCQgIAoaGhFlckIiIViQJSMcjJyXGEo6pVq1pdTpnl6ekJQEJCAkFBQbrcJiIiJUadtIvB2T5HXl5eFldS9p39DNWPS0RESpICUjHSZbUrp89QRESsoIAkIiIikocCkhSriIgIpk2bZnUZIiIihaKAJIB5Ketit0mTJl3WcdetW8ewYcOKtlgREZFiplFsAsCRI0cc9+fNm8eECROIjY11bKtUqZLjvmEY5OTk4OJy6V+fwMDAoi1URKQEHE/NxMkGldxdcHFWW0JFpIAkAISEhDju+/n5YbPZHNt++eUXbrrpJr7//nvGjRvH5s2b+fHHHwkPDycqKorVq1eTmppKgwYNmDJlCp06dXIcKyIigscff5zHH38cMFuqPvzwQxYvXswPP/xAtWrVeOONN7j99ttL9HxFRPLam5jK4s1HWLzpCFuPJDu2e7s54+Phiq+ni/nTw/zp4+GCr+eZn/967Ot4bG7zcnPWgJMySAGpBBiGwemsHEve29O16P5hjhkzhtdff53atWtTpUoVDhw4QLdu3XjppZdwd3fnf//7Hz169CA2NpYaNWpc8DjPPfccr776Kq+99hrvvPMO9957L/v27cPf379I6hQRKah9x86For8PJ593n9TMHFIzc4g7/9OX5Oxkyx2izvzMG7p8cz12pYa/F35erldwdnIlFJBKwOmsHBpO+MGS9976fGe83IrmP/Pzzz/PLbfc4njs7+9Ps2bNHI9feOEFFi5cyDfffMOIESMueJxBgwbRr18/ACZPnszbb7/N2rVr6dKlS5HUKSJyMfuPpbF48xG+33yEzYeSHNudnWy0q1OV7k1CubVRCD4eLqSkZ5OSnkXy6TM/07NITs8m+XQWKenZJKef+XnmcUrGv/fNJsdukGM3OJmWxcm0ws/nVr2KJ43D/GhczZdG1fxoHOZHoI97UX4ccgEKSFJgrVq1yvX41KlTTJo0icWLF3PkyBGys7M5ffo0+/fvv+hxmjZt6rjv7e2Nr6+vY0kREZHicOD4uVC06WDuUNS2dlW6Nw2lc6MQ/L3dcr3O39st37aCOnv1oKDh6uzjlHQzTCWkZHDwxGkOnjjN0r/jHMcN8nGncTU/GoedCU3V/Ajz89BlvCKmgFQCPF2d2fp8Z8veu6h4e3vnevyf//yHZcuW8frrr3PVVVfh6elJ7969yczMvOhxXF1zNxnbbDbsdnuR1SkiAnDwRBrfn7l8tvFfocjJBm3rVKV7kzA6NwqmaqXiaZGx2Wx4ubng5eZCiJ9HoV+flJbF30eS+PtQMlsOJ7HlUBK7E1NJSMngp+0J/LT93P9YVvZypXGYH42q+Z5pcfKjpr8XTk4KTZdLAakEnP1HUt78/vvvDBo0iDvvvBMwW5T27t1rbVEiUqEdOnma7zcd4bvNR9h44KRju5MNrv1XS1FAMYWiouTn5Uq7OgG0qxPg2Jaakc32uGS2HEpmy6EkthxOZkd8CifTsli5M5GVOxMd+1Zyd6FhqG+u0FQn0LvUjcrLyrFzIi2T46nm7URqFsfTMjl+KpO7W1UnrLKnJXWVv29tKTF169ZlwYIF9OjRA5vNxvjx49USJCIl7vDJ02ZL0eYj/LX/pGO7zQaRtfzp3jSMLo1CykXfHW93F1rW9KdlzXODWtKzctgRf8rRyrTlcDLbjyRzKiObtXuPs3bvcce+7i5O1A/1pXGY75nLdH5cHVIJd5eiudpgGAbJ6dn/Cjtngk/av+7/6/Gx1ExS0rMveLxralZWQJKyZ+rUqTzwwAO0a9eOgIAAnn76aZKTL3OYh4hIIRxJOs33m+NYvOkw6/OEojYR/tzWNJTOjUMI8in8pa2yxsPVmSbV/WhS3c+xLTvHzq6jqWcCk3mZ7u/DSaRm5rDxwMlcrWsuTjbqBvucC03VfGkQ6ouXmwvpWTnnwk6uVh4z3JzddiI1i2OpmZxMyyTbbhT6HJxsUMXLjSrebvh7mf2+qni7UdXbulBrMwyj8GciJCcn4+fnR1JSEr6+vrmeS09PZ8+ePdSqVQsPj/L/j7M46bMUkbPiktIdLUUx+044ttts0PpMKOrSKIQgX/2tOB+73WDf8bRcoWnL4aTzjq6z2cw+rGmZlzdFjbebM/6VzLBT5UxH97P3q3r/a9uZ7b6erjiXUH+pi31//5takEREpNSKTzZD0febj7Bub55QVNOfbk1C6NoklGCFoktycrJRK8CbWgHe9GgWBpiXxA6dPM3fh5P5+8zluS2HkkhIyXCEIxcn27lg43Uu2JitPa74V3I/E35cqertTmUvVzyKcICQVRSQRESkVEk8lcHiTebos3X7jvPv6xytalahe9NQujYOvayRYZKbzWajehUvqlfxonOjcysqJKSkk5aRg38lN3zcXSrkFAIKSCIiYrnsHDu/xB5lfswBorcl5OrH0rJmFbo3CaVrkxBC/azpsFvRBPl4gI/VVVhLAUlERCyzM+EU82MOsGD9IY6mZDi2N6vuR49mYXRrEmrZKCap2BSQRESkRKWkZ7F40xG++PNArhFoVb3duLNFNe5uFU69kArefCGWU0ASEZFiZxgGa/Yc54s/D7Bkc5xjAW9nJxs31Qvk7lbh3FQvCDeX0jWJoVRcCkgiIlJsDp88zVcxB/ly/UH2HUtzbK8T6M09rcK585pqFWKuIil7FJBERKRIpWflsGxrPPNjDvLbjqOOUWiV3F3o0SyU3i3DuaZG5Qo5MkrKDgUkEREpElsOJTH/zwMs2nCYpNPnJh+MrOXPPa3C6dokpFyuSynlk+UXe9977z0iIiLw8PAgMjKStWvXXnDfrKwsnn/+eerUqYOHhwfNmjVj6dKlufaZMmUKrVu3xsfHh6CgIHr27ElsbGyufW688UZsNluu28MPP1ws5yciUp6dSM1k1u976PrWb9z2zko+WbWPpNNZhPp5MPLmq/j1yRuZ91BberWsrnAkZYqlv63z5s0jKiqKGTNmEBkZybRp0+jcuTOxsbEEBQXl23/cuHF89tlnfPjhh9SvX58ffviBO++8kz/++IMWLVoA8OuvvzJ8+HBat25NdnY2zzzzDLfeeitbt27F29vbcayhQ4fy/PPPOx57eXkV/wmXYpdq6p44cSKTJk267GMvXLiQnj17XtbrRaR0ybEbrNhxlC//PMiyrfFk5piLVLs5O3Fro2DuaRVO+6sCSmzpCJHiYGlAmjp1KkOHDmXw4MEAzJgxg8WLFzNz5kzGjBmTb/9PP/2UZ599lm7dugHwyCOPsHz5ct544w0+++wzgHwtSh9//DFBQUHExMRw/fXXO7Z7eXkREhKCmI4cOeK4P2/ePCZMmJCr5a1SpUpWlCUipciexFS+jDnAVzGHiEtOd2xvXM2Xe1qFc3uzMCp7uVlYoUjRsewSW2ZmJjExMXTq1OlcMU5OdOrUiVWrVp33NRkZGfkWLPX09GTlypUXfJ+kpCQA/P39c22fPXs2AQEBNG7cmLFjx5KWlna+l+d67+Tk5Fy38iQkJMRx8/Pzw2az5do2d+5cGjRogIeHB/Xr1+f99993vDYzM5MRI0YQGhqKh4cHNWvWZMqUKQBEREQAcOedd2Kz2RyPRaRsSM3IZv6fB7hnxipuev0X3vt5F3HJ6VTxcmVQuwgWj+rAdyOvY0DbCIUjKVcsa0FKTEwkJyeH4ODgXNuDg4PZvn37eV/TuXNnpk6dyvXXX0+dOnWIjo5mwYIF5OScf7Vhu93O448/Tvv27WncuLFje//+/alZsyZhYWFs2rSJp59+mtjYWBYsWHDBeqdMmcJzzz13GWcKGAZkXTyAFRtXL3NVxyswe/ZsJkyYwLvvvkuLFi3466+/GDp0KN7e3gwcOJC3336bb775hi+++IIaNWpw4MABDhw4AMC6desICgpi1qxZdOnSBWfnsr+AoUh5ZxgGMftO8MWfB/hu0xHHoqVONrj+6kDuaRVOxwZBuLvo37OUX2Wqx9xbb73F0KFDqV+/PjabjTp16jB48GBmzpx53v2HDx/Oli1b8rUwDRs2zHG/SZMmhIaG0rFjR3bt2kWdOnXOe6yxY8cSFRXleJycnEx4eHjBCs9Kg8lhBdu3qD1zGNy8L73fRUycOJE33niDu+66C4BatWqxdetW/vvf/zJw4ED2799P3bp16dChAzabjZo1azpeGxgYCEDlypV1SVPEYjl2g2OnMkhIySAhJZ2E5Pz3j555nJVzbi20iKpe3N0qnF7XVNcCsVJhWBaQAgICcHZ2Jj4+Ptf2+Pj4C36RBgYGsmjRItLT0zl27BhhYWGMGTOG2rVr59t3xIgRfPfdd6xYsYLq1atftJbIyEgAdu7cecGA5O7ujru7e0FOrVxJTU1l165dDBkyhKFDhzq2Z2dn4+fnB8CgQYO45ZZbqFevHl26dOG2227j1ltvtapkkQonM9vO0VMZJCSnnwk8GRz91/2zASjxVAb/WgP2orzcnOneJJS7W4XTOqKK5iySCseygOTm5kbLli2Jjo52jG6y2+1ER0czYsSIi77Ww8ODatWqkZWVxVdffcU999zjeM4wDEaOHMnChQv55ZdfqFWr1iVr2bBhAwChoaGXfT4X5epltuRYwfXKRuedOnUKgA8//NARJM86e7nsmmuuYc+ePSxZsoTly5dzzz330KlTJ7788ssrem+Riu50Zo4ZblIyzrTw5L5/9EwAOp6aWeBjOtmgaiV3gnzO3jwI9nUn0Nfj3LYz912dLZ8JRsQyll5ii4qKYuDAgbRq1Yo2bdowbdo0UlNTHaPaBgwYQLVq1RwdftesWcOhQ4do3rw5hw4dYtKkSdjtdp566inHMYcPH86cOXP4+uuv8fHxIS4uDgA/Pz88PT3ZtWsXc+bMoVu3blStWpVNmzYxevRorr/+epo2bVo8J2qzXfFlLqsEBwcTFhbG7t27uffeey+4n6+vL3369KFPnz707t2bLl26cPz4cfz9/XF1db1gPzERyW3jgZO8/mMsGw6cJCU9u8Cvc3W2EVgpT9Dx8SDI17wffGa7v7cbLgo+IpdkaUDq06cPR48eZcKECcTFxdG8eXOWLl3q6Li9f/9+nJzO/UNOT09n3Lhx7N69m0qVKtGtWzc+/fRTKleu7Nhn+vTpgDkZ5L/NmjWLQYMG4ebmxvLlyx1hLDw8nF69ejFu3LhiP9+y6rnnnmPUqFH4+fnRpUsXMjIy+PPPPzlx4gRRUVFMnTqV0NBQWrRogZOTE/PnzyckJMTx3yUiIoLo6Gjat2+Pu7s7VapUsfaEREqhwydP89oPsSz861Cu7e4uTgT5uhPsCDseBOZp6QnycaeKlxtOmndIpMhY3kl7xIgRF7yk9ssvv+R6fMMNN7B169aLHs8wLn6BPTw8nF9//bVQNVZ0Dz74IF5eXrz22ms8+eSTeHt706RJEx5//HEAfHx8ePXVV9mxYwfOzs60bt2a77//3hFu33jjDaKiovjwww+pVq0ae/fute5kREqZUxnZ/PfXXXywYjcZ2eaEi3ddU40HO9SmWhVPfD1c1P9HxAI241KJQs4rOTkZPz8/kpKS8PX1zfVceno6e/bsoVatWvnmbZLC0Wcp5VWO3WD+nwd4/cd/SDyVAUCbWv6M696AptUrW1ucSDl2se/vf7O8BUlEpKJZuSORFxdvZXtcCgA1q3oxtmsDOjcKVmuRSCmhgCQiUkJ2JpxiyvfbiN6eAICvhwujOtZlQNsI3FzUcVqkNFFAEhEpZsdTM3lr+T98tmY/OXYDFycb911bk8c61qWKt5bnECmNFJBERIpJRnYOn/yxl3d+2ukYst+pQTBju9WnTqAWgBYpzRSQipH6v185fYZSFhmGwZItcUxZso0Dx08D0DDUl3HdG9DuqgCLqxORglBAKgaurq4ApKWl4enpaXE1ZVtamrnI79nPVKS023DgJC9+t5U/950AIMjHnf90rkeva6rjrHmKRMoMBaRi4OzsTOXKlUlIMDtienl5aWRKIRmGQVpaGgkJCVSuXNmxrIlIaXXo5GleW7qdRRvMZYU8XJ146Po6DLu+Nt7u+lMrUtboX20xObvg7tmQJJencuXKF1y8WKQ0OJWRzYxfdvHhb+cmeux1TXX+0/lqQv3UgixSVikgFRObzUZoaChBQUFkZWVZXU6Z5OrqqpYjKbUuNNHj+O4NaVLdz+LqRORKKSAVM2dnZ33Ji5QzeSd6jKjqxdhuDbi1oSZ6FCkvFJBERApoZ0IKk7/fzk//mujxsU5Xc/+1NTXRo0g5o4AkInIJx1Mzmbb8H2b/a6LH+9vWZNTNmuhRpLxSQBIRuYDzTfR4S8NgxnatT21N9ChSrikgiYjkccGJHm9rQLs6muhRpCJQQBIROSM5PYulW+L4fO1+/tp/EjAnenyycz3u0kSPIhWKApKIVGgZ2Tn8EnuUrzccYvm2BDLPzGV0dqLHh26ojZeb/lSKVDT6Vy8iFY7dbrB273G+3nCIxZuOkHymfxHAVUGV6Nk8jLtbhRPs62FhlSJiJQUkEakwth1JZtGGQ3y74TCHk9Id24N93bm9WRh3NK9GozBfzWUkIgpIIlK+HTp5mq83HOLrvw4TG5/i2O7j7kLXJiH0bF6NyNpV1b9IRHJRQBKRcudkWiaLNx/h678Os3bvccd2N2cnbqofSM/m1bipfhAerprlXkTOTwFJRMqF9Kwclm+LZ9Ffh/n1nwSycgwAbDaIrOVPz+bV6No4FD8vV4srFZGyQAFJRMqsHLvBH7sSWfTXYX74O45TGec6WzcI9aVn8zB6NAsjrLKnhVWKSFmkgCQiZYphGGw5ZHa2/mbjYY6mZDieq1bZkzuah9GzRTWuDvaxsEoRKesUkESkTNh3LJWvNxxm0YZD7D6a6the2cuV7k1C6dmiGi1rVMFJna1FpAgoIIlIqZV4KoPFm46waMMhx8zWAO4uTnRqGEzP5tW44epA3FycrCtSRMolBSQRKVVS0rOI3pbAog2H+G1HIjl2s7O1kw3aXxXAHc2r0blRMD4e6mwtIsVHAUlELHcyLZNlW+NZuiWO33YkkpljdzzXtLofdzSvRo9moQT5aGZrESkZCkgiYomjKRn88HccS7fEsWr3MUdLEUDtAG9uaxZGz+Zh1A6sZGGVIlJRKSCJSIk5fPI0S7eYoWjdvuMY5zIR9UN86No4lK5NQqgbVEnLfYiIpRSQRKRY7TuWypItcSzZEsfGAydzPdesuh9dGofSpXEItQK8rSlQROQ8LB/68d577xEREYGHhweRkZGsXbv2gvtmZWXx/PPPU6dOHTw8PGjWrBlLly4t9DHT09MZPnw4VatWpVKlSvTq1Yv4+PgiPzeRisgwDP6JT+Gt5Tvo+tZv3PDaL7y8ZDsbD5zEZoPWEVUYf1tDfh9zM1+P6MAjN9ZROBKRUsfSFqR58+YRFRXFjBkziIyMZNq0aXTu3JnY2FiCgoLy7T9u3Dg+++wzPvzwQ+rXr88PP/zAnXfeyR9//EGLFi0KfMzRo0ezePFi5s+fj5+fHyNGjOCuu+7i999/L9HzFykvDMPg78PJLNlyhCVb4nLNU+TsZOPa2v50aRxK50bB6mgtImWCzTD+3QugZEVGRtK6dWveffddAOx2O+Hh4YwcOZIxY8bk2z8sLIxnn32W4cOHO7b16tULT09PPvvsswIdMykpicDAQObMmUPv3r0B2L59Ow0aNGDVqlVce+21Bao9OTkZPz8/kpKS8PX1vaLPQaQsstsN/jpwkqVbjrD07zgOHD/teM7N2YkOdQPo0iiEWxoGU8XbzcJKRUTOKej3t2UtSJmZmcTExDB27FjHNicnJzp16sSqVavO+5qMjAw8PHL/36enpycrV64s8DFjYmLIysqiU6dOjn3q169PjRo1ChWQRCqi7Bw76/aeYOmWI/zwdzxxyemO5zxcnbjx6iC6NgnhpvpB+GqeIhEpwywLSImJieTk5BAcHJxre3BwMNu3bz/vazp37szUqVO5/vrrqVOnDtHR0SxYsICcnJwCHzMuLg43NzcqV66cb5+4uLgL1puRkUFGxrk1n5KTkwt8riJlWWa2nT92JbJ0SxzLtsZzLDXT8Vwldxdurh9E18Yh3FAvEC83jfsQkfKhTP01e+uttxg6dCj169fHZrNRp04dBg8ezMyZM4v9vadMmcJzzz1X7O8jUhqkZ+Ww4p+jLN0Sx/Jt8SSnZzue8/N05ZaGwXRtHEL7qwLwcHW2sFIRkeJhWUAKCAjA2dk53+ix+Ph4QkJCzvuawMBAFi1aRHp6OseOHSMsLIwxY8ZQu3btAh8zJCSEzMxMTp48masV6WLvCzB27FiioqIcj5OTkwkPDy/UOYuUdulZObzz0w4+/n0vqZk5ju0Bldzp3CiYLo1DuLZ2VVydLR8AKyJSrCz7K+fm5kbLli2Jjo52bLPb7URHR9O2bduLvtbDw4Nq1aqRnZ3NV199xR133FHgY7Zs2RJXV9dc+8TGxrJ///6Lvq+7uzu+vr65biLlScy+E3R/+zfe+3kXqZk5hPl5MLh9BF881JY1z3TkpTubcF3dQIUjEakQLL3EFhUVxcCBA2nVqhVt2rRh2rRppKamMnjwYAAGDBhAtWrVmDJlCgBr1qzh0KFDNG/enEOHDjFp0iTsdjtPPfVUgY/p5+fHkCFDiIqKwt/fH19fX0aOHEnbtm3VQVsqpNOZObz+Yywzf9+DYZitRS/c0YgujUM0m7WIVFiWBqQ+ffpw9OhRJkyYQFxcHM2bN2fp0qWOTtb79+/Hyenc/62mp6czbtw4du/eTaVKlejWrRuffvpprktllzomwJtvvomTkxO9evUiIyODzp078/7775fYeYuUFqt2HWPMgk3sO5YGwF3XVGPCbQ2p7KVh+SJSsVk6D1JZpnmQpCw7lZHNK0u28+nqfQCE+nkw+c4m3FQ//wStIiLlSamfB0lErLHin6OMXbCZQyfNiR37tanB2G71NW+RiMi/KCCJVBBJp7N4afFWvvjzIADVq3jySq+mtL8qwOLKRERKHwUkkQpg+dZ4nl20mfjkDGw2GNg2gic718PbXX8CRETOR38dRcqxE6mZTPr2b77ecBiAWgHevNq7Ka0j/C2uTESkdFNAEimnvt98hAlfbyHxVCZONhh6XW1G33K1Zr4WESkABSSRcuZoSgYTvt7Cki3m2oJXB1fi1d7NaB5e2drCRETKEAUkkXLCMAwWbTjEc99u5WRaFi5ONh69sQ7Db74Kdxe1GomIFIYCkkg5EJeUzrMLNxO9PQGARmG+vNq7KY3C/CyuTESkbFJAEinDDMPgiz8P8OJ320jJyMbN2YlRHa/ioRvqaM00EZEroIAkUkYdOJ7G2AWbWbkzEYBm4ZV5rXdTrg72sbgyEZGyTwFJpIyx2w0+W7OPl5dsJy0zB3cXJ/5zaz0e6FALZyctLisiUhQUkETKkL2JqTz11SbW7jkOQJsIf17p3ZRaAd4WVyYiUr4oIImUATl2g1m/7+H1H2NJz7Lj5ebM013qc/+1NXFSq5GISJFTQBIp5XbEp/Dkl5vYcOAkAO2vqsrLdzUl3N/L2sJERMoxBSSRUiorx84HK3bz1vIdZObY8XF34dnuDejTOhybTa1GIiLFSQFJpBTaejiZp77ayJZDyQDcVC+QyXc1IdTP0+LKREQqBgUkkVLm/37bzctLtpNtN/DzdGXS7Q3p2byaWo1EREqQApJIKfL1hkO8uHgbAF0ahfB8z0YE+XhYXJWISMWjgCRSSmw8cJKnvtwEwEM31GZMl/pqNRIRsYjWIhApBRKS0xn26Z9kZNvpWD+IpzorHImIWEkBScRi6Vk5DPs0hvjkDK4KqsS0vs01I7aIiMUUkEQsZBgGzyzczIYDJ/HzdOX/BrTCx8PV6rJERCo8BSQRC320cg8L1h/C2cnG+/deQ4SWDBERKRUUkEQs8ktsApO/N0esje/egPZXBVhckYiInKWAJGKBXUdPMfLzv7Ab0Ld1OAPbRVhdkoiI/IsCkkgJSzqdxdBP/iQlPZvWEVV4/o7GGrEmIlLKKCCJlKAcu8HIz/9id2IqYX4eTL+vJW4u+mcoIlLa6C+zSAl6eck2VvxzFA9XJz4Y0IqASu5WlyQiIuehgCRSQr6MOciHv+0B4I27m9O4mp/FFYmIyIUoIImUgPX7T/DMgs0AjLr5Kro3DbW4IhERuRgFJJFidiTpNA99GkNmjp1bGwbzeKerrS5JREQuQQFJpBilZ+Uw7H8xHE3JoH6ID2/2aY6TlhERESn1LA9I7733HhEREXh4eBAZGcnatWsvuv+0adOoV68enp6ehIeHM3r0aNLT0x3PR0REYLPZ8t2GDx/u2OfGG2/M9/zDDz9cbOcoFZNhGDz15SY2H0qiipcrHw5ohbe7i9VliYhIAVj613revHlERUUxY8YMIiMjmTZtGp07dyY2NpagoKB8+8+ZM4cxY8Ywc+ZM2rVrxz///MOgQYOw2WxMnToVgHXr1pGTk+N4zZYtW7jlllu4++67cx1r6NChPP/8847HXl5exXSWUlFN/3UX32w8jIuTjffvbUm4v37HRETKCksD0tSpUxk6dCiDBw8GYMaMGSxevJiZM2cyZsyYfPv/8ccftG/fnv79+wNma1G/fv1Ys2aNY5/AwMBcr3n55ZepU6cON9xwQ67tXl5ehISEFPUpiQCwfGs8r/0QC8Ck2xvRtk5ViysSEZHCsOwSW2ZmJjExMXTq1OlcMU5OdOrUiVWrVp33Ne3atSMmJsZxGW737t18//33dOvW7YLv8dlnn/HAAw/km6l49uzZBAQE0LhxY8aOHUtaWtpF683IyCA5OTnXTeR8/olP4bG5f2EYcN+1Nbjv2ppWlyQiIoVkWQtSYmIiOTk5BAcH59oeHBzM9u3bz/ua/v37k5iYSIcOHTAMg+zsbB5++GGeeeaZ8+6/aNEiTp48yaBBg/Idp2bNmoSFhbFp0yaefvppYmNjWbBgwQXrnTJlCs8991zhTlIqnBOpmTz4yZ+kZuZwbW1/JvZoZHVJIiJyGcpUj9FffvmFyZMn8/777xMZGcnOnTt57LHHeOGFFxg/fny+/T/66CO6du1KWFhYru3Dhg1z3G/SpAmhoaF07NiRXbt2UadOnfO+99ixY4mKinI8Tk5OJjw8vIjOTMqDrBw7w+esZ//xNKpX8eT9e1vi6mz5OAgREbkMlgWkgIAAnJ2diY+Pz7U9Pj7+gn2Dxo8fz/3338+DDz4ImOEmNTWVYcOG8eyzz+LkdO7LaN++fSxfvvyirUJnRUZGArBz584LBiR3d3fc3bUshFzYS4u38ceuY3i5OfN/A1vh7+1mdUkiInKZLPvfWzc3N1q2bEl0dLRjm91uJzo6mrZt2573NWlpablCEICzszNgDqn+t1mzZhEUFET37t0vWcuGDRsACA3V7MZyeT5fu5+P/9gLwJt9mlM/xNfagkRE5IpYeoktKiqKgQMH0qpVK9q0acO0adNITU11jGobMGAA1apVY8qUKQD06NGDqVOn0qJFC8cltvHjx9OjRw9HUAIzaM2aNYuBAwfi4pL7FHft2sWcOXPo1q0bVatWZdOmTYwePZrrr7+epk2bltzJS7mxds9xJny9BYAnbrmazo00OlJEpKyzNCD16dOHo0ePMmHCBOLi4mjevDlLly51dNzev39/rhajcePGYbPZGDduHIcOHSIwMJAePXrw0ksv5Tru8uXL2b9/Pw888EC+93Rzc2P58uWOMBYeHk6vXr0YN25c8Z6slEsHT6TxyGcxZOUYdG8Syoibr7K6JBERKQI2I++1KSmQ5ORk/Pz8SEpKwtdXl1MqorTMbHpNX8W2I8k0CvNl/sNt8XIrU+MeREQqnIJ+f2uIjchlsNsNnvhiI9uOJBNQyY0PBrRSOBIRKUcUkEQuwzs/7WTJljhcnW3MuK8l1Sp7Wl2SiIgUIQUkkUJauuUIby7/B4AXezamVYS/xRWJiEhRU0ASKYSth5MZPW8jAIPaRdCndQ2LKxIRkeKggCRSQMdOZTD0f39yOiuHDlcFMK57A6tLEhGRYqKAJFIAmdl2Hpm9nkMnT1Ozqhfv9m+Bi5YREREpt/QXXuQSDMNg4jd/s3bPcSq5u/B/A1pR2UvLiIiIlGcKSCKX8NnqfXy+dj82G7zVtzl1g32sLklERIqZApLIRfyxK5Hnvt0KwFOd69OxQbDFFYmISEnQzHZSqtjtBr/vSiQ1I4dAHzcCKrkTUMkdb/eS/1XdfyyN4bPXk203uKN5GA/fULvEaxAREWsoIEmpkZyexRNfbGTZ1vh8z3m5OZ8JS2dCk487gY6f54JUoE/RhKlTGdkM/d+fnEjLoml1P17p1RSbzXbFxxURkbJBAUlKhdi4FB769E/2HkvDzcWJhqG+HEvN4GhKBulZdtIyc9h/PI39x9MueSxPV2cCzrQ+nQ1R5n03R4g6G7K83ZzzBR+73WD0vA3ExqcQ6OPOB/e3wsPVubhOXURESiEFJLHc1xsOMearzZzOyqFaZU+m33cNTatXBswRZKmZOSSmZJB4ygxMiacyOHoqk8RTGSSmZHD0VMaZ+5mczsrhdFYOB46f5sDx05d8bw9Xp9yhqZI7SaczWbY1HjcXJz64vyUhfh7F/AmIiEhpo4AklsnKsTP5+23M+n0vANfVDeCtvi3w9z43hN5ms1HJ3YVK7i5EBHhf8pipGdn5g1SecJV4JlylZeaQnmXn4InTHDyRP0xNubMJLWpUKbLzFRGRskMBSSyRkJzO8DnrWbf3BADDb6pD1C31cHa6sn4+3u4ueLu7ULNqwcOUGZ4yc4WoptX96NWy+hXVIiIiZZcCkpS4dXuP8+js9RxNycDH3YU37mnGrY1CSryOwoQpERGpWBSQpMQYhsHHf+zlpcXbyLYbXB1ciRn3taR2YCWrSxMREclFAUlKRFpmNmMXbObrDYcB6NEsjFd6NcHLTb+CIiJS+ujbSYrdnsRUHv40htj4FFycbDzTrQGD20doXiERESm1FJCkWP34dxxPfLGRlIxsAn3cea//NbSp5W91WSIiIhelgCTFIsduMHVZLO/9vAuA1hFVeK//NQT5ak4hEREp/RSQpMgdT83ksbl/8duORAAGt4/gmW4NcHXW2sgiIlI2KCBJkdp08CSPfLaeQydP4+nqzMu9mnBH82pWlyUiIlIoCkhSZOat28/4r/8mM9tORFUvZtzfkvohvlaXJSIiUmgKSHLF0rNymPTN38xddwCATg2CmdqnGb4erhZXJiIicnkUkOSKHDyRxqOz17PpYBI2G/zn1no8ckMdnK5wyRARERErFbrXbEREBM8//zz79+8vjnqkDPltx1F6vLOSTQeTqOLlyieD2zD8pqsUjkREpMwrdEB6/PHHWbBgAbVr1+aWW25h7ty5ZGRkFEdtUkrZ7Qbv/byTgTPXciItiybV/Ph2ZAeuvzrQ6tJERESKxGUFpA0bNrB27VoaNGjAyJEjCQ0NZcSIEaxfv744apRSJDk9i4c+i+G1H2KxG9CnVTjzH25L9SpeVpcmIiJSZGyGYRhXcoCsrCzef/99nn76abKysmjSpAmjRo1i8ODB5XopieTkZPz8/EhKSsLXt2KM1IqNS+Hhz2LYk5iKm7MTz9/RiL5talhdloiISIEV9Pv7sjtpZ2VlsXDhQmbNmsWyZcu49tprGTJkCAcPHuSZZ55h+fLlzJkz53IPL6XM1xsOMearzZzOyqFaZU/ev/camoVXtrosERGRYlHoS2zr16/PdVmtUaNGbNmyhZUrVzJ48GDGjx/P8uXLWbhwYYGO99577xEREYGHhweRkZGsXbv2ovtPmzaNevXq4enpSXh4OKNHjyY9Pd3x/KRJk7DZbLlu9evXz3WM9PR0hg8fTtWqValUqRK9evUiPj6+sB9FhZCVY+e5b//msbkbOJ2VQ4erAvh2ZAeFIxERKdcK3YLUunVrbrnlFqZPn07Pnj1xdc0/102tWrXo27fvJY81b948oqKimDFjBpGRkUybNo3OnTsTGxtLUFBQvv3nzJnDmDFjmDlzJu3ateOff/5h0KBB2Gw2pk6d6tivUaNGLF++/NxJuuQ+zdGjR7N48WLmz5+Pn58fI0aM4K677uL3338vzEdR7iUkpzN8znrW7T0BwKM31uGJW+vhrFFqIiJSzhW6D9K+ffuoWbNmkbx5ZGQkrVu35t133wXAbrcTHh7OyJEjGTNmTL79R4wYwbZt24iOjnZse+KJJ1izZg0rV64EzBakRYsWsWHDhvO+Z1JSEoGBgcyZM4fevXsDsH37dho0aMCqVau49tprC1R7ee+DtG7vcR6dvZ6jKRn4uLvw+j3N6NwoxOqyRERErkhBv78LfYktISGBNWvW5Nu+Zs0a/vzzzwIfJzMzk5iYGDp16nSuGCcnOnXqxKpVq877mnbt2hETE+O4DLd7926+//57unXrlmu/HTt2EBYWRu3atbn33ntzzdkUExNDVlZWrvetX78+NWrUuOD7AmRkZJCcnJzrVh4ZhsGs3/fQ74PVHE3J4OrgSnw9or3CkYiIVCiFDkjDhw/nwIED+bYfOnSI4cOHF/g4iYmJ5OTkEBwcnGt7cHAwcXFx531N//79ef755+nQoQOurq7UqVOHG2+8kWeeecaxT2RkJB9//DFLly5l+vTp7Nmzh+uuu46UlBQA4uLicHNzo3LlygV+X4ApU6bg5+fnuIWHhxf4XMuSj1bu4blvt5JtN7itaSgLH21P7cBKVpclIiJSogodkLZu3co111yTb3uLFi3YunVrkRR1Ib/88guTJ0/m/fffZ/369SxYsIDFixfzwgsvOPbp2rUrd999N02bNqVz5858//33nDx5ki+++OKK3nvs2LEkJSU5bucLiWXd0ZQMpi3fAcATt1zNO/1a4O2u1WhERKTiKfS3n7u7O/Hx8dSuXTvX9iNHjuTrDH0xAQEBODs75xs9Fh8fT0jI+S/njB8/nvvvv58HH3wQgCZNmpCamsqwYcN49tlncXLKn/cqV67M1Vdfzc6dOwEICQkhMzOTkydP5mpFutj7gnne7u7uBT6/smjqsn84lZFNk2p+DL/pqnI9j5WIiMjFFLoF6dZbb3W0ppx18uRJnnnmGW655ZYCH8fNzY2WLVvm6nBtt9uJjo6mbdu2531NWlpavhDk7OwMmH1nzufUqVPs2rWL0NBQAFq2bImrq2uu942NjWX//v0XfN+KYOvhZOatM/tqjb+todZTExGRCq3QLUivv/46119/PTVr1qRFixYAbNiwgeDgYD799NNCHSsqKoqBAwfSqlUr2rRpw7Rp00hNTWXw4MEADBgwgGrVqjFlyhQAevTowdSpU2nRogWRkZHs3LmT8ePH06NHD0dQ+s9//kOPHj2oWbMmhw8fZuLEiTg7O9OvXz8A/Pz8GDJkCFFRUfj7++Pr68vIkSNp27ZtgUewlTeGYfDi4q3YDejeJJQ2tfytLklERMRShQ5I1apVY9OmTcyePZuNGzfi6enJ4MGD6dev33nnRLqYPn36cPToUSZMmEBcXBzNmzdn6dKljo7b+/fvz9ViNG7cOGw2G+PGjePQoUMEBgbSo0cPXnrpJcc+Bw8epF+/fhw7dozAwEA6dOjA6tWrCQw8t5Dqm2++iZOTE7169SIjI4POnTvz/vvvF/ajKDeWb0vgj13HcHNxYkzX+pd+gYiISDl3xWuxVVTlZR6kzGw7t775K3uPpfHIjXV4uosCkoiIlF/Fvhbb1q1b2b9/P5mZmbm233777Zd7SLHA/1btZe+xNAIqufPojXWsLkdERKRUKHRA2r17N3feeSebN2/GZrM5OkefHfGUk5NTtBVKsTl2KoO3os1h/U92vhofj8JdIhURESmvCj2K7bHHHqNWrVokJCTg5eXF33//zYoVK2jVqhW//PJLMZQoxWXa8h2kpGfTMNSX3i3L58SXIiIil6PQLUirVq3ip59+IiAgACcnJ5ycnOjQoQNTpkxh1KhR/PXXX8VRpxSx2LgUZq/ZB5jD+rUArYiIyDmFbkHKycnBx8cHMCd7PHz4MAA1a9YkNja2aKuTYvHvYf2dGwXTtk5Vq0sSEREpVQrdgtS4cWM2btxIrVq1iIyM5NVXX8XNzY0PPvgg3+zaUjr9HJvAbzsScXW28Uy3BlaXIyIiUuoUOiCNGzeO1NRUAJ5//nluu+02rrvuOqpWrcq8efOKvEApWlk5dl5cvA2AB9rXomZVb4srEhERKX0KHZA6d+7suH/VVVexfft2jh8/TpUqVbR2Vxnw2ep97D6aSlVvN4bffJXV5YiIiJRKheqDlJWVhYuLC1u2bMm13d/fX+GoDDiRmsm05eaw/qhbr8ZXw/pFRETOq1ABydXVlRo1amiuozLqregdJJ3Oon6ID31aaVi/iIjIhRR6FNuzzz7LM888w/Hjx4ujHikmOxNS+HT1uWH9Ls6F/k8vIiJSYRS6D9K7777Lzp07CQsLo2bNmnh75+7ku379+iIrTorOS4u3kWM36NQgmPZXBVhdjoiISKlW6IDUs2fPYihDitMvsQn8HHsUFycbz3TTYrQiIiKXUuiANHHixOKoQ4pJ9r+G9Q9sF0HtwEoWVyQiIlL6qSNKOTdn7X52Jpyiipcro26ua3U5IiIiZUKhW5CcnJwuOqRfI9xKj6S0LN5c9g8AUbdcjZ+XhvWLiIgURKED0sKFC3M9zsrK4q+//uKTTz7hueeeK7LC5Mq9/dMOTqRlUTeoEv3a1LC6HBERkTKj0AHpjjvuyLetd+/eNGrUiHnz5jFkyJAiKUyuzO6jp/jkj70AjNOwfhERkUIpsm/Na6+9lujo6KI6nFyhyd9vI9tucFO9QG64OtDqckRERMqUIglIp0+f5u2336ZatWpFcTi5Qit3JLJ8WwLOTjae7d7Q6nJERETKnEJfYsu7KK1hGKSkpODl5cVnn31WpMVJ4WXn2Hnhu60A3H9tTa4K0rB+ERGRwip0QHrzzTdzBSQnJycCAwOJjIykSpUqRVqcFN68Pw8QG5+Cn6crj3XUsH4REZHLUeiANGjQoGIoQ4pCcnoWU380h/U/3qkuVbzdLK5IRESkbCp0H6RZs2Yxf/78fNvnz5/PJ598UiRFyeV576edHEvNpHagN/ddW9PqckRERMqsQgekKVOmEBCQf7HToKAgJk+eXCRFSeHtTUxl5u97ABjXvQGuGtYvIiJy2Qr9Lbp//35q1aqVb3vNmjXZv39/kRQlhTdlyTaycgyuqxvATfWCrC5HRESkTCt0QAoKCmLTpk35tm/cuJGqVasWSVFSOH/sSuSHv+NxssH42xpedCkYERERubRCB6R+/foxatQofv75Z3JycsjJyeGnn37iscceo2/fvsVRo1xEjt3gxe+2AXBvZE2uDvaxuCIREZGyr9Cj2F544QX27t1Lx44dcXExX2632xkwYID6IFngy5gDbD2SjI+HC6NvudrqckRERMqFQgckNzc35s2bx4svvsiGDRvw9PSkSZMm1KypUVMlLSU9i9d+MIf1P9axLv4a1i8iIlIkCh2Qzqpbty5162oiQiu9/8suEk9lEFHViwFtI6wuR0REpNwodB+kXr168corr+Tb/uqrr3L33XcXuoD33nuPiIgIPDw8iIyMZO3atRfdf9q0adSrVw9PT0/Cw8MZPXo06enpjuenTJlC69at8fHxISgoiJ49exIbG5vrGDfeeCM2my3X7eGHHy507VY6cDyNj1aaw/qf7d4QNxcN6xcRESkqhf5WXbFiBd26dcu3vWvXrqxYsaJQx5o3bx5RUVFMnDiR9evX06xZMzp37kxCQsJ5958zZw5jxoxh4sSJbNu2jY8++oh58+bxzDPPOPb59ddfGT58OKtXr2bZsmVkZWVx6623kpqamutYQ4cO5ciRI47bq6++Wqjarfbyku1kZttpf1VVOjXQsH4REZGiVOhLbKdOncLNLX9fF1dXV5KTkwt1rKlTpzJ06FAGDx4MwIwZM1i8eDEzZ85kzJgx+fb/448/aN++Pf379wcgIiKCfv36sWbNGsc+S5cuzfWajz/+mKCgIGJiYrj++usd2728vAgJCSlUvaXF2j3HWbz5CE42GNddw/pFRESKWqFbkJo0acK8efPybZ87dy4NGzYs8HEyMzOJiYmhU6dO54pxcqJTp06sWrXqvK9p164dMTExjstwu3fv5vvvvz9vi9ZZSUlJAPj7++faPnv2bAICAmjcuDFjx44lLS3tovVmZGSQnJyc62YFu93ghe+2AtCndQ0ahPpaUoeIiEh5VugWpPHjx3PXXXexa9cubr75ZgCio6OZM2cOX375ZYGPk5iYSE5ODsHBwbm2BwcHs3379vO+pn///iQmJtKhQwcMwyA7O5uHH3441yW2f7Pb7Tz++OO0b9+exo0b5zpOzZo1CQsLY9OmTTz99NPExsayYMGCC9Y7ZcoUnnvuuQKfX3FZ8NchNh9KopK7C0/cqmH9IiIixaHQAalHjx4sWrSIyZMn8+WXX+Lp6UmzZs346aef8rXSFLVffvmFyZMn8/777xMZGcnOnTt57LHHeOGFFxg/fny+/YcPH86WLVtYuXJlru3Dhg1z3G/SpAmhoaF07NiRXbt2UadOnfO+99ixY4mKinI8Tk5OJjw8vIjOrGBSM7J5dakZHkfefBUBldxL9P1FREQqissa5t+9e3e6d+8OmEHh888/5z//+Q8xMTHk5OQU6BgBAQE4OzsTHx+fa3t8fPwF+waNHz+e+++/nwcffBAww01qairDhg3j2Wefxcnp3BXDESNG8N1337FixQqqV69+0VoiIyMB2Llz5wUDkru7O+7u1gaSGb/uIiElgxr+XgxqH2FpLSIiIuXZZY8NX7FiBQMHDiQsLIw33niDm2++mdWrVxf49W5ubrRs2ZLo6GjHNrvdTnR0NG3btj3va9LS0nKFIABnZ2cADMNw/BwxYgQLFy7kp59+Ou/Cunlt2LABgNDQ0ALXX9IOnTzNByt2A/BMt/q4uzhbXJGIiEj5VagWpLi4OD7++GM++ugjkpOTueeee8jIyGDRokWF6qB9VlRUFAMHDqRVq1a0adOGadOmkZqa6hjVNmDAAKpVq8aUKVMA8/Le1KlTadGiheMS2/jx4+nRo4cjKA0fPpw5c+bw9ddf4+PjQ1xcHAB+fn54enqya9cu5syZQ7du3ahatSqbNm1i9OjRXH/99TRt2rTQ51BSXlmynYxsO5G1/OncqGyOvhMRESkrChyQevTowYoVK+jevTvTpk2jS5cuODs7M2PGjMt+8z59+nD06FEmTJhAXFwczZs3Z+nSpY6O2/v378/VYjRu3DhsNhvjxo3j0KFDBAYG0qNHD1566SXHPtOnTwfMySD/bdasWQwaNAg3NzeWL1/uCGPh4eH06tWLcePGXfZ5FLeYfcf5ZuNhbDYYf5uG9YuIiBQ3m3H22tQluLi4MGrUKB555JFcS4y4urqycePGy2pBKsuSk5Px8/MjKSkJX9/iG2pvtxvcOf0PNh44yT2tqvNq72bF9l4iIiLlXUG/vwvcB2nlypWkpKTQsmVLIiMjeffdd0lMTCySYuXCvt54iI0HTuLt5sx/bq1ndTkiIiIVQoED0rXXXsuHH37IkSNHeOihh5g7dy5hYWHY7XaWLVtGSkpKcdZZIaVlZvPKEnMduUdvuoogXw+LKxIREakYCj2KzdvbmwceeICVK1eyefNmnnjiCV5++WWCgoK4/fbbi6PGCuuDFbuJS06nWmVPhnS49Gg8ERERKRpXtAR8vXr1ePXVVzl48CCff/55UdUkwJGk08z4dRcAY7vVx8NVw/pFRERKyhUFpLOcnZ3p2bMn33zzTVEcToBXl8aSnmWnVc0qdG9SeudnEhERKY+KJCBJ0dpw4CQL/zoEwIQeGtYvIiJS0hSQShnDMHj+278B6HVNdZpWr2xtQSIiIhWQAlIp8+2mI6zffxJPV2ee6qJh/SIiIlZQQCpFcuwGr/2wHYBHbqxDsIb1i4iIWEIBqRRxdrLxwf2tuKN5GEOvq211OSIiIhVWoRarleLXINSXt/q2sLoMERGRCk0tSCIiIiJ5KCCJiIiI5KGAJCIiIpKHApKIiIhIHgpIIiIiInkoIImIiIjkoYAkIiIikocCkoiIiEgeCkgiIiIieSggiYiIiOShgCQiIiKShwKSiIiISB4KSCIiIiJ5KCCJiIiI5KGAJCIiIpKHApKIiIhIHgpIIiIiInkoIImIiIjkoYAkIiIikocCkoiIiEgelgek9957j4iICDw8PIiMjGTt2rUX3X/atGnUq1cPT09PwsPDGT16NOnp6YU6Znp6OsOHD6dq1apUqlSJXr16ER8fX+TnJiIiImWTpQFp3rx5REVFMXHiRNavX0+zZs3o3LkzCQkJ591/zpw5jBkzhokTJ7Jt2zY++ugj5s2bxzPPPFOoY44ePZpvv/2W+fPn8+uvv3L48GHuuuuuYj9fERERKRtshmEYVr15ZGQkrVu35t133wXAbrcTHh7OyJEjGTNmTL79R4wYwbZt24iOjnZse+KJJ1izZg0rV64s0DGTkpIIDAxkzpw59O7dG4Dt27fToEEDVq1axbXXXlug2pOTk/Hz8yMpKQlfX98r+hxERESkZBT0+9uyFqTMzExiYmLo1KnTuWKcnOjUqROrVq0672vatWtHTEyM45LZ7t27+f777+nWrVuBjxkTE0NWVlauferXr0+NGjUu+L4iIiJSsbhY9caJiYnk5OQQHByca3twcDDbt28/72v69+9PYmIiHTp0wDAMsrOzefjhhx2X2ApyzLi4ONzc3KhcuXK+feLi4i5Yb0ZGBhkZGY7HycnJBT5XERERKVss76RdGL/88guTJ0/m/fffZ/369SxYsIDFixfzwgsvFPt7T5kyBT8/P8ctPDy82N9TRERErGFZQAoICMDZ2Tnf6LH4+HhCQkLO+5rx48dz//338+CDD9KkSRPuvPNOJk+ezJQpU7Db7QU6ZkhICJmZmZw8ebLA7wswduxYkpKSHLcDBw5cxlmLiIhIWWBZQHJzc6Nly5a5Olzb7Xaio6Np27bteV+TlpaGk1Pukp2dnQEwDKNAx2zZsiWurq659omNjWX//v0XfF8Ad3d3fH19c93kCmSlw8n9cDAGYpdAzCew4jX4/in4aijELrW6QhERqcAs64MEEBUVxcCBA2nVqhVt2rRh2rRppKamMnjwYAAGDBhAtWrVmDJlCgA9evRg6tSptGjRgsjISHbu3Mn48ePp0aOHIyhd6ph+fn4MGTKEqKgo/P398fX1ZeTIkbRt27bAI9jkPAwDMk/BqQRIPWrezt4/lQCpCXDq6LmfmSkXP962b2HYLxBUv0TKFxER+TdLA1KfPn04evQoEyZMIC4ujubNm7N06VJHJ+v9+/fnajEaN24cNpuNcePGcejQIQIDA+nRowcvvfRSgY8J8Oabb+Lk5ESvXr3IyMigc+fOvP/++yV34mWFYUD6yX8Fm0uEn+zThTu+sxt4B0GlwNw/968yb18OhqE/gatnsZyeiIjIhVg6D1JZVm7mQTIMOBUP8X+bt4StcDTW3JZ6FHIyC3c8V+8zQSdP6KkUZG6rFHRuu7sv2Gz5j3EqAaa3N4NXqyFw29SiOVcREanwCvr9bWkLkpSwzDQ4uu1MGNoK8VvMQJR27OKvc/c7F3S8A3KHnLzhx837yuusFAR3zoDP7oI/P4LaN0LD26/8uCIiIgWkgFQe2e1wYs+5FqH4LWYgOr4bOE+Doc0J/OtAcCPzFtQAfMPOBKJAcPUo8VPgqo7QbhT88TZ8MwLCWkBlTa0gIiIlQwGprEs9Bgl5WoQStkFW2vn39w48E4LOhKHghhBYv3T287l5POxdCYfXw4KhMPA7cNavrIiIFD9925QV2Rlm36B/twjF/w2nLjD7t4uHGXwcrUINzZ+Vgkq27ivh4ga9Z8KM68xO2ytehZueufTrRERErpACUmljGJB0IHeLUPzfkLgDjJzzv6ZKRO4WoeDG4F8bnJxLtPRi4V8LekyDr4aY8yTVuh4iOlhdlYiIlHMKSKXNR7fCwbXnf86jcp4WocbmPEHuPiVaYolr0ht2/QwbPjMnkXzkd/Dyt7oqEREpxxSQSpsqNeHwXxBwde4WoaCGZsfp8w2Lrwi6vgIH1sCxHfD1cOg7p/x+FkkH4dguqNYS3CtZXY2ISIWkeZAuU7HNg5R2HNwqmf1vJLcjm+D/OppzM3V9DSKHWV1R0YvfCh93g9MnwMnFDEkR15mXFsPblM7O9CIiZUhBv78VkC5TuZkosqxZPQOWPg3O7jA0GkKaWF1R0Tm2C2Z1NSfpdPXKPxLR2Q2qtzHDUq3roForBWkRkUJSQCpmCkgWMQz4vC/8sxSq1oWHfi2aySmtdnI/zOwKyQfNS6oDv4WMFNj7G+xZYd5SjuR+jasXhEeeCUzXQ2hzTYMgInIJCkjFTAHJQqnHYEZ7MzC0uB/ueNfqiq5MSpzZcnR8txn6Bn+ffzoGwzBbmPaeCUt7foO0xNz7uPlAzXZm61Kt6yG4CfxrLUMREVFAKnYKSBbbswI+uR0wzLmSGveyuqLLk3oMPu5uLgFTuQYMXgp+1S79OsOAo9vPtS7tXWkuLPxvHpXNKRFqXW/2YwpqUH47touIFJACUjFTQCoFfnrRnBvJ3Rce/s2cD6osSU+CT3rAkY3gEwqDl5jzPl0Oe445b9bZ1qV9f0BmSu59vAP/FZiuh6p1FJhEpMJRQCpmCkilQE622fpyYLXZYfmBpeDsanVVBZOZCp/eZdbuVdUMR4H1iu74OdlwZMO5Fqb9qyH7dO59fMLMy3FnR8lVqVl07y8iUkopIBUzBaRS4uR+mNHBbI3pMBo6TbK6okvLSofP+8DuX8DDz1xjLrRp8b5ndgYcijFbl/asMCcjzcnMvU/lGudal2rfAD4hxVuTiIgFFJCKmQJSKbL1a/hiAGCD+xdCnZusrujCcrJg3v3wzxJw9YYBX0N465KvI+s0HFh7pv/Sb2Z4smefe97ZDe75FOp1KfnaRESKkQJSMVNAKmW+fRxiZkGlYHj4d6gUaHVF+dlz4KsH4e8F5mLC935pXuIqDTJOmZfh9vwKO6Mh4W/zsxy+BjyrWF2diEiRKej3t8YAS/nQZQoENjAnWVz0MNjtVleUm90O34wyw5GTq9k6U1rCEZhLmtTtBLe+AEN/Mpe6ORUPP46zujIREUsoIEn54OppDvd38YCdy2H1e1ZXdI5hwNIx5mK7Nifo/RFcfavVVV2Yqwfc/g5gg78+MxcKFhGpYBSQpPwIbgidJ5v3lz8Hh9ZbW89Z0c/D2v+a93tOh4Z3WFtPQdS4FtqcWevu21HmqDsRkQpEAUnKl1YPQIPbwZ4FXw0xl+uw0orXYeVU8373qdCsr7X1FEbHCeAXbo4U/OlFq6sRESlRCkhSvthscPvb5hf78d2w+Anralk9HX56wbx/64vQeoh1tVwO90rQY5p5f/V0OLDO0nJEREqSApKUP55VoNf/mf19Ns2DDZ+XfA3r/2f2OwK4cSy0G1nyNRSFqzpBs/6AAd+MMOdTEhGpABSQpHyqca0ZTMBsRUrcWXLvvflLc8QamMHohqdL7r2LQ+eXzGVKjm6H396wuhoRkRKhgCTl13VPmMtoZKXCVw+UTOvH9sWwYBhgmP2hbnmh7K935uUP3V437//2BsRtsbYeEZESoIAk5ZeTM9z1AXj6mwvCLn+ueN9v108wfxAYOdC0L3R7o+yHo7Ma3gH1bzNn2/5mhLnWm4hIOaaAJOWbbxj0fN+8v/o9+OfH4nmffX/A5/3N9c0a3A53vAdO5eifl80G3d8Adz84/Besft/qikREilU5+gsucgH1ukLkw+b9RQ9D8pGiPf6h9TD7Hsg+DVfdAr0+AmeXon2P0sAnxOyPBPDzS3Bsl7X1iIgUIwUkqRg6PQfBTSDtGCwcZq6LVhTi/4bP7oLMFLO/U59PwcWtaI5dGrW4D2rdANnpZkf00raki4hIEVFAkorB1QPungWuXuYK9r9Pu/JjJu6E//WE0yegWivo97m55El5dnaeKVcv2LcS1n9idUUiIsVCAUkqjoC60O018/5PL8GBtZd/rJP74X93QGqC2TJ135fg7lM0dZZ2VSLMWbYBlk2ApEOWliMiUhwUkKRiaX4vNO5tjjT7cgicPln4Y6TEwSe3Q/JBc9X7+xeak1NWJG2GQfXWkJEMi6PMBXlFRMqRUhGQ3nvvPSIiIvDw8CAyMpK1ay/8f/Y33ngjNpst36179+6Ofc73vM1m47XXXnPsExERke/5l19+uVjPU0oBmw1umwqVa0LSfvj2scJ9uaceM1uOTuwxjzHga6gUWHz1llZOznD7u+DsBv8shS1fWV2RiEiRsjwgzZs3j6ioKCZOnMj69etp1qwZnTt3JiEh4bz7L1iwgCNHjjhuW7ZswdnZmbvvvtuxz7+fP3LkCDNnzsRms9GrV69cx3r++edz7TdyZBldDkIKx8MPes8CJxfYushcFqQgTp+ET3uaM0r7hMHAb8xpBCqqoPpw/ZPm/SVPmeFRRKScsDwgTZ06laFDhzJ48GAaNmzIjBkz8PLyYubMmefd39/fn5CQEMdt2bJleHl55QpI/34+JCSEr7/+mptuuonatWvnOpaPj0+u/by9vYv1XKUUqd4Sbh5v3l/yNCRsv/j+Gadgzj0Qt8lcdmPgN2ZfnIqu/eMQ1MgcHXh27TkRkXLA0oCUmZlJTEwMnTp1cmxzcnKiU6dOrFq1qkDH+Oijj+jbt+8Fw018fDyLFy9myJD8K6m//PLLVK1alRYtWvDaa6+RnX3h2YEzMjJITk7OdZMyrt0oqHOzOX/Rlw9A1unz75eVDnP7wYE14FEZ7l9kdvgWc0qDO94xFwbe/AX884PVFYmIFAlLA1JiYiI5OTkEBwfn2h4cHExcXNwlX7927Vq2bNnCgw8+eMF9PvnkE3x8fLjrrrtybR81ahRz587l559/5qGHHmLy5Mk89dRTFzzOlClT8PPzc9zCw8MvWZ+Uck5O0HOG2SKU8Df8OC7/PtmZ8MUAc2oAt0pw3wIIaVzytZZm1VpC2+Hm/e9GQ7r+50FEyj7LL7FdiY8++ogmTZrQpk2bC+4zc+ZM7r33Xjw8PHJtj4qK4sYbb6Rp06Y8/PDDvPHGG7zzzjtkZJx/QdOxY8eSlJTkuB04cKBIz0Us4hMMd84w76/7P9j23bnn7DnmpJI7fgAXT+j/hXlpTvK78RmoUguSD8HySVZXIyJyxSwNSAEBATg7OxMfH59re3x8PCEhIRd9bWpqKnPnzj3vpbOzfvvtN2JjYy/awnRWZGQk2dnZ7N2797zPu7u74+vrm+sm5cRVnaDdmQ76Xw+HpIPmDNHfjIS/F4KTK/T9DCLaW1tnaebmZU4gCfDnR7D3d2vrERG5QpYGJDc3N1q2bEl0dLRjm91uJzo6mrZt2170tfPnzycjI4P77rvvgvt89NFHtGzZkmbNml2ylg0bNuDk5ERQUFDBT0DKj5snQNg1kH4SvhpqjsraMBtszuYM3Fd1uuQhKrxa10PLQeb9b0ZeuE+XiEgZYPkltqioKD788EM++eQTtm3bxiOPPEJqaiqDBw8GYMCAAYwdOzbf6z766CN69uxJ1apVz3vc5ORk5s+ff97Wo1WrVjFt2jQ2btzI7t27mT17NqNHj+a+++6jSpUKNuGfmFzcoPdH4OYD+/+AdR8CNug5HRr0sLq6suOW58EnFI7vgl80r5iIlF2WLznep08fjh49yoQJE4iLi6N58+YsXbrU0XF7//79ODnlznGxsbGsXLmSH3/88YLHnTt3LoZh0K9fv3zPubu7M3fuXCZNmkRGRga1atVi9OjRREVFFe3JSdniX9ucRHLBUPPxbW9Csz7W1lTWePiZn9vnfeGPd6BRTwhrYXVVIiKFZjMMrRFwOZKTk/Hz8yMpKUn9kcqbvxeaLUl1dVntsn35gDm7dnATGPYzOLtaXZGICFDw72/LL7GJlDqN7lQ4ulJdXgFPf4jfDL+/ZXU1IiKFpoAkIkWvUiB0fcW8/+srcDTW2npERApJAUlEikeTu6HurZCTCV+PMOeVEhEpIxSQRKR42Gxmh223SnBwrTkRp4hIGaGAJCLFx6863PKceX/5c3Bin7X1iIgUkAKSiBSvlg9AzfaQlQrfPQ4aOCsiZYACkogULycn6PE2uHjArp9g4+dWVyQickkKSCJS/AKughvPzIi/dCykxF98fxERiykgiUjJaDsCQpuZ690tedLqaqQ0S082Fzy2262uRCowBSQRKRnOLnDHe+DkAlu/hq3fWF2RlEa7f4X3r4WPu8F3j6nPmlhGAUlESk5IE2j/uHn/+//A6ROWliOlSFY6LH0G/nc7JB8yt63/H6x809q6pMJSQBKRknX9kxBwNZyKhx/HWV2NlAZxm+GDG2H1e+bjloPhlufN+9HPweYvLStNKi4FJBEpWa4ecPs7gA3++gx2/Wx1RWIVew6snAYf3ARHt4F3IPT/AnpMg/aPwbXDzf0WPQr7VllZqVRACkgiUvJqXAtthpn3vx0FmanW1iMl78Q++KQHLJ8I9iyo1x0eXQ1Xdz63z60vQP3bICcD5vaDY7usq1cqHAUkEbFGxwngFw4n98NPL1pdjZQUw4ANn8P09rDvd3Mpmtvfhb6zwTsg975OznDXh1CtpdlfbXZvSD1mTd1S4SggiYg13CuZl1IAVk+HA+ssLUdKQNpx+GIALHoYMlMgPBIeXgnX3G+u3Xc+bl7Qby5UrgHHd5stSVnpJVu3VEgKSCJinas6QbP+gAHfjIDsDKsrkuKyYzm83xa2fWNO9XDzeBi8BPxrXfq1lYLg3i/Bww8OrDEDluZIkmKmgCQi1ur8ktk59+h2+O0Nq6uRopaZBov/A7N7wak4CKgHD0bD9f8xL6EVVGA96DMbnFzh74Xm6DYpPlmnzf92FZgCkohYy8sfur1u3v/tDYjbYm09UnQOxcB/r4N1H5qP2zwED/0KYc0v73i1roM73jXv/z4N/pxVFFXKvx3+C74ZBa/WgbebQ+IOqyuyjM0wNE3p5UhOTsbPz4+kpCR8fX2tLkekbDMMmHcfbP8OwlrAkOXmzNvF9V4ZKeaSJ6dPnv9nejKENIbGvcDdp3jqKM9ysmHlVPj1FbBng0+oOYv6VR2L5vi/vAK/TAabszktQN1ORXPciiozFbZ8BX/ONAPSv/mFwwM/gF81a2orBgX9/lZAukwKSCJFLCUO3m0DGUlwywvQftSF9zUMyDxlBprTJy4edv798/QJSE8CI6dgNbl6Q+M7ocUACG9z4Y7Ecs6xXbDwITh4ptN9ozuh+1SzpbCoGIY5N9LGOeYouAeWmrO0S+HEb4WYWbBxLmQkm9uc3aDB7dD0HvjhGTi207ws+sDSov1vaCEFpGKmgCRSDNZ/anbWdvGAax8xW3LO28KTZLZMXAlnd/CsDB6V8/90cYd/lkLiP+f2D6gH1wyAZn3zD0cXM7Ss/8RcLiQrFdz9oPvr0OTu4gmW2Znw2V2w9zfwCYMHl5erVo5ik5VuroX450w4sPrc9iq1oNVgaH7vud/vk/vho86QchiqtYIBX5ujT8s4BaRipoAkUgwMAz7tCbt/Kdj+zm7gWeX8IedSP109L/7FbRjmiKn1/zM7BWed6bDq5Ar1u5thqfZN4KSunJxKMPut/LPEfBxxHfScDpXDi/d9T5+EmZ3NDv7BTeCBJbokeiGJO83Wog2zz62BaHM2f5dbDYZaN57/dzlhO8zqYr6mzs3Qbx64uJVk5UVOAamYKSCJFJOUOFjxmvnH+0pDTlFJTzL7aKz/FA6vP7fdrwa0uA9a3At+1Yu/jtJo+/fwzUhISzQDa8cJ5hIhJRUcT+yD/+sEqQnmtBH95hVf/7WyJjsTYhebrUV7Vpzb7lsdWg4yf3d9Qy99nAPrzEWEs9Kg0V3Q6/8KNwKxlFFAKmYKSCIVVNxmMyhtmmsGJwBsZgfkawbA1V3L/P9hF0jGKfhhrNnCBhDUCHp9CMGNSr6WQzEwqztknza/+G+bVrH7i53YCzGfwF+fQurRMxtt5jIurR4wg2RhA87O5TCnr7ksTOsHzZGnZfQzVkAqZgpIIhVc1mnY9p3Z72bvb+e2ewVA835mx+7Aq62rrzgdWAsLhppfxNig3Qhz4kcXd+tq2r4Y5t4LGNDpOejwuHW1WCEnG3b8YLYW7YwGzny1Vwoxg/s1A678kueWr+DLIeaxb3gabnrmSqu2hAJSMVNAEhGHY7vgr8/M/h2n4s9tr9HW/GJqeAe4eVtXX1HJyTKH7v/2Bhh2cwh4z+nm/ESlweoZsPRp8/7dH5sj6Mq75MNmK17MJ2Zn6rNq32S2FtXrCs6uRfd+6/4PFj9h3u/6KkQ+VHTHLiEKSMVMAUlE8snJhh0/ml9YO348N52Au685p9I1A8x5nsripYmj/5itRkc2mI+b9oVur5rLf5QmS56GNTPMUYoDv4UakVZXVPTsdtj1k9la9M/Sc79nXlXNfkXXDISqdYrv/c/OQwVw1/9B07uL772KgQJSMVNAEpGLSj5iztOz/n9nLkWdEdzEDEpN7zZH4JV2hgFrP4Rl4yE73az5tjdLb+uMPcecdDT2e/D0N4f/F2dYKEmnEsx+RTGfwMl957bX7GCORGvQo2QucxqGGUTX/tdcV6/fXKh7S/G/bxFRQCpmCkgiUiB2O+xbaQalrd9AzpkFeZ3dzUtv19xvfsGVxukCko/A18NhV7T5uM7NcMf7BRv5ZKXMVPi4uzkrtH8dMySV1UkODcPs4/bnTLPPmz3L3O7hZy703GqwuU5dSbPbYeEw2DwfXDzNOZLKSGudAlIxU0ASkUJLO25+ocR8Agl/n9tepZYZlJrfCz4h1tX3b38vgu8eN+e/cfEwZzdvM7TsXB5MiTeH/yftN/uC3b8IXD2srqrg0o7Dhjnm3EXHdp7bXr212beoYU9w87KsPMCcRmBuf9i5zAxsg5dYM4qxkMpUQHrvvfd47bXXiIuLo1mzZrzzzju0adPmvPveeOON/Prrr/m2d+vWjcWLFwMwaNAgPvnkk1zPd+7cmaVLlzoeHz9+nJEjR/Ltt9/i5OREr169eOutt6hUqWCzhCogichlMwxzPqX1/4PNX5rLpoA599PVnc1LcDXbm52iczIgJ9P8MsrJOPPz3/cL8nwWZGfkeT7z3DbH82e2ZWeYwQIgtDnc9WHZHJGXsM2cCTojyewDdtf/lc6Wun87vgdWvWt2+s9ON7e5VYKmfczWotK2pEpmKvyvJxxca46YG/IDVImwuqqLKjMBad68eQwYMIAZM2YQGRnJtGnTmD9/PrGxsQQFBeXb//jx42RmZjoeHzt2jGbNmvF///d/DBo0CDADUnx8PLNmnVvp2d3dnSpVzl3v79q1K0eOHOG///0vWVlZDB48mNatWzNnzpwC1a2AJCJFIuMUbF1khqUDa6yu5hybE3SIModzl+V5nXb/ai5JYs+G654wJ7IsjY5shJXTzN8Fw25uC2kCrYZAk96le4bwtOPmJc2EreBf21zctlL+7+/SoswEpMjISFq3bs27774LgN1uJzw8nJEjRzJmzJhLvn7atGlMmDCBI0eO4O1tDqMdNGgQJ0+eZNGiRed9zbZt22jYsCHr1q2jVatWACxdupRu3bpx8OBBwsLCLvm+CkgiUuSOxppBaePnkHbM3GZzNjveOruZt7P3XdzN4dvO7nmedzuz7cxjx/0LbLvQa/yqge+l/xaWCRvmwKJHzPs93oaWA62t5yzDMJfV+f0t2P3zue1XdYL2j0NEh7JzSTP5CMy81Vy/LaQJDFpc+kY4nlHQ729L52PPzMwkJiaGsWPHOrY5OTnRqVMnVq1aVaBjfPTRR/Tt29cRjs765ZdfCAoKokqVKtx88828+OKLVK1aFYBVq1ZRuXJlRzgC6NSpE05OTqxZs4Y778w/OiMjI4OMjAzH4+Tk5EKdq4jIJQXWg84vmf19stPN4FOGl3QoNZr3N0cS/voKfDfaXBbmqo7W1WPPMReM/f2tc9Mm2Jyh8V3Q/rHSdxmtIHxDzX5eMzubs81/3h/u+6ps9fvKw9KLsYmJieTk5BAcHJxre3BwMHFxcZd8/dq1a9myZQsPPvhgru1dunThf//7H9HR0bzyyiv8+uuvdO3alZwcc66IuLi4fJfvXFxc8Pf3v+D7TpkyBT8/P8ctPLyYF2EUkYrLycnsgKtwVHRuHGvO3WTkwBcDIW5LydeQddqcaPGda+DLwWY4cvGENg/BqL/MNc7KYjg6q2odMxS5+5ojN798wJwbrIwq0yv6ffTRRzRp0iRfh+6+ffs67jdp0oSmTZtSp04dfvnlFzp2vLz/axg7dixRUVGOx8nJyQpJIiJlhc0Gt78NSQfNL+8598CD0SUzZcHpE2YwWvPfc2ujefqbs1C3HgreVYu/hpIS2gz6fQ6f3mUulPvtY3DHu2XnUuG/WNqCFBAQgLOzM/Hx8bm2x8fHExJy8aGuqampzJ07lyFDhlzyfWrXrk1AQAA7d5pDJUNCQkhISMi1T3Z2NsePH7/g+7q7u+Pr65vrJiIiZYiLO/T9DAKuhuRDMOduyEgpvvdLOghLn4GpjeCnF81wVLkGdH0NRm+BG8eUr3B0VkQHuHuW2dF/w2ewrJR2jL8ESwOSm5sbLVu2JDo62rHNbrcTHR1N27ZtL/ra+fPnk5GRwX333XfJ9zl48CDHjh0jNNT8P4W2bdty8uRJYmJiHPv89NNP2O12IiPLxkRXIiJyGTyrwL3zwTvQ7CtTHJeBErbBwofhrWaw+j3ISjVnUL/r/2DkXxA5rHyszXcx9bvD7e+Y9/942xyhV8ZYPopt3rx5DBw4kP/+97+0adOGadOm8cUXX7B9+3aCg4MZMGAA1apVY8qUKbled91111GtWjXmzp2ba/upU6d47rnn6NWrFyEhIezatYunnnqKlJQUNm/ejLu7OQ17165diY+PZ8aMGY5h/q1atdIwfxGRiuDgn+bQ9Ox0cyh99zeu7DKQYcD+VWbH63/OzblHxHXQ4XGo07FMXma6Yr+/bS5TA2ZgumaAtfVQRkaxAfTp04ejR48yYcIE4uLiaN68OUuXLnV03N6/fz9OeSb2io2NZeXKlfz444/5jufs7MymTZv45JNPOHnyJGFhYdx666288MILjnAEMHv2bEaMGEHHjh0dE0W+/fbbxXuyIiJSOlRvZU6A+cUA+PMj8K8F7UYW/jh2O/yzxGwhObj2zEYbNLzdHJFWrWVRVl32tB9lTlnx+zSzP5JnFXPNuDLA8hakskotSCIi5cCq9+CHZ8z7d38CjXoW7HXZGbDpC/PyUeI/5jZnd2jeD9qNKj8L5BYFw4BvRpoL7Tq7w31fQq3rLSunzLQgiYiIWObaR83lPdZ9CAsfAt9qEN76wvunJ0PMx7D6fUg5Ym5z94PWQyDyYfAJvvBrKyqbDW6bZo7m2/6dOUfSoO8grLnVlV2UWpAuk1qQRETKiZxsmHev2XfIKwAeXGYumfFvKfGwZjqsm2mu7QbgEwZtH4VrBoKHvgcuKSsdZveGvb+Zn/MDP0DAVSVeRplZaqSsUkASESlHMk7Bx93MNdGqXgVDloGXPyTuNC+jbfzcXMwXzGkC2j8GTe4p2+vUWSE9GT65zfyc/cJhyI8lvqSNAlIxU0ASESlnUuLgw46QfBDCI6FSMGz7FjjzNRkeaa6RdnUXc7ZzuTynjsKsLnBsJwTWh8FLzDBaQhSQipkCkohIORS/1VxPLONf621e3dVsMap58fn5pBBO7oePOkPKYajeGgZ8XWJzQxX0+1sRWERE5KzghtDnM6haF5r1h0dXQ/+5CkdFrXINuH8BeFSGg+tg3v2QnWl1VbmoBekyqQVJRETkCh1YB/+7HbLSoHEvc7bxYr58qRYkERERKd3CW0OfT8HJFbZ8BUueMudNKgUUkERERMQ6V3WCO2cANnM+ql9fsboiQAFJRERErNakN3R7zbz/yxRY84G19aCAJCIiIqVBm6Fw45llX5Y8BZu/tLQcBSQREREpHW54CtoMAwxz6Zcdyy0rRWuxiYiISOlgs0GXVyDtOOyKBg8/y0pRQBIREZHSw8kJek43ZzTPuyZeSZZh2TuLiIiInI+Lm6XhCBSQRERERPJRQBIRERHJQwFJREREJA8FJBEREZE8FJBERERE8lBAEhEREclDAUlEREQkDwUkERERkTwUkERERETyUEASERERyUMBSURERCQPBSQRERGRPBSQRERERPJwsbqAssowDACSk5MtrkREREQK6uz39tnv8QtRQLpMKSkpAISHh1tciYiIiBRWSkoKfn5+F3zeZlwqQsl52e12Dh8+jI+PDzabrciOm5ycTHh4OAcOHMDX17fIjluWVPTPoKKfP+gz0PlX7PMHfQbFef6GYZCSkkJYWBhOThfuaaQWpMvk5ORE9erVi+34vr6+FfIfxb9V9M+gop8/6DPQ+Vfs8wd9BsV1/hdrOTpLnbRFRERE8lBAEhEREclDAamUcXd3Z+LEibi7u1tdimUq+mdQ0c8f9Bno/Cv2+YM+g9Jw/uqkLSIiIpKHWpBERERE8lBAEhEREclDAUlEREQkDwUkERERkTwUkEqZ9957j4iICDw8PIiMjGTt2rVWl1QipkyZQuvWrfHx8SEoKIiePXsSGxtrdVmWefnll7HZbDz++ONWl1KiDh06xH333UfVqlXx9PSkSZMm/Pnnn1aXVWJycnIYP348tWrVwtPTkzp16vDCCy9ccs2osmrFihX06NGDsLAwbDYbixYtyvW8YRhMmDCB0NBQPD096dSpEzt27LCm2GJysc8gKyuLp59+miZNmuDt7U1YWBgDBgzg8OHD1hVcxC71O/BvDz/8MDabjWnTppVIbQpIpci8efOIiopi4sSJrF+/nmbNmtG5c2cSEhKsLq3Y/frrrwwfPpzVq1ezbNkysrKyuPXWW0lNTbW6tBK3bt06/vvf/9K0aVOrSylRJ06coH379ri6urJkyRK2bt3KG2+8QZUqVawurcS88sorTJ8+nXfffZdt27bxyiuv8Oqrr/LOO+9YXVqxSE1NpVmzZrz33nvnff7VV1/l7bffZsaMGaxZswZvb286d+5Menp6CVdafC72GaSlpbF+/XrGjx/P+vXrWbBgAbGxsdx+++0WVFo8LvU7cNbChQtZvXo1YWFhJVQZYEip0aZNG2P48OGOxzk5OUZYWJgxZcoUC6uyRkJCggEYv/76q9WllKiUlBSjbt26xrJly4wbbrjBeOyxx6wuqcQ8/fTTRocOHawuw1Ldu3c3HnjggVzb7rrrLuPee++1qKKSAxgLFy50PLbb7UZISIjx2muvObadPHnScHd3Nz7//HMLKix+eT+D81m7dq0BGPv27SuZokrQhc7/4MGDRrVq1YwtW7YYNWvWNN58880SqUctSKVEZmYmMTExdOrUybHNycmJTp06sWrVKgsrs0ZSUhIA/v7+FldSsoYPH0737t1z/R5UFN988w2tWrXi7rvvJigoiBYtWvDhhx9aXVaJateuHdHR0fzzzz8AbNy4kZUrV9K1a1eLKyt5e/bsIS4uLte/BT8/PyIjIyvk38SzkpKSsNlsVK5c2epSSoTdbuf+++/nySefpFGjRiX63lqstpRITEwkJyeH4ODgXNuDg4PZvn27RVVZw2638/jjj9O+fXsaN25sdTklZu7cuaxfv55169ZZXYoldu/ezfTp04mKiuKZZ55h3bp1jBo1Cjc3NwYOHGh1eSVizJgxJCcnU79+fZydncnJyeGll17i3nvvtbq0EhcXFwdw3r+JZ5+raNLT03n66afp169fhVnA9pVXXsHFxYVRo0aV+HsrIEmpM3z4cLZs2cLKlSutLqXEHDhwgMcee4xly5bh4eFhdTmWsNvttGrVismTJwPQokULtmzZwowZMypMQPriiy+YPXs2c+bMoVGjRmzYsIHHH3+csLCwCvMZyPllZWVxzz33YBgG06dPt7qcEhETE8Nbb73F+vXrsdlsJf7+usRWSgQEBODs7Ex8fHyu7fHx8YSEhFhUVckbMWIE3333HT///DPVq1e3upwSExMTQ0JCAtdccw0uLi64uLjw66+/8vbbb+Pi4kJOTo7VJRa70NBQGjZsmGtbgwYN2L9/v0UVlbwnn3ySMWPG0LdvX5o0acL999/P6NGjmTJlitWllbizf/cq+t9EOBeO9u3bx7JlyypM69Fvv/1GQkICNWrUcPxd3LdvH0888QQRERHF/v4KSKWEm5sbLVu2JDo62rHNbrcTHR1N27ZtLaysZBiGwYgRI1i4cCE//fQTtWrVsrqkEtWxY0c2b97Mhg0bHLdWrVpx7733smHDBpydna0usdi1b98+39QO//zzDzVr1rSoopKXlpaGk1PuP8vOzs7Y7XaLKrJOrVq1CAkJyfU3MTk5mTVr1lSIv4lnnQ1HO3bsYPny5VStWtXqkkrM/fffz6ZNm3L9XQwLC+PJJ5/khx9+KPb31yW2UiQqKoqBAwfSqlUr2rRpw7Rp00hNTWXw4MFWl1bshg8fzpw5c/j666/x8fFx9DHw8/PD09PT4uqKn4+PT77+Vt7e3lStWrXC9MMaPXo07dq1Y/Lkydxzzz2sXbuWDz74gA8++MDq0kpMjx49eOmll6hRowaNGjXir7/+YurUqTzwwANWl1YsTp06xc6dOx2P9+zZw4YNG/D396dGjRo8/vjjvPjii9StW5datWoxfvx4wsLC6Nmzp3VFF7GLfQahoaH07t2b9evX891335GTk+P42+jv74+bm5tVZReZS/0O5A2Erq6uhISEUK9eveIvrkTGykmBvfPOO0aNGjUMNzc3o02bNsbq1autLqlEAOe9zZo1y+rSLFPRhvkbhmF8++23RuPGjQ13d3ejfv36xgcffGB1SSUqOTnZeOyxx4waNWoYHh4eRu3atY1nn33WyMjIsLq0YvHzzz+f99/9wIEDDcMwh/qPHz/eCA4ONtzd3Y2OHTsasbGx1hZdxC72GezZs+eCfxt//vlnq0svEpf6HcirJIf52wyjnE7RKiIiInKZ1AdJREREJA8FJBEREZE8FJBERERE8lBAEhEREclDAUlEREQkDwUkERERkTwUkERERETyUEASEblMNpuNRYsWWV2GiBQDBSQRKZMGDRqEzWbLd+vSpYvVpYlIOaC12ESkzOrSpQuzZs3Ktc3d3d2iakSkPFELkoiUWe7u7oSEhOS6ValSBTAvf02fPp2uXbvi6elJ7dq1+fLLL3O9fvPmzdx88814enpStWpVhg0bxqlTp3LtM3PmTBo1aoS7uzuhoaGMGDEi1/OJiYnceeedeHl5UbduXb755hvHcydOnODee+8lMDAQT09P6tatmy/QiUjppIAkIuXW+PHj6dWrFxs3buTee++lb9++bNu2DYDU1FQ6d+5MlSpVWLduHfPnz2f58uW5AtD06dMZPnw4w4YNY/PmzXzzzTdcddVVud7jueee45577mHTpk1069aNe++9l+PHjzvef+vWrSxZsoRt27Yxffp0AgICSu4DEJHLVyJL4oqIFLGBAwcazs7Ohre3d67bSy+9ZBiGYQDGww8/nOs1kZGRxiOPPGIYhmF88MEHRpUqVYxTp045nl+8eLHh5ORkxMXFGYZhGGFhYcazzz57wRoAY9y4cY7Hp06dMgBjyZIlhmEYRo8ePYzBgwcXzQmLSIlSHyQRKbNuuukmpk+fnmubv7+/437btm1zPde2bVs2bNgAwLZt22jWrBne3t6O59u3b4/dbic2Nhabzcbhw4fp2LHjRWto2rSp4763tze+vr4kJCQA8Mgjj9CrVy/Wr1/PrbfeSs+ePWnXrt1lnauIlCwFJBEps7y9vfNd8ioqnp6eBdrP1dU112ObzYbdbgega9eu7Nu3j++//55ly5bRsWNHhg8fzuuvv17k9YpI0VIfJBEpt1avXp3vcYMGDQBo0KABGzduJDU11fH877//jpOTE/Xq1cPHx4eIiAiio6OvqIbAwEAGDhzIZ599xrRp0/jggw+u6HgiUjLUgiQiZVZGRgZxcXG5trm4uDg6Qs+fP59WrVrRoUMHZs+ezdq1a/noo48AuPfee5k4cSIDBw5k0qRJHD16lJEjR3L//fcTHBwMwKRJk3j44YcJCgqia9eupKSk8PvvvzNy5MgC1TdhwgRatmxJo0aNyMjI4LvvvnMENBEp3RSQRKTMWrp0KaGhobm21atXj+3btwPmCLO5c+fy6KOPEhoayueff07Dhg0B8PLy4ocffuCxxx6jdevWeHl50atXL6ZOneo41sCBA0lPT+fNN9/kP//5DwEBAfTu3bvA9bm5uTF27Fj27t2Lp6cn1113HXPnzi2CMxeR4mYzDMOwuggRkaJms9lYuHAhPXv2tLoUESmD1AdJREREJA8FJBEREZE81AdJRMol9R4QkSuhFiQRERGRPBSQRERERPJQQBIRERHJQwFJREREJA8FJBEREZE8FJBERERE8lBAEhEREclDAUlEREQkDwUkERERkTz+H9HRyDirZtosAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting to see if the model is overfitting\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182/182 [==============================] - 1s 6ms/step\n",
      "(5819, 60, 2)\n",
      "(5819, 60, 2)\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model('modelus1.h5')\n",
    "preds = model.predict(test_data_tensors)\n",
    "\n",
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "# Assuming preds is the output of model.predict\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming preds is the output of model.predict\n",
    "predicted_class_labels = preds.argmax(axis=-1)\n",
    "predicted_class_labels_df = pd.DataFrame({'Predicted_Class': predicted_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "# Print the first 50 rows\n",
    "#print(predicted_class_labels_df.head(50))\n",
    "\n",
    "true_class_labels = test_label_tensors.argmax(axis=-1)\n",
    "true_class_labels_df = pd.DataFrame({'Predicted_Class': true_class_labels[:, 0]}) #puts into dataframe\n",
    "\n",
    "#print(true_class_labels_df[0:10])\n",
    "\n",
    "\n",
    "# for i in predicted_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "# for i in true_class_labels_df['Predicted_Class'][60:100]:\n",
    "#     print(i)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "### making a prediction function based on models guesses.\n",
    "# print(preds.shape)\n",
    "dol = pd.DataFrame(test_data_participants_tensor)\n",
    "dol[\"Name\"] = dol[1]\n",
    "dol = dol.astype(object)\n",
    "\n",
    "unique_indices = dol.drop_duplicates(subset=\"Name\").index.tolist()\n",
    "\n",
    "unique_indices.append(len(dol)) #appending last index\n",
    "\n",
    "true_df_list = []\n",
    "pred_df_list = []\n",
    "\n",
    "for i in range(len(unique_indices)-1): #segment data\n",
    "    if i == unique_indices[-1]:\n",
    "        break\n",
    "    start_index = unique_indices[i]\n",
    "    end_index = unique_indices[i + 1]\n",
    "\n",
    "    # print(start_index, end_index)\n",
    "\n",
    "    true_list = true_class_labels_df[start_index: end_index]\n",
    "    pred_list = predicted_class_labels_df[start_index: end_index]\n",
    "\n",
    "    true_df_list.append(true_list)\n",
    "    pred_df_list.append(pred_list)\n",
    "\n",
    "pred_list = []\n",
    "true_list = []\n",
    "\n",
    "#now for the prediction:\n",
    "for df in pred_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred = 1\n",
    "    elif avg > 0.5:\n",
    "        pred = 0\n",
    "    pred_list.append(pred)\n",
    "\n",
    "for df in true_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred1 = 1\n",
    "    elif avg > 0.5:\n",
    "        pred1 = 0\n",
    "    true_list.append(pred1)\n",
    "\n",
    "\n",
    "print(pred_list)\n",
    "print(true_list)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5819, 60, 2)\n",
      "(5819, 60, 2)\n",
      "   0  1\n",
      "0  1  0\n",
      "1  1  0\n",
      "2  1  0\n",
      "3  1  0\n",
      "4  1  0\n",
      "[1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1]\n",
      "[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "#making a prediction function based on sum of outputs\n",
    "\n",
    "print(preds.shape)\n",
    "print(test_label_tensors.shape)\n",
    "\n",
    "predictions = pd.DataFrame(preds[:, -1, :])\n",
    "test_label = pd.DataFrame(test_label_tensors[:, -1, :])\n",
    "\n",
    "\n",
    "print(test_label.head(5))\n",
    "\n",
    "\n",
    "True_df_list = []\n",
    "predict_df_list = []\n",
    "\n",
    "\n",
    "for i in range(len(unique_indices)-1): #segment data\n",
    "    if i == unique_indices[-1]:\n",
    "        break\n",
    "    start_index = unique_indices[i]\n",
    "    end_index = unique_indices[i + 1]\n",
    "\n",
    "    # print(start_index, end_index)\n",
    "\n",
    "    true_list = predictions[start_index: end_index]\n",
    "    pred_list = test_label[start_index: end_index]\n",
    "\n",
    "    True_df_list.append(true_list)\n",
    "    predict_df_list .append(pred_list)\n",
    "\n",
    "\n",
    "# now for predictions\n",
    "\n",
    "\n",
    "final_predictions = []\n",
    "true_list = []\n",
    "\n",
    "for i in True_df_list:\n",
    "    sum_0 = sum(i[0])\n",
    "    sum_1 = sum(i[1])\n",
    "    if sum_0 > sum_1:\n",
    "        final_predictions.append(1)\n",
    "    else:\n",
    "        final_predictions.append(0)\n",
    "\n",
    "\n",
    "for df in true_df_list:\n",
    "    avg = sum(df['Predicted_Class'])/len(df)\n",
    "    if avg <= 0.5:\n",
    "        pred1 = 1\n",
    "    elif avg > 0.5:\n",
    "        pred1 = 0\n",
    "    true_list.append(pred1)\n",
    "    \n",
    "\n",
    "print(final_predictions)\n",
    "print(true_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
